--- a/src/build/.gitignore
+++ b/src/build/.gitignore
@@ -23,6 +23,13 @@ ciopfs
 /x64/
 /linux/debian_*-sysroot/
 /linux/ubuntu_*-sysroot/
+# We've built anything with pios in the name
+/linux/pios_*-sysroot/
+/linux/sysroot_scripts/*pios*
+/linux/sysroot_scripts/generated_package_lists/buster.*
+/linux/sysroot_scripts/generated_package_lists/bullseye.*
+/linux/sysroot_scripts/generated_package_lists/*pios*
+
 /ios_files
 /mac_files
 
--- a/src/build/config/linux/BUILD.gn
+++ b/src/build/config/linux/BUILD.gn
@@ -5,6 +5,7 @@
 import("//build/config/c++/c++.gni")
 import("//build/config/chromeos/ui_mode.gni")
 import("//build/config/linux/pkg_config.gni")
+import("//build/config/sysroot.gni")
 import("//build/config/ui.gni")
 
 group("linux") {
--- a/src/build/install-build-deps.sh
+++ b/src/build/install-build-deps.sh
@@ -34,13 +34,13 @@ build_apt_package_list() {
   echo "Building apt package list." >&2
   apt-cache dumpavail | \
     python3 -c '\
-      import re,sys; \
-      o = sys.stdin.read(); \
-      p = {"i386": ":i386"}; \
-      f = re.M | re.S; \
-      r = re.compile(r"^Package: (.+?)$.+?^Architecture: (.+?)$", f); \
-      m = ["%s%s" % (x, p.get(y, "")) for x, y in re.findall(r, o)]; \
-      print("\n".join(m))'
+import re,sys;\
+o = sys.stdin.read();\
+p = {"i386": ":i386"};\
+f = re.M | re.S;\
+r = re.compile(r"^Package: (.+?)$.+?^Architecture: (.+?)$", f);\
+m = ["%s%s" % (x, p.get(y, "")) for x, y in re.findall(r, o)];\
+print("\n".join(m))'
 }
 
 # Checks whether a particular package is available in the repos.
--- a/src/chrome/app/chrome_main_delegate.cc
+++ b/src/chrome/app/chrome_main_delegate.cc
@@ -68,6 +68,7 @@
 #include "components/nacl/common/buildflags.h"
 #include "components/services/heap_profiling/public/cpp/profiling_client.h"
 #include "components/startup_metric_utils/browser/startup_metric_utils.h"
+#include "components/version_info/pi_patch_version_info.h"
 #include "components/version_info/version_info.h"
 #include "content/public/common/content_client.h"
 #include "content/public/common/content_constants.h"
@@ -394,6 +395,15 @@ bool HandleVersionSwitches(const base::C
   }
 #endif
 
+  if (command_line.HasSwitch(switches::kPiPatchVersion)) {
+    printf("%s %s %s\nPi patch: %s\n",
+           version_info::GetProductName().c_str(),
+           version_info::GetVersionNumber().c_str(),
+           chrome::GetChannelName(chrome::WithExtendedStable(true)).c_str(),
+           version_info::GetPiPatchVersionString().c_str());
+    return true;
+  }
+
   if (command_line.HasSwitch(switches::kVersion)) {
     printf("%s %s %s\n", version_info::GetProductName().c_str(),
            version_info::GetVersionNumber().c_str(),
--- a/src/chrome/browser/about_flags.cc
+++ b/src/chrome/browser/about_flags.cc
@@ -6291,14 +6291,14 @@ const FeatureEntry kFeatureEntries[] = {
      flag_descriptions::kChromeOSDirectVideoDecoderDescription,
      kOsCrOS | kOsLacros,
      FEATURE_VALUE_TYPE(media::kUseChromeOSDirectVideoDecoder)},
-#if defined(ARCH_CPU_ARM_FAMILY)
+#endif  // BUILDFLAG(IS_CHROMEOS) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
+#if defined(USE_V4L2_CODEC)
     {"prefer-libyuv-image-processor",
      flag_descriptions::kPreferLibYuvImageProcessorName,
      flag_descriptions::kPreferLibYuvImageProcessorDescription,
      kOsCrOS | kOsLacros,
      FEATURE_VALUE_TYPE(media::kPreferLibYuvImageProcessor)},
 #endif  // defined(ARCH_CPU_ARM_FAMILY)
-#endif  // BUILDFLAG(IS_CHROMEOS) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
 
 #if BUILDFLAG(IS_ANDROID)
     {"force-startup-signin-promo",
--- a/src/chrome/common/chrome_switches.cc
+++ b/src/chrome/common/chrome_switches.cc
@@ -417,6 +417,9 @@ const char kPackExtensionKey[] = "pack-e
 // crashpad (or breakpad) is initialized.
 const char kPreCrashpadCrashTest[] = "pre-crashpad-crash-test";
 
+// Print the patch version and return
+const char kPiPatchVersion[] = "pi-patch-version";
+
 // Used to mock the response received from the Web Permission Prediction
 // Service. Used for testing.
 const char kPredictionServiceMockLikelihood[] =
--- a/src/chrome/common/chrome_switches.h
+++ b/src/chrome/common/chrome_switches.h
@@ -134,6 +134,7 @@ extern const char kOnTheFlyMhtmlHashComp
 extern const char kOpenInNewWindow[];
 extern const char kPackExtension[];
 extern const char kPackExtensionKey[];
+extern const char kPiPatchVersion[];
 extern const char kPreCrashpadCrashTest[];
 extern const char kPredictionServiceMockLikelihood[];
 extern const char kPreinstalledWebAppsDir[];
--- a/src/components/version_info/BUILD.gn
+++ b/src/components/version_info/BUILD.gn
@@ -14,6 +14,9 @@ static_library("version_info") {
   sources = [
     "version_info.cc",
     "version_info.h",
+    "pi_patch_version_info.cc",
+    "pi_patch_version_info.h",
+    "pi_patch_version_values.h",
   ]
 
   deps = [
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_info.cc
@@ -0,0 +1,11 @@
+#include "components/version_info/pi_patch_version_info.h"
+#include "components/version_info/pi_patch_version_values.h"
+
+namespace version_info {
+
+std::string GetPiPatchVersionString() {
+  return PI_PATCH_VERSION_STRING;
+}
+
+}  // namespace version_info
+
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_info.h
@@ -0,0 +1,12 @@
+#ifndef COMPONENTS_PI_PATCH_VERSION_INFO_VERSION_INFO_H_
+#define COMPONENTS_PI_PATCH_VERSION_INFO_VERSION_INFO_H_
+
+#include <string>
+
+namespace version_info {
+
+// Returns a string with the patch tag for our patches
+std::string GetPiPatchVersionString();
+
+}  // namespace version_info
+#endif  // COMPONENTS_VERSION_INFO_VERSION_INFO_H_
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_values.h
@@ -0,0 +1,2 @@
+// Pi patch version - generated by pi-util/settag.py
+#define PI_PATCH_VERSION_STRING "rpi_2.53"
--- a/src/content/renderer/render_thread_impl.cc
+++ b/src/content/renderer/render_thread_impl.cc
@@ -112,6 +112,7 @@
 #include "media/base/decoder_factory.h"
 #include "media/base/media.h"
 #include "media/base/media_switches.h"
+#include "media/gpu/buildflags.h"
 #include "media/media_buildflags.h"
 #include "media/renderers/default_decoder_factory.h"
 #include "media/video/gpu_video_accelerator_factories.h"
@@ -1039,7 +1040,7 @@ media::GpuVideoAcceleratorFactories* Ren
 
   const bool enable_video_decode_accelerator =
 
-#if BUILDFLAG(IS_LINUX)
+#if BUILDFLAG(IS_LINUX) && !BUILDFLAG(USE_V4L2_CODEC)
       base::FeatureList::IsEnabled(media::kVaapiVideoDecodeLinux) &&
 #else
       !cmd_line->HasSwitch(switches::kDisableAcceleratedVideoDecode) &&
--- a/src/media/base/media_switches.cc
+++ b/src/media/base/media_switches.cc
@@ -800,14 +800,6 @@ const base::Feature kUseChromeOSDirectVi
 const base::Feature kLimitConcurrentDecoderInstances{
     "LimitConcurrentDecoderInstances", base::FEATURE_ENABLED_BY_DEFAULT};
 
-#if defined(ARCH_CPU_ARM_FAMILY)
-// Some architectures have separate image processor hardware that
-// can be used by Chromium's ImageProcessor to color convert/crop/etc.
-// video buffers.  Sometimes it is more efficient/performant/correct
-// to use libYUV instead of the hardware to do this processing.
-const base::Feature kPreferLibYuvImageProcessor{
-    "PreferLibYUVImageProcessor", base::FEATURE_DISABLED_BY_DEFAULT};
-#endif  // defined(ARCH_CPU_ARM_FAMILY)
 #if BUILDFLAG(IS_CHROMEOS)
 // ChromeOS has one of two VideoDecoder implementations active based on
 // SoC/board specific configurations that are sent via command line flags. This
@@ -818,6 +810,14 @@ const base::Feature kUseAlternateVideoDe
     base::FEATURE_DISABLED_BY_DEFAULT};
 #endif  // BUILDFLAG(IS_CHROMEOS)
 #endif  // BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
+#if BUILDFLAG(USE_V4L2_CODEC)
+// Some architectures have separate image processor hardware that
+// can be used by Chromium's ImageProcessor to color convert/crop/etc.
+// video buffers.  Sometimes it is more efficient/performant/correct
+// to use libYUV instead of the hardware to do this processing.
+const base::Feature kPreferLibYuvImageProcessor{
+    "PreferLibYUVImageProcessor", base::FEATURE_DISABLED_BY_DEFAULT};
+#endif  // defined(ARCH_CPU_ARM_FAMILY)
 
 #if BUILDFLAG(IS_MAC)
 // Enable binding multiple shared images to a single GpuMemoryBuffer for
--- a/src/media/base/media_switches.h
+++ b/src/media/base/media_switches.h
@@ -14,6 +14,7 @@
 #include "build/build_config.h"
 #include "build/chromeos_buildflags.h"
 #include "media/base/media_export.h"
+#include "media/gpu/buildflags.h"
 #include "media/media_buildflags.h"
 
 namespace base {
@@ -242,13 +243,13 @@ MEDIA_EXPORT extern const base::Feature
 #if BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
 MEDIA_EXPORT extern const base::Feature kUseChromeOSDirectVideoDecoder;
 MEDIA_EXPORT extern const base::Feature kLimitConcurrentDecoderInstances;
-#if defined(ARCH_CPU_ARM_FAMILY)
-MEDIA_EXPORT extern const base::Feature kPreferLibYuvImageProcessor;
-#endif  // defined(ARCH_CPU_ARM_FAMILY)
 #if BUILDFLAG(IS_CHROMEOS)
 MEDIA_EXPORT extern const base::Feature kUseAlternateVideoDecoderImplementation;
 #endif  // BUILDFLAG(IS_CHROMEOS)
 #endif  // BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
+#if BUILDFLAG(USE_V4L2_CODEC)
+MEDIA_EXPORT extern const base::Feature kPreferLibYuvImageProcessor;
+#endif  // defined(ARCH_CPU_ARM_FAMILY)
 
 #if BUILDFLAG(IS_MAC)
 MEDIA_EXPORT extern const base::Feature kMultiPlaneVideoToolboxSharedImages;
--- a/src/media/capture/video/linux/video_capture_device_factory_linux.cc
+++ b/src/media/capture/video/linux/video_capture_device_factory_linux.cc
@@ -310,8 +310,25 @@ void VideoCaptureDeviceFactoryLinux::Get
       } else if (frame_size.type == V4L2_FRMSIZE_TYPE_STEPWISE ||
                  frame_size.type == V4L2_FRMSIZE_TYPE_CONTINUOUS) {
         // TODO(mcasas): see http://crbug.com/249953, support these devices.
-        NOTIMPLEMENTED_LOG_ONCE();
-        continue;
+//        NOTIMPLEMENTED_LOG_ONCE();
+//        continue;
+        // Kludge so we have some video
+        static const v4l2_frmsize_discrete sizes[] = {
+          {1280, 720},
+          {640, 360},
+          {320, 180}
+        };
+        for (const auto& size : sizes) {
+          supported_format.frame_size.SetSize(size.width, size.height);
+          const std::vector<float> frame_rates = GetFrameRateList(
+              fd, v4l2_format.pixelformat, size.width, size.height);
+          for (const auto& frame_rate : frame_rates) {
+            supported_format.frame_rate = frame_rate;
+            supported_formats->push_back(supported_format);
+            DVLOG(1) << VideoCaptureFormat::ToString(supported_format);
+          }
+        }
+        break;
       }
 
       const std::vector<float> frame_rates = GetFrameRateList(
--- a/src/media/gpu/BUILD.gn
+++ b/src/media/gpu/BUILD.gn
@@ -19,6 +19,7 @@ buildflag_header("buildflags") {
     "USE_VAAPI=$use_vaapi",
     "USE_VAAPI_IMAGE_CODECS=$use_vaapi_image_codecs",
     "USE_V4L2_CODEC=$use_v4l2_codec",
+    "USE_V4L2_CODEC_RPI=$use_v4l2_codec_rpi",
     "USE_LIBV4L2=$use_v4lplugin",
     "USE_VAAPI_X11=$use_vaapi_x11",
   ]
--- a/src/media/gpu/args.gni
+++ b/src/media/gpu/args.gni
@@ -25,6 +25,10 @@ declare_args() {
   # platforms which have v4l2 hardware encoder
   use_v4l2_codec_aml = false
 
+  # Indicates if this is V4L2 on RPi.  Only compiles stateful V4L2 code
+  # and removes all legacy codecs
+  use_v4l2_codec_rpi = false
+
   # Indicates if VA-API-based hardware acceleration is to be used. This
   # is typically the case on x86-based ChromeOS devices.
   # VA-API should also be compiled by default on x11-using linux devices
--- a/src/media/gpu/gpu_video_decode_accelerator_factory.cc
+++ b/src/media/gpu/gpu_video_decode_accelerator_factory.cc
@@ -29,7 +29,9 @@
 #include "ui/gl/gl_implementation.h"
 #elif BUILDFLAG(USE_V4L2_CODEC)
 #include "media/gpu/v4l2/v4l2_device.h"
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
 #include "media/gpu/v4l2/v4l2_slice_video_decode_accelerator.h"
+#endif
 #include "media/gpu/v4l2/v4l2_video_decode_accelerator.h"
 #include "ui/gl/gl_surface_egl.h"
 #endif
@@ -64,10 +66,12 @@ gpu::VideoDecodeAcceleratorCapabilities
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       V4L2VideoDecodeAccelerator::GetSupportedProfiles(),
       &capabilities.supported_profiles);
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       V4L2SliceVideoDecodeAccelerator::GetSupportedProfiles(),
       &capabilities.supported_profiles);
 #endif
+#endif
 #elif BUILDFLAG(IS_MAC)
   capabilities.supported_profiles =
       VTVideoDecodeAccelerator::GetSupportedProfiles(workarounds);
@@ -146,8 +150,10 @@ GpuVideoDecodeAcceleratorFactory::Create
     &GpuVideoDecodeAcceleratorFactory::CreateVaapiVDA,
 #elif BUILDFLAG(USE_V4L2_CODEC)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA,
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2SliceVDA,
 #endif
+#endif
 
 #if BUILDFLAG(IS_MAC)
     &GpuVideoDecodeAcceleratorFactory::CreateVTVDA,
@@ -207,6 +213,7 @@ GpuVideoDecodeAcceleratorFactory::Create
   return decoder;
 }
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
 std::unique_ptr<VideoDecodeAccelerator>
 GpuVideoDecodeAcceleratorFactory::CreateV4L2SliceVDA(
     const gpu::GpuDriverBugWorkarounds& /*workarounds*/,
@@ -222,6 +229,7 @@ GpuVideoDecodeAcceleratorFactory::Create
   return decoder;
 }
 #endif
+#endif
 
 #if BUILDFLAG(IS_MAC)
 std::unique_ptr<VideoDecodeAccelerator>
--- a/src/media/gpu/v4l2/BUILD.gn
+++ b/src/media/gpu/v4l2/BUILD.gn
@@ -28,9 +28,6 @@ source_set("v4l2") {
     "buffer_affinity_tracker.h",
     "generic_v4l2_device.cc",
     "generic_v4l2_device.h",
-    "v4l2_decode_surface.cc",
-    "v4l2_decode_surface.h",
-    "v4l2_decode_surface_handler.h",
     "v4l2_device.cc",
     "v4l2_device.h",
     "v4l2_device_poller.cc",
@@ -39,8 +36,6 @@ source_set("v4l2") {
     "v4l2_framerate_control.h",
     "v4l2_image_processor_backend.cc",
     "v4l2_image_processor_backend.h",
-    "v4l2_slice_video_decode_accelerator.cc",
-    "v4l2_slice_video_decode_accelerator.h",
     "v4l2_stateful_workaround.cc",
     "v4l2_stateful_workaround.h",
     "v4l2_utils.cc",
@@ -55,30 +50,42 @@ source_set("v4l2") {
     "v4l2_video_decoder_backend.h",
     "v4l2_video_decoder_backend_stateful.cc",
     "v4l2_video_decoder_backend_stateful.h",
-    "v4l2_video_decoder_backend_stateless.cc",
-    "v4l2_video_decoder_backend_stateless.h",
-    "v4l2_video_decoder_delegate_h264.cc",
-    "v4l2_video_decoder_delegate_h264.h",
-    "v4l2_video_decoder_delegate_h264_legacy.cc",
-    "v4l2_video_decoder_delegate_h264_legacy.h",
-    "v4l2_video_decoder_delegate_vp8.cc",
-    "v4l2_video_decoder_delegate_vp8.h",
-    "v4l2_video_decoder_delegate_vp8_legacy.cc",
-    "v4l2_video_decoder_delegate_vp8_legacy.h",
-    "v4l2_video_decoder_delegate_vp9.cc",
-    "v4l2_video_decoder_delegate_vp9.h",
-    "v4l2_video_decoder_delegate_vp9_legacy.cc",
-    "v4l2_video_decoder_delegate_vp9_legacy.h",
     "v4l2_video_encode_accelerator.cc",
     "v4l2_video_encode_accelerator.h",
   ]
 
+  if (!use_v4l2_codec_rpi) {
+    sources += [
+      "v4l2_decode_surface.cc",
+      "v4l2_decode_surface.h",
+      "v4l2_decode_surface_handler.h",
+
+      "v4l2_slice_video_decode_accelerator.cc",
+      "v4l2_slice_video_decode_accelerator.h",
+
+      "v4l2_video_decoder_backend_stateless.cc",
+      "v4l2_video_decoder_backend_stateless.h",
+      "v4l2_video_decoder_delegate_h264.cc",
+      "v4l2_video_decoder_delegate_h264.h",
+      "v4l2_video_decoder_delegate_h264_legacy.cc",
+      "v4l2_video_decoder_delegate_h264_legacy.h",
+      "v4l2_video_decoder_delegate_vp8.cc",
+      "v4l2_video_decoder_delegate_vp8.h",
+      "v4l2_video_decoder_delegate_vp8_legacy.cc",
+      "v4l2_video_decoder_delegate_vp8_legacy.h",
+      "v4l2_video_decoder_delegate_vp9.cc",
+      "v4l2_video_decoder_delegate_vp9.h",
+      "v4l2_video_decoder_delegate_vp9_legacy.cc",
+      "v4l2_video_decoder_delegate_vp9_legacy.h",
+    ]
+  }
+
   libs = [
     "EGL",
     "GLESv2",
   ]
 
-  if (use_v4l2_codec_aml) {
+  if (use_v4l2_codec_aml && !use_v4l2_codec_rpi) {
     sources += [
       "aml_v4l2_device.cc",
       "aml_v4l2_device.h",
@@ -155,6 +162,7 @@ source_set("unit_test") {
   ]
 }
 
+if (!use_v4l2_codec_rpi) {
 executable("v4l2_stateless_decoder") {
   testonly = true
   sources = [
@@ -178,3 +186,4 @@ executable("v4l2_stateless_decoder") {
     "//third_party/libgav1:libgav1",
   ]
 }
+}
--- a/src/media/gpu/v4l2/generic_v4l2_device.cc
+++ b/src/media/gpu/v4l2/generic_v4l2_device.cc
@@ -478,7 +478,11 @@ bool GenericV4L2Device::PostSandboxIniti
 }
 
 void GenericV4L2Device::EnumerateDevicesForType(Type type) {
+#if BUILDFLAG(USE_V4L2_CODEC_RPI)
+  static const std::string kDecoderDevicePattern = "/dev/video1";
+#else
   static const std::string kDecoderDevicePattern = "/dev/video-dec";
+#endif
   static const std::string kEncoderDevicePattern = "/dev/video-enc";
   static const std::string kImageProcessorDevicePattern = "/dev/image-proc";
   static const std::string kJpegDecoderDevicePattern = "/dev/jpeg-dec";
--- a/src/media/gpu/v4l2/v4l2_device.cc
+++ b/src/media/gpu/v4l2/v4l2_device.cc
@@ -28,6 +28,7 @@
 #include "media/base/bind_to_current_loop.h"
 #include "media/base/color_plane_layout.h"
 #include "media/base/video_types.h"
+#include "media/gpu/buildflags.h"
 #include "media/gpu/chromeos/fourcc.h"
 #include "media/gpu/chromeos/platform_video_frame_utils.h"
 #include "media/gpu/macros.h"
@@ -44,8 +45,10 @@ namespace media {
 
 namespace {
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
 // Maximum number of requests that can be created.
 constexpr size_t kMaxNumRequests = 32;
+#endif
 
 gfx::Rect V4L2RectToGfxRect(const v4l2_rect& rect) {
   return gfx::Rect(rect.left, rect.top, rect.width, rect.height);
@@ -591,8 +594,10 @@ bool V4L2WritableBufferRef::DoQueue(V4L2
   DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
   DCHECK(buffer_data_);
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   if (request_ref && buffer_data_->queue_->SupportsRequests())
     request_ref->ApplyQueueBuffer(&(buffer_data_->v4l2_buffer_));
+#endif
 
   bool queued = buffer_data_->QueueBuffer(std::move(video_frame));
 
@@ -853,7 +858,9 @@ void V4L2WritableBufferRef::SetConfigSto
   DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
   DCHECK(buffer_data_);
 
+#if defined(OS_CHROMEOS)
   buffer_data_->v4l2_buffer_.config_store = config_store;
+#endif
 }
 
 V4L2ReadableBuffer::V4L2ReadableBuffer(const struct v4l2_buffer& v4l2_buffer,
@@ -985,6 +992,7 @@ V4L2Queue::V4L2Queue(scoped_refptr<V4L2D
       weak_this_factory_(this) {
   DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   // Check if this queue support requests.
   struct v4l2_requestbuffers reqbufs;
   memset(&reqbufs, 0, sizeof(reqbufs));
@@ -1000,6 +1008,7 @@ V4L2Queue::V4L2Queue(scoped_refptr<V4L2D
     supports_requests_ = true;
     DVLOGF(4) << "Queue supports request API.";
   }
+#endif
 }
 
 V4L2Queue::~V4L2Queue() {
@@ -1541,23 +1550,34 @@ uint32_t V4L2Device::VideoCodecProfileTo
                                                    bool slice_based) {
   if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
     if (slice_based)
+#ifdef V4L2_PIX_FMT_H264_SLICE
       return V4L2_PIX_FMT_H264_SLICE;
+#else
+      /* EMPTY */;
+#endif
     else
       return V4L2_PIX_FMT_H264;
   } else if (profile >= VP8PROFILE_MIN && profile <= VP8PROFILE_MAX) {
     if (slice_based)
+#ifdef V4L2_PIX_FMT_VP8_FRAME
       return V4L2_PIX_FMT_VP8_FRAME;
+#else
+      /* EMPTY */;
+#endif
     else
       return V4L2_PIX_FMT_VP8;
   } else if (profile >= VP9PROFILE_MIN && profile <= VP9PROFILE_MAX) {
     if (slice_based)
+#ifdef V4L2_PIX_FMT_VP9_FRAME
       return V4L2_PIX_FMT_VP9_FRAME;
+#else
+      /* EMPTY */;
+#endif
     else
       return V4L2_PIX_FMT_VP9;
-  } else {
-    DVLOGF(1) << "Unsupported profile: " << GetProfileName(profile);
-    return 0;
   }
+  LOG(ERROR) << "Unknown profile: " << GetProfileName(profile);
+  return 0;
 }
 
 namespace {
@@ -1652,7 +1672,9 @@ std::vector<VideoCodecProfile> V4L2Devic
   std::vector<VideoCodecProfile> profiles;
   switch (pix_fmt) {
     case V4L2_PIX_FMT_H264:
+#ifdef V4L2_PIX_FMT_H264_SLICE
     case V4L2_PIX_FMT_H264_SLICE:
+#endif
       if (!get_supported_profiles(VideoCodec::kH264, &profiles)) {
         DLOG(WARNING) << "Driver doesn't support QUERY H264 profiles, "
                       << "use default values, Base, Main, High";
@@ -1664,11 +1686,15 @@ std::vector<VideoCodecProfile> V4L2Devic
       }
       break;
     case V4L2_PIX_FMT_VP8:
+#ifdef V4L2_PIX_FMT_VP8_FRAME
     case V4L2_PIX_FMT_VP8_FRAME:
+#endif
       profiles = {VP8PROFILE_ANY};
       break;
     case V4L2_PIX_FMT_VP9:
+#ifdef V4L2_PIX_FMT_VP9_FRAME
     case V4L2_PIX_FMT_VP9_FRAME:
+#endif
       if (!get_supported_profiles(VideoCodec::kVP9, &profiles)) {
         DLOG(WARNING) << "Driver doesn't support QUERY VP9 profiles, "
                       << "use default values, Profile0";
@@ -2129,6 +2155,7 @@ absl::optional<struct v4l2_event> V4L2De
   return event;
 }
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
 V4L2RequestsQueue* V4L2Device::GetRequestsQueue() {
   DCHECK_CALLED_ON_VALID_SEQUENCE(client_sequence_checker_);
 
@@ -2197,6 +2224,7 @@ V4L2RequestsQueue* V4L2Device::GetReques
 
   return requests_queue_.get();
 }
+#endif
 
 bool V4L2Device::IsCtrlExposed(uint32_t ctrl_id) {
   DCHECK_CALLED_ON_VALID_SEQUENCE(client_sequence_checker_);
@@ -2222,8 +2250,10 @@ bool V4L2Device::SetExtCtrls(uint32_t ct
   ext_ctrls.count = ctrls.size();
   ext_ctrls.controls = &ctrls[0].ctrl;
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   if (request_ref)
     request_ref->ApplyCtrls(&ext_ctrls);
+#endif
 
   const int result = Ioctl(VIDIOC_S_EXT_CTRLS, &ext_ctrls);
   if (result < 0) {
@@ -2284,6 +2314,8 @@ bool V4L2Device::SetGOPLength(uint32_t g
   return true;
 }
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
+
 class V4L2Request {
  public:
   V4L2Request(const V4L2Request&) = delete;
@@ -2562,4 +2594,6 @@ void V4L2RequestsQueue::ReturnRequest(V4
     free_requests_.push(request);
 }
 
+#endif
+
 }  //  namespace media
--- a/src/media/gpu/v4l2/v4l2_device.h
+++ b/src/media/gpu/v4l2/v4l2_device.h
@@ -26,6 +26,7 @@
 #include "media/base/video_decoder_config.h"
 #include "media/base/video_frame.h"
 #include "media/base/video_frame_layout.h"
+#include "media/gpu/buildflags.h"
 #include "media/gpu/chromeos/fourcc.h"
 #include "media/gpu/media_gpu_export.h"
 #include "media/gpu/v4l2/buffer_affinity_tracker.h"
@@ -55,6 +56,26 @@
 #define V4L2_PIX_FMT_MM21 v4l2_fourcc('M', 'M', '2', '1')
 #endif
 
+// Missing defines in the 5.4 linux/v4l2-controls.h
+#ifndef V4L2_CID_MPEG_VIDEO_VP8_PROFILE
+#define V4L2_CID_MPEG_VIDEO_VP8_PROFILE                 (V4L2_CID_MPEG_BASE+511)
+enum v4l2_mpeg_video_vp8_profile {
+  V4L2_MPEG_VIDEO_VP8_PROFILE_0 = 0,
+  V4L2_MPEG_VIDEO_VP8_PROFILE_1 = 1,
+  V4L2_MPEG_VIDEO_VP8_PROFILE_2 = 2,
+  V4L2_MPEG_VIDEO_VP8_PROFILE_3 = 3,
+};
+#endif
+#ifndef V4L2_CID_MPEG_VIDEO_VP9_PROFILE
+#define V4L2_CID_MPEG_VIDEO_VP9_PROFILE                 (V4L2_CID_MPEG_BASE+512)
+enum v4l2_mpeg_video_vp9_profile {
+  V4L2_MPEG_VIDEO_VP9_PROFILE_0 = 0,
+  V4L2_MPEG_VIDEO_VP9_PROFILE_1 = 1,
+  V4L2_MPEG_VIDEO_VP9_PROFILE_2 = 2,
+  V4L2_MPEG_VIDEO_VP9_PROFILE_3 = 3,
+};
+#endif
+
 namespace gfx {
 struct NativePixmapPlane;
 }  // namespace gfx
@@ -484,6 +505,7 @@ class MEDIA_GPU_EXPORT V4L2Queue
   base::WeakPtrFactory<V4L2Queue> weak_this_factory_;
 };
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
 class V4L2Request;
 
 // Base class for all request related classes.
@@ -601,6 +623,7 @@ class MEDIA_GPU_EXPORT V4L2RequestsQueue
 
   SEQUENCE_CHECKER(sequence_checker_);
 };
+#endif
 
 class MEDIA_GPU_EXPORT V4L2Device
     : public base::RefCountedThreadSafe<V4L2Device> {
@@ -773,9 +796,11 @@ class MEDIA_GPU_EXPORT V4L2Device
   // Attempt to dequeue a V4L2 event and return it.
   absl::optional<struct v4l2_event> DequeueEvent();
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   // Returns requests queue to get free requests. A null pointer is returned if
   // the queue creation failed or if requests are not supported.
   V4L2RequestsQueue* GetRequestsQueue();
+#endif
 
   // Check whether the V4L2 control with specified |ctrl_id| is supported.
   bool IsCtrlExposed(uint32_t ctrl_id);
@@ -824,8 +849,10 @@ class MEDIA_GPU_EXPORT V4L2Device
   // Indicates whether the request queue creation has been tried once.
   bool requests_queue_creation_called_ = false;
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   // The request queue stores all requests allocated to be used.
   std::unique_ptr<V4L2RequestsQueue> requests_queue_;
+#endif
 
   SEQUENCE_CHECKER(client_sequence_checker_);
 };
--- a/src/media/gpu/v4l2/v4l2_video_decode_accelerator.cc
+++ b/src/media/gpu/v4l2/v4l2_video_decode_accelerator.cc
@@ -1192,6 +1192,26 @@ bool V4L2VideoDecodeAccelerator::FlushIn
   return (decoder_state_ != kError);
 }
 
+void V4L2VideoDecodeAccelerator::CheckResolutionChangePending() {
+  struct v4l2_format format;
+  gfx::Size visible_size;
+  bool again;
+  GetFormatInfo(&format, &visible_size, &again);
+  gfx::Size new_coded(format.fmt.pix_mp.width, format.fmt.pix_mp.height);
+  if (resolution_change_pending_) {
+    if (coded_size_ == new_coded) {
+      LOG(INFO) << __func__ << ": New resolution " << new_coded.ToString() << " == Old resolution: Cancel change";
+      resolution_change_pending_ = false;
+    }
+  } else {
+    if (coded_size_ != new_coded) {
+      LOG(INFO) << __func__ << ": New resolution " << new_coded.ToString() <<
+        "!= Old resolution: " << coded_size_.ToString() << " Start change";
+      resolution_change_pending_ = true;
+    }
+  }
+}
+
 void V4L2VideoDecodeAccelerator::ServiceDeviceTask(bool event_pending) {
   DVLOGF(4);
   DCHECK(decoder_thread_.task_runner()->BelongsToCurrentThread());
@@ -1215,11 +1235,11 @@ void V4L2VideoDecodeAccelerator::Service
     return;
   }
 
-  bool resolution_change_pending = false;
+  resolution_change_pending_ = false;
   if (event_pending)
-    resolution_change_pending = DequeueResolutionChangeEvent();
+    resolution_change_pending_ = DequeueResolutionChangeEvent();
 
-  if (!resolution_change_pending && coded_size_.IsEmpty()) {
+  if (!resolution_change_pending_ && coded_size_.IsEmpty()) {
     // Some platforms do not send an initial resolution change event.
     // To work around this, we need to keep checking if the initial resolution
     // is known already by explicitly querying the format after each decode,
@@ -1232,11 +1252,15 @@ void V4L2VideoDecodeAccelerator::Service
     gfx::Size visible_size;
     bool again;
     if (GetFormatInfo(&format, &visible_size, &again) && !again) {
-      resolution_change_pending = true;
+      resolution_change_pending_ = true;
       DequeueResolutionChangeEvent();
     }
   }
 
+  if (resolution_change_pending_) {
+    LOG(INFO) << "Resolution change pending";
+  }
+
   Dequeue();
   Enqueue();
 
@@ -1278,7 +1302,7 @@ void V4L2VideoDecodeAccelerator::Service
             << buffers_at_client_.size() << "]";
 
   ScheduleDecodeBufferTaskIfNeeded();
-  if (resolution_change_pending)
+  if (resolution_change_pending_)
     StartResolutionChange();
 }
 
@@ -1561,8 +1585,11 @@ bool V4L2VideoDecodeAccelerator::Enqueue
   }
 
   if (!ret) {
-    LOG(ERROR) << "Error in Dequeue output buffer";
-    NOTIFY_ERROR(PLATFORM_FAILURE);
+    CheckResolutionChangePending();
+    if (!resolution_change_pending_) {
+      LOG(ERROR) << "Error in Enqueue output buffer";
+      NOTIFY_ERROR(PLATFORM_FAILURE);
+    }
     return false;
   }
 
@@ -1723,7 +1750,7 @@ bool V4L2VideoDecodeAccelerator::IsDecod
   memset(&cmd, 0, sizeof(cmd));
   cmd.cmd = V4L2_DEC_CMD_STOP;
   if (device_->Ioctl(VIDIOC_TRY_DECODER_CMD, &cmd) != 0) {
-    VLOGF(2) "V4L2_DEC_CMD_STOP is not supported.";
+    VLOGF(2) << "V4L2_DEC_CMD_STOP is not supported.";
     return false;
   }
 
--- a/src/media/gpu/v4l2/v4l2_video_decode_accelerator.h
+++ b/src/media/gpu/v4l2/v4l2_video_decode_accelerator.h
@@ -274,6 +274,9 @@ class MEDIA_GPU_EXPORT V4L2VideoDecodeAc
                       int32_t picture_buffer_id,
                       EGLImageKHR egl_image);
 
+
+  void CheckResolutionChangePending();
+
   // Service I/O on the V4L2 devices.  This task should only be scheduled from
   // DevicePollTask().  If |event_pending| is true, one or more events
   // on file descriptor are pending.
@@ -579,6 +582,9 @@ class MEDIA_GPU_EXPORT V4L2VideoDecodeAc
   // The number of pictures that are sent to PictureReady and will be cleared.
   int picture_clearing_count_;
 
+  // We've spotted that we need a res change
+  bool resolution_change_pending_;
+
   // Output picture coded size.
   gfx::Size coded_size_;
 
--- a/src/media/gpu/v4l2/v4l2_video_decoder.cc
+++ b/src/media/gpu/v4l2/v4l2_video_decoder.cc
@@ -18,6 +18,7 @@
 #include "media/base/media_switches.h"
 #include "media/base/video_types.h"
 #include "media/base/video_util.h"
+#include "media/gpu/buildflags.h"
 #include "media/gpu/chromeos/chromeos_status.h"
 #include "media/gpu/chromeos/dmabuf_video_frame_pool.h"
 #include "media/gpu/chromeos/fourcc.h"
@@ -28,7 +29,9 @@
 #include "media/gpu/macros.h"
 #include "media/gpu/v4l2/v4l2_status.h"
 #include "media/gpu/v4l2/v4l2_video_decoder_backend_stateful.h"
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
 #include "media/gpu/v4l2/v4l2_video_decoder_backend_stateless.h"
+#endif
 
 namespace media {
 
@@ -46,8 +49,17 @@ constexpr size_t kNumInputBuffers = 8;
 
 // Input format V4L2 fourccs this class supports.
 constexpr uint32_t kSupportedInputFourccs[] = {
-    V4L2_PIX_FMT_H264_SLICE, V4L2_PIX_FMT_VP8_FRAME, V4L2_PIX_FMT_VP9_FRAME,
-    V4L2_PIX_FMT_H264,       V4L2_PIX_FMT_VP8,       V4L2_PIX_FMT_VP9,
+#ifdef V4L2_PIX_FMT_H264_SLICE
+    V4L2_PIX_FMT_H264_SLICE,
+#endif
+#ifdef V4L2_PIX_FMT_VP8_FRAME
+    V4L2_PIX_FMT_VP8_FRAME,
+#endif
+#ifdef V4L2_PIX_FMT_VP9_FRAME
+    V4L2_PIX_FMT_VP9_FRAME,
+#endif
+    V4L2_PIX_FMT_H264,       V4L2_PIX_FMT_VP8,
+    V4L2_PIX_FMT_VP9,
 };
 
 // Number of output buffers to use for each VD stage above what's required by
@@ -323,12 +335,17 @@ V4L2Status V4L2VideoDecoder::InitializeB
     backend_ = std::make_unique<V4L2StatefulVideoDecoderBackend>(
         this, device_, profile_, color_space_, decoder_task_runner_);
   } else {
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
     DCHECK_EQ(preferred_api_and_format.first, kStateless);
     VLOGF(1) << "Using a stateless API for profile: "
              << GetProfileName(profile_)
              << " and fourcc: " << FourccToString(input_format_fourcc);
     backend_ = std::make_unique<V4L2StatelessVideoDecoderBackend>(
         this, device_, profile_, color_space_, decoder_task_runner_);
+#else
+    VLOGF(1) << "No backend capable of taking this profile.";
+    return V4L2Status::Codes::kFailedResourceAllocation;
+#endif
   }
 
   if (!backend_->Initialize()) {
--- a/src/media/mojo/services/gpu_mojo_media_client_cros.cc
+++ b/src/media/mojo/services/gpu_mojo_media_client_cros.cc
@@ -62,6 +62,10 @@ VideoDecoderType GetActualPlatformDecode
     const gpu::GPUInfo& gpu_info) {
 #if BUILDFLAG(IS_CHROMEOS)
   return GetPreferredCrosDecoderImplementation(gpu_preferences);
+#elif BUILDFLAG(USE_V4L2_CODEC_RPI)
+  // Kludge for RPI to enable h/w decode - V4L2 decode isn't selected
+  // with the normal logic
+  return VideoDecoderType::kVda;
 #else
   // On linux, VDA and Vaapi have GL restrictions.
   switch (GetPreferredLinuxDecoderImplementation(gpu_preferences, gpu_info)) {
--- /dev/null
+++ b/src/pi-util/BUILD.txt
@@ -0,0 +1,250 @@
+Build notes (cross compile from Ubuntu)
+=======================================
+
+Build from a patch
+------------------
+
+# Pick somewhere to put this
+cd ~
+mkdir chromium
+cd chromium
+# Get the build tools & put on path
+# You may want to add the path in .bashrc
+git clone https://chromium.googlesource.com/chromium/tools/depot_tools
+export PATH=$PATH:`pwd`/depot_tools
+# Get the main tree
+fetch chromium
+cd src
+# Checkout the version you want
+# * Fix version number
+git checkout 55.0.2883.99
+# Fix up any missing dependancies on the build m/c
+# * may well be unnecessary if you have built any other chrome
+./build/install-build-deps.sh
+./build/install-build-deps.sh --arm
+# Fetch & pull the other bits of the tree to sync.
+# As we are checking out a tag the --with_branch_heads is important
+gclient sync --with_branch_heads
+# Patch - should be completely clean if everything matchs
+# * Fix patch file to correct name / location
+cd ..
+patch -p1 < v55.0.2883.99.patch
+cd src
+# * Get a sysroot from somewhere and put it in build/linux/raspian_jessie_pi1-sysroot
+# * Example below is only if you have got an appropriate one lying around
+# * Otherwise follow sysroot instructions further down
+rsync -rl previous_location/raspian_jessie_pi1-sysroot build/linux/
+# Build output directories (out/armv6, out/armv7)
+# * This script currently assumes a sysroot of build/linux/raspian_jessie_pi1-sysroot
+#   so may need editing if you have put it elsewhere
+pi-util/gngen.py
+# Build chrome
+ninja -C out/armv6 chrome chrome_sandbox
+# Build armv7 ffmpeg
+ninja -C out/armv7 third_party/ffmpeg
+
+
+To run on a Pi
+--------------
+
+This requires a little installation.  The sandbox and ffmpeg shared libs
+need to be copied to the pi.  As neither is being tweaked much by me these
+steps should only be required if the underlying Chrome changes.  Otherwise
+you can just run out of the build directory (src/out/armv6)
+
+Assuming you can mount the build dir from the pi.
+
+# On the Pi NOT the build machine
+cd <path to build env>/src
+# Copy the ffmpeg libs
+pi-util/cplibs.sh
+# Copy the sandbox. BUILDTYPE tells the script where to get it from
+# This doesn't seem to be needed anymore with linux 4.9 and chrome 55
+BUILDTYPE=armv6 build/update-linux-sandbox.sh
+# Run chrome
+cd out/armv6
+./chrome
+
+
+Rebuilds
+--------
+
+In most cases a simple "ninja -C out/armv6 chrome" is all that is needed
+and the pi can run from out/armv6.
+
+To clean build "rm -rf out" and follow the build instructions from gngen.py
+
+
+Updating chromium from git
+--------------------------
+
+There is no script for this as the merges are prone to conflicts and it
+is much easier to sort them if you are doing stuff manually.
+
+If updating between major versions then mergeing tends to fail horribly
+so something along the lines of:
+
+# Remember where we are
+cat pi-util/pipaths.py
+OLDTAG=103...
+
+# Look for where we are going
+git tag -l "104.*"
+TAG=104...
+
+# * Make sure there are no updates required and no untracked files
+pi-util/gitscan.py status
+# Set rename limit to huge as files are moved around frequently and getting
+# git to track them is much easier than trying to do it ourselves
+git config diff.renameLimit 1000000
+
+# Tag source & make a patch file - patch file is useful when files are moved
+# as then git goes all unhelpful
+pi-util/dodiff.py > ../v${OLDTAG}_stash.patch
+# As git stash will reset the branch switch to a temp branch 1st
+pi-util/gitscan.py checkout -b stash/103/base
+pi-util/gitscan.py --gitscan-no-src reset {BASE}
+pi-util/gitscan.py --gitscan-no-src stash -u
+pi-util/gitscan.py --gitscan-no-src checkout {BASE}
+
+# Need to do src separately as the stash will lose pi-utils
+git reset $OLDTAG
+git stash -u
+
+git checkout $TAG -b test/103/rpi_2
+
+# Clean out old objects
+rm -rf out
+# Beware that git clean might kill our sub-repos so so don't do it unless we
+# are sure it won't
+# git clean -dxf
+
+### Do the "get environment" stages of a new build
+./build/install-build-deps.sh
+./build/install-build-deps.sh --arm
+# Fetch & pull the other bits of the tree to sync.
+# As we are checking out a tag the --with_branch_heads is important
+gclient sync -D --with_branch_heads
+
+# Start rebuild
+git stash pop
+
+# Fix pipaths & make new branches (now so we don't forget later)
+sed "s/src_commit=.*/src_commit=\"$TAG\"/" pi-util/pipaths.py | tee t
+mv t pi-util/pipaths.py && git add pi-util/pipaths.py
+chmod 0755 pi-util/*.py pi-util/*.sh
+pi-util/gitscan.py --gitscan-no-src checkout -b test/104/rpi_2
+
+# If running with filemode false then readd pi-util with filemode true
+git config core.filemode true
+git add pi-util
+git config core.filemode false
+
+
+### Fix conflicts (there will be some)
+
+# If building a separated ffmpeg .so (we are not not currrently) then
+# fix chrome major version for ffmpeg .so in pi-util/cplibs.sh and third_party/ffmpeg/BUILD.gn
+
+git commit
+### run through all other dirs we care about doing the same
+### Probably need to fix exec perms on pi-util scripts
+pi-util/rootgen.sh
+pi-util/gngen.py
+### Fix up any new libpackage-dev that we need
+ninja ...
+### Fix up build disasters
+
+
+If updating within a major version mergeing seems to work reliably so my
+preferred method for achieving this goes:
+
+# Make sure everything is committed
+pi-util/gitscan.py status
+# Revert to base chromium checkout for old checkout
+pi-util/gitscan.py --gitscan-no-src checkout {BASE}
+# Merge new version into current base
+git fetch --all
+TAG=<new_tag>
+git merge $TAG
+# Fix conflicts - DEPS always seems to conflict
+git checkout $TAG -- DEPS
+# Update pi-util/pipaths.py to contain the new tag
+# Either commit now or later
+sed "s/src_commit=.*/src_commit=\"$TAG\"/" pi-util/pipaths.py | tee t
+mv t pi-util/pipaths.py && git add pi-util/pipaths.py
+git commit --no-edit
+# Get the rest of the tree
+gclient sync --with_branch_heads
+# Checkout our tree and merge the new base into it
+pi-util/gitscan.py --gitscan-no-src checkout test/104/rpi_2
+pi-util/gitscan.py --gitscan-no-src merge --no-edit {BASE}
+
+and we should be good to go.  At this point you can either clean build or
+not.  Chromes dependancy checks seem remarkably good so a simple build
+works nearly all the time.
+
+# Rebuild from clean
+rm -rf out
+# refetch root (optional)
+pi-util/rootgen.sh
+# Configure
+pi-util/gngen.py
+# Build release armv7 chrome (and any other targets you feel like)
+ninja -C out/armv7-rel chrome
+
+
+Sysroots (one time only)
+------------------------
+
+1st you will need to get the dev files for a bunch of libs on your pi (or
+if you can get the right files by magic on your cross-compile m/c then
+that is good too).  In src/pi-util there is a shell script
+pi-install-dev.sh which lists all the libs I think are needed along with a
+helpful apt-get install so all you should need to do is run it on an
+appropriate pi.
+
+Next the appropriate bits need to be copied to
+build/linux/<sysroot-name>-sysroot. We use raspian_stretch_pi1 as the
+sysroot name in these instructions and in the example script files so you
+might well find it easiest to use the same name too
+
+The script pi-util/syncroot.sh that will copy the needed bits of a root to
+the right place and then fix the full path symlinks to be relative.  It
+uses rsync to copy the files so the src can contain a machine name
+
+pi-util/syncroot.sh my-pi: raspian_stretch_pi1
+
+The "raspian_stretch_pi1" can be omitted and syncroot will choose the current
+default sysroot name.
+
+Beware that there are ~8 rsync statements so if the rsync is operating
+over ssh then you may need to type your password 8 times...  Note also
+that the script appends -sysroot to the given name so don't add that
+yourself!
+
+If the pi root is updated then this script can / should be rerun to update
+the sysroot.
+
+
+
+Other notes on the tree
+-----------------------
+
+The definitive list of expected repos is in pi-util/pipaths.py
+
+The script pi-util/gitscan.py will perform the same git op on all the
+repos that are in use in the current patch set.  It has substitutions
+of {PATH} and {BASE} for the path to the current repo and the chromium
+commit on which the current branch is based
+
+The current dev branch is test/57/mmal_2
+
+Status of optional neon by build file:
+skia/BUILD.gn:                     yes
+build/secondary/third_party/libjpeg_turbo/BUILD.gn: yes
+third_party/libwebp/BUILD.gn:      yes
+third_party/openmax_dl/dl/BUILD.gn unused
+third_party/libyuv/BUILD.gn:       yes
+third_party/libyuv/libyuv.gni:     yes
+third_party/pdfium/skia/BUILD.gn:  unused
--- /dev/null
+++ b/src/pi-util/README.txt
@@ -0,0 +1,118 @@
+Release notes
+=============
+
+This version should run with gpu-mem=64 with the default switches. Having
+said that this will only allow for 1 stream.  If you are playing >1 stream
+(even transiently) then you will need more (say gpu_mem=128) and you will
+need to set the --mmal-decoders option to the desired max number. The code
+should give up cleanly if it cannot allocate a h/w video decoder and give
+the stream to old-style ffmpeg decode, but as it stands in many cases it
+thinks it has allocated a decoder cleanly only to find that it fails when
+it tries to use it.
+
+Needs a current (buster 2019-06-07+) firmware/userland
+
+There are a few command-line switches - in general you shouldn't use
+them!
+
+
+Decode and resizer options
+--------------------------
+
+--mmal-decode-opaque     Set the decoder to use opaque frames between
+decoder and resizer.  This should be faster than i420 but doesn't work
+with old firmware.  This is the default with newer firmware (>=
+2016-11-01). (see --mmal-decode-i420)
+
+--mmal-decode-i420       Set the decoder to use I420 frames between
+decoder and resizer.  This generates an unnecessary conversion but works
+with all firmware.  This is the default with older firmware (<
+2016-11-01). (see --mmal-decode-opaque)
+
+--mmal-low-delay         Force "low-delay" mode on the decoder pipe.  This
+reduces the number of buffered ES frames before the decoder.  It isn't
+exactly low-delay but is definitely lower than otherwise.  May have a
+slight performance penalty and increase the risk of stuttering.  This mode
+will be automatically set by Chrome for some streams.
+
+--mmal-resize-isp        Use ISP resize rather than resizer.  Is noticably
+faster but requires --mmal-frame-copy or --mmal-zero-copy and newer
+firmware.  This is the default with newer firmware  (>= 2016-11-01) and
+enough gpu memory to support --mmal-frame-copy.
+
+--mmal-resize-resizer    Use resizer rather than ISP. Slower than ISP
+resize but supports older firmware and --mmal-slice-copy which may be
+needed if GPU memory is very limited (as will be the case on a Pi1 with a
+default setup).
+
+--mmal-resize-mode=NEVER|ALWAYS|SMALLER
+Sets resize behaviour.
+  NEVER    Output is the native size of the video
+  ALWAYS   Output allways attempts to match the size of the displayed picture
+           This is normally the fastest mode for SHM-RGB copy
+  SMALLER  Resize to smaller of native & display. This saves memory and is
+           the fastest for EGL output
+
+
+Copy-modes
+----------
+
+--mmal-copy-mode=<copy mode>
+
+This sets the output frame type & mmal->chrome copy mode. Current values
+for <copy mode> are:
+
+slice                   slowest - uses only a small amount of memory
+                        in the resizer
+
+<alloc>-<format>-<copy>
+  <alloc>
+    SHM      Frame allocated from shared memory
+    GPU      Frame allocated from gpu memory
+  <format>
+    YUV      3-plane I420
+    YC       2-plane I420 e.g. NV12
+    RGB      1-plane 4-byte RGBX
+  <copy>
+    COPY     Data copied on the ARM.  This should be slower than DMA but
+             sometimes give more performance at the expense of slightly
+	     higher ARM CPU usage
+    DMA      Data copied by firmware DMA to ARM buffers.
+    ZC       Data put directly into GPU buffer.  Fastest - only works
+             with EGL (needs vcsm-cma).
+
+Currently valid combinations are:
+
+SHM-YUV-DMA
+SHM-YC-DMA
+SHM-RGB-DMA
+SHM-RGB-COPY  Default for non-gpu operation
+GPU-RGB-DMA
+GPU-RGB-ZC
+GPU-YUV-COPY
+GPU-YUV-ZC    Default for EGL operation
+
+
+Misc options
+------------
+
+--enable-logging=stderr This is a standard option for chrome but worth
+noting as the mmal code will print out its interpretation of the command
+line options passed to it along with how much GPU memory it has detected
+and the firmware date.
+
+--pi-patch-version       Print out the versions of Chromium and Pi
+patches.  Chrome will then terminate
+
+--mmal-decoders=<n>      Set the number of mmal decoders we wil try to
+create simultainiously. Default=1. If this number is exceeded then decoder
+init will fail and chrome will fallback to ffmpeg decode.  There is no
+panalty for setting this to a large number if you wish to have "unlimited"
+decoders.  However if it is set too big and there isn't the gpu mem to
+satisfy the requirements of the decode it may fail cleanly and revert to
+software (ffmpeg) decode or init may appear to succeed and decode then
+fails in an undefined manner.
+
+--mmal-frame-buffers=<n> Set the number of gpu "frame" buffers.
+Change with care.
+
--- /dev/null
+++ b/src/pi-util/cpbuild.sh
@@ -0,0 +1,31 @@
+set -e
+if [ "$2" == "" ]; then
+  echo "mkzip <zipname> <out/dir>"
+  exit 1
+fi
+
+BASEDIR=`pwd`
+TMPBASE=$BASEDIR/out/tmp
+TMPDIRNAME=$1
+ZIPFILE=$1.zip
+OUTDIR=$BASEDIR/$2
+
+cd $OUTDIR
+D=$TMPBASE/$TMPDIRNAME
+rm -rf $D
+mkdir -p $D
+
+echo "=== Copying"
+cp -r * $D
+cd $D
+
+echo "=== Clean unwanted"
+find . -name obj -exec rm -rf {} +
+rm -rf gen clang_*
+rm -rf *.TOC *_deps *.zip core-* bin test_* toolchain.ninja third_party tools
+cd $TMPBASE
+
+echo "=== Zipping"
+zip -r -q $ZIPFILE $TMPDIRNAME
+
+echo "=== Done: $TMPBASE/$ZIPFILE"
--- /dev/null
+++ b/src/pi-util/cplibs.sh
@@ -0,0 +1,19 @@
+set -e
+
+FFNAME=libffmpeg_chrome.so.66
+LIBROOT=/usr/lib/arm-linux-gnueabihf
+
+if [ ! -d $LIBROOT ]; then
+  echo Can\'t find $LIBROOT
+  echo Are you sure you are running this on a Pi?
+  exit 1
+fi
+
+echo Copying $FFNAME from armv6/7 to $LIBROOT/...
+
+cp out/armv7/$FFNAME /tmp
+sudo cp /tmp/$FFNAME $LIBROOT/neon/vfp
+cp out/armv6/$FFNAME /tmp
+sudo cp /tmp/$FFNAME $LIBROOT
+
+
--- /dev/null
+++ b/src/pi-util/defargs_arm64-bullseye.gn
@@ -0,0 +1,16 @@
+# Build arguments go here. Examples:
+#   is_component_build = true
+#   is_debug = false
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm64"
+target_os = "linux"
+
+# Enables screen sharing in hangouts
+enable_hangout_services_extension = true
+
+# We have issues with the lib for this & it is probably for unittest only
+use_gnome_keyring = false
+
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
+
--- /dev/null
+++ b/src/pi-util/defargs_arm64.gn
@@ -0,0 +1,21 @@
+# Build arguments go here. Examples:
+#   is_component_build = true
+#   is_debug = false
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm64"
+target_os = "linux"
+
+# We don't actually need this - v4l2 will do better (auto-set by gngen)
+media_use_mmal = false
+
+# Enables screen sharing in hangouts
+enable_hangout_services_extension = true
+
+# We have issues with the lib for this & it is probably for unittest only
+use_gnome_keyring = false
+# Buster pipewire is too early
+rtc_use_pipewire = false
+
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
+
--- /dev/null
+++ b/src/pi-util/defargs_armv6-bullseye.gn
@@ -0,0 +1,21 @@
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm"
+target_os = "linux"
+
+arm_float_abi = "hard"
+arm_use_neon = false
+arm_optionally_use_neon = false
+arm_version = 6
+arm_use_thumb = false
+arm_arch = "armv6z"
+
+# We want H.264 in ffmpeg
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
+
+# We have issues with the lib for this & it is probably for unittest only
+use_gnome_keyring = false
+
+# This crashes the compiler!
+#rtc_use_h264 = false
+
--- /dev/null
+++ b/src/pi-util/defargs_armv6.gn
@@ -0,0 +1,35 @@
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm"
+target_os = "linux"
+
+arm_float_abi = "hard"
+arm_use_neon = false
+arm_optionally_use_neon = false
+arm_version = 6
+arm_use_thumb = false
+arm_arch = "armv6z"
+
+media_use_mmal = true
+
+# Separate out so we can have both arm v6 & v7 versions
+#is_component_ffmpeg = true
+
+# tcmalloc doesn't like armv6 by default
+#use_allocator = "none"
+
+# Could use system libjpeg but go with chromiums version
+# use_system_libjpeg = true
+#use_libjpeg_turbo = true
+
+# We have issues with the lib for this & it is probably for unittest only
+use_gnome_keyring = false
+# Buster pipewire is too early
+rtc_use_pipewire = false
+
+# We want H.264 in ffmpeg
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
+
+# This crashes the compiler!
+rtc_use_h264 = false
+
--- /dev/null
+++ b/src/pi-util/defargs_armv7-bullseye.gn
@@ -0,0 +1,25 @@
+# Build arguments go here. Examples:
+#   is_component_build = true
+#   is_debug = false
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm"
+target_os = "linux"
+
+arm_float_abi = "hard"
+arm_use_neon = true
+# We have lib issues if we enable thumb
+arm_use_thumb = false
+arm_optionally_use_neon = false
+arm_version = 7
+arm_arch = "armv7-a"
+
+enable_widevine = true
+
+# Enables screen sharing in hangouts
+enable_hangout_services_extension = true
+
+# We have issues with the lib for this & it is probably for unittest only
+use_gnome_keyring = false
+
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
--- /dev/null
+++ b/src/pi-util/defargs_armv7.gn
@@ -0,0 +1,31 @@
+# Build arguments go here. Examples:
+#   is_component_build = true
+#   is_debug = false
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm"
+target_os = "linux"
+
+arm_float_abi = "hard"
+arm_use_neon = true
+# We have lib issues if we enable thumb
+arm_use_thumb = false
+arm_optionally_use_neon = false
+arm_version = 7
+arm_arch = "armv7-a"
+
+media_use_mmal = true
+enable_widevine = true
+
+# Enables screen sharing in hangouts
+enable_hangout_services_extension = true
+
+# We have issues with the lib for this & it is probably for unittest only
+use_gnome_keyring = false
+# Buster pipewire is too early
+rtc_use_pipewire = false
+
+#is_component_ffmpeg = true
+# tcmalloc doesn't like armv6 by default
+#use_allocator = "none"
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
--- /dev/null
+++ b/src/pi-util/dodiff.py
@@ -0,0 +1,35 @@
+#!/usr/bin/env python3
+
+import os, sys, string, subprocess
+
+# Local
+import gitscan, pipaths
+
+def doscan(outfile = sys.stdout):
+    revdict = gitscan.revdict()
+
+    cpath = gitscan.basepath()
+
+    for p in pipaths.pipaths:
+        os.chdir(os.path.join(cpath, p))
+        diff = subprocess.check_output(["git", "diff", revdict[p]], text=True)
+
+        header = False
+        lines = diff.split("\n")
+        # Remove terminal blank line
+        if lines[-1] == "":
+            lines.pop()
+        for line in lines:
+            if line.startswith("diff --git "):
+                header = True
+            if header:
+                line = line.replace(" a/", " a/" + p + "/")
+                line = line.replace(" b/", " b/" + p + "/")
+            if line.startswith("+++ "):
+                header = False
+            print(line, file=outfile)
+
+
+if __name__ == '__main__':
+    doscan()
+
--- /dev/null
+++ b/src/pi-util/gitscan.py
@@ -0,0 +1,69 @@
+#!/usr/bin/env python3
+
+import os, string, subprocess, sys
+
+# Local
+import pipaths
+
+def revdict():
+    revdict = {'src':pipaths.src_commit}
+    stuff = subprocess.check_output(["gclient", "revinfo"], text=True)
+    for line in stuff.split("\n"):
+        pathn = line.find(":")
+        commitn = line.rfind("@")
+        if pathn != -1 and commitn != -1 :
+             revdict[line[:pathn]] = line[commitn+1:]
+    return revdict
+
+def basepath():
+    cpath = os.getcwd()
+    if not cpath.endswith("/src"):
+        raise "CWD doesn't end with /src"
+
+    return cpath[:-4]
+
+def gitscan(args, nosrc = False, quiet=False):
+    rv = 0
+
+    oldcwd = os.getcwd()
+    rdict = revdict()
+    cpath = basepath()
+
+    for p in pipaths.pipaths:
+        if nosrc and p == "src":
+            continue
+
+        os.chdir(os.path.join(cpath, p))
+
+        gitargs = [a.replace("{PATH}", p).replace("{BASE}", rdict[p]) for a in args]
+        gitargs[0:0] = ["git"]
+
+        if not quiet:
+            print(">>>", p)
+
+        rv = subprocess.call(gitargs)
+        if rv != 0:
+            if not quiet:
+                print("Git returned non-zero error code", rv, "\ncwd =", os.getcwd(), "\ncmd =", gitargs)
+            break
+
+    os.chdir(oldcwd)
+    return rv
+
+
+if __name__ == '__main__':
+
+    if len(sys.argv) < 2:
+        print("Usage: gitscan [--gitscan-no-src] <git cmd>")
+        print("  substitutes {PATH} and {BASE}")
+        exit(0)
+
+    nosrc = False
+
+    if sys.argv[1] == "--gitscan-no-src":
+        nosrc = True
+        del sys.argv[1]
+
+    gitscan(sys.argv[1:], nosrc)
+
+
--- /dev/null
+++ b/src/pi-util/gngen.py
@@ -0,0 +1,72 @@
+#!/usr/bin/env python3
+
+import os, ast, fileinput, subprocess, sys
+
+def docopy(name, vars, is_debug=False, is_ozone=False):
+    dir_suffix = ""
+    deb_str = "false"
+
+    if is_ozone:
+        ozone_str = "true"
+        dir_suffix = dir_suffix + "-ozone"
+    else:
+        ozone_str = "false"
+
+    if is_debug:
+        deb_str = "true"
+        dir_suffix = dir_suffix + "-deb"
+    else:
+        deb_str = "false"
+        dir_suffix = dir_suffix + "-rel"
+
+
+    dest_dir = os.path.join("out", name + dir_suffix)
+    src_file = os.path.join("pi-util", "defargs_" + name + ".gn")
+
+    # Ignore any errors making dir (in particular it already exists)
+    try:
+        os.makedirs(dest_dir)
+    except:
+        pass
+
+    dargs = open(os.path.join(dest_dir, "args.gn"), "wt")
+    dargs.write('# -- copied from: ' + src_file + '\n')
+
+    for line in fileinput.input(src_file):
+        dargs.write(line)
+
+    dargs.write('# -- created by ' + sys.argv[0] + '\n')
+    dargs.write('is_debug = ' + deb_str + '\n')
+    dargs.write('use_ozone = ' + ozone_str + '\n')
+    if is_ozone:
+        dargs.write('ozone_platform_x11 = true\n')
+        dargs.write('use_v4l2_codec = true\n')
+        dargs.write('use_v4l2_codec_rpi = true\n')
+
+    dargs.write('target_sysroot = "' + vars["target_sysroot"] + '"\n')
+    dargs.write('google_api_key = "' + vars["google_api_key"] + '"\n')
+    dargs.write('google_default_client_id = "' + vars["google_default_client_id"] + '"\n')
+    dargs.write('google_default_client_secret = "' + vars["google_default_client_secret"] + '"\n')
+
+    dargs.close()
+
+    subprocess.check_call(["gn", "gen", dest_dir])
+
+
+if __name__ == '__main__':
+    gyp_vars = {}
+    gypi = os.path.join(os.environ["HOME"], ".gyp", "include.gypi")
+    if os.path.isfile(gypi):
+        print("Importing from:", gypi)
+        gyps = open(gypi).read(-1)
+        gyp_vars = ast.literal_eval(gyps)["variables"]
+
+    gyp_vars["target_sysroot"] = os.path.abspath("build/linux/pios_bullseye_arm-sysroot")
+
+    docopy("armv6-bullseye", gyp_vars, is_ozone=True)
+    docopy("armv7-bullseye", gyp_vars, is_ozone=True)
+
+    gyp_vars["target_sysroot"] = os.path.abspath("build/linux/pios_bullseye_arm64-sysroot")
+
+    docopy("arm64-bullseye", gyp_vars, is_ozone=True)
+
--- /dev/null
+++ b/src/pi-util/makeall.sh
@@ -0,0 +1,47 @@
+set -e
+
+GET_BUILD_DEPS=
+if [ "$1" == "--build-deps" ]; then
+  GET_BUILD_DEPS=1
+  shift
+fi
+
+if [ "$1" == "" ]; then
+  echo "Usage: $0 [--build-deps] <git tag>"
+  exit 1
+fi
+
+echo === Check all committed
+pi-util/gitscan.py diff --name-status --exit-code
+echo === Reset third party libraries
+pi-util/gitscan.py --gitscan-no-src checkout {BASE}
+TAG=$1
+echo === Fetch chrome
+pi-util/gitscan.py fetch -t --all
+echo === Checkout chrome $TAG
+git checkout $TAG
+if [ ! $GET_BUILD_DEPS ]; then
+  echo === Skip system build dependancies
+else
+  echo === Get system build dependancies
+  build/install-build-deps.sh --arm
+fi
+echo === Sync third party libraries
+gclient sync -D --with_branch_heads
+# Shouldn't need this but the x bit often gets accidentally lost
+# due to core.filemode options
+chmod +x pi-util/*.sh pi-util/*.py
+echo === Checkout third party libraries
+pi-util/gitscan.py --gitscan-no-src checkout $TAG --
+echo === Get pi sysroots
+rm -rf out
+pi-util/rootgen.sh
+echo === Setup gn
+pi-util/gngen.py
+echo === Start build
+ninja -C out/armv7-ozone-rel chrome
+ninja -C out/arm64-ozone-rel chrome
+ninja -C out/armv6-ozone-rel chrome
+
+
+
--- /dev/null
+++ b/src/pi-util/mksyspatch.sh
@@ -0,0 +1,21 @@
+#!/bin/bash -e
+
+SRC_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && cd .. && pwd )"
+TPATCH=/tmp/sysroot.patch
+PATCHFILE_PIOS=$SRC_DIR/pi-util/sysroot-pios.patch
+PATCHFILE_BULLSEYE=$SRC_DIR/pi-util/sysroot-bullseye.patch
+
+cd $SRC_DIR
+echo "Making: $PATCHFILE_PIOS"
+cp $PATCHFILE_PIOS ${PATCHFILE_PIOS}.old
+diff -u build/linux/sysroot_scripts/sysroot-{creator,creator-pios}.sh > ${TPATCH} || true
+diff -u build/linux/sysroot_scripts/generate_{keyring,pios-keyring}.sh >> $TPATCH || true
+awk -f pi-util/patch2nd.awk $TPATCH > $PATCHFILE_PIOS
+echo "Making: $PATCHFILE_BULLSEYE"
+cp $PATCHFILE_BULLSEYE ${PATCHFILE_BULLSEYE}.old
+diff -u build/linux/sysroot_scripts/sysroot-creator-{bullseye,pios-bullseye}.sh > $TPATCH || true
+awk -f pi-util/patch2nd.awk $TPATCH > $PATCHFILE_BULLSEYE
+
+echo "Done"
+
+
--- /dev/null
+++ b/src/pi-util/patch2nd.awk
@@ -0,0 +1,3 @@
+/^\-\-\-/  { next }
+/^\+\+\+/ { $1="---"; print; $1="+++"; }
+{ print }
--- /dev/null
+++ b/src/pi-util/patchmake.sh
@@ -0,0 +1,50 @@
+set -e
+
+GET_BUILD_DEPS=
+if [ "$1" == "--build-deps" ]; then
+  GET_BUILD_DEPS=1
+  shift
+fi
+
+if [ "$1" == "" ]; then
+  echo "Usage: $0 [--build-deps] <patch file>"
+  exit 1
+fi
+if [ ! -e "$1" ]; then
+  echo "Didn't find patchfile $1"
+  exit 1
+fi
+
+PATCHFILE=$1
+TAG=${PATCHFILE##*/}
+TAG=${TAG:1}
+TAG=${TAG%%_*}
+
+echo "Version $TAG extracted from patchfile name"
+
+echo === Checkout chrome $TAG
+git checkout $TAG
+if [ ! $GET_BUILD_DEPS ]; then
+  echo === Skip system build dependancies
+else
+  echo === Get system build dependancies
+  build/install-build-deps.sh --unsupported --arm
+fi
+echo === Sync third party libraries
+gclient sync -D --with_branch_heads
+echo === Patch
+patch -p2 < $PATCHFILE
+# Shouldn't need this but the x bit often gets accidentally lost
+# due to core.filemode options
+chmod +x pi-util/*.sh pi-util/*.py
+echo === Get pi sysroots
+rm -rf out
+pi-util/rootgen.sh
+echo === Setup gn
+pi-util/gngen.py
+echo === Start build
+ninja -C out/armv7-bullseye-ozone-rel chrome
+ninja -C out/arm64-bullseye-ozone-rel chrome
+
+
+
--- /dev/null
+++ b/src/pi-util/pi-install-dev.sh
@@ -0,0 +1,53 @@
+# Install set to build appropriate root on a clean pi
+
+APT=aptitude
+#APT=apt-get
+
+sudo $APT install \
+comerr-dev \
+libasound2-dev \
+libatk1.0-dev \
+libatk-bridge2.0-dev \
+libcap-dev \
+libcups2-dev \
+libexif-dev \
+libffi-dev \
+libgbm-dev \
+libgconf2-dev \
+libgl1-mesa-dev \
+libgles-dev \
+libgtk-3-dev \
+libjpeg-dev \
+libkrb5-dev \
+libnspr4-dev \
+libnss3-dev \
+libpam0g-dev \
+libpango1.0-dev \
+libpci-dev \
+libpcre3-dev \
+libpipewire-0.2-dev \
+libssl-dev \
+libudev-dev \
+libx11-xcb-dev \
+libxcb1-dev \
+libxcb-dri3-dev \
+libxcb-shm0-dev \
+libxcb-image0-dev \
+libxss-dev \
+libxt-dev \
+libxtst-dev \
+mesa-common-dev \
+python-xcbgen \
+uuid-dev \
+xcb-proto
+
+echo Also need python-xcbgen on host
+
+# Pulse (hopefully) disabled
+# libpulse-dev \
+
+# Obviously replace paths appropriately below
+# Now run pi-util/syncroot.sh on the compile m/c to grab the appropriate
+# bits of the root and fix up the paths.
+# e.g. ON COMPILE M/C in src dir:
+# pi-util/syncroot.sh my-pi: raspian_jessie_pi1
--- /dev/null
+++ b/src/pi-util/pipaths.py
@@ -0,0 +1,9 @@
+pipaths=[
+    "src",
+    "src/native_client",
+    "src/third_party/ffmpeg",
+    "src/third_party/libyuv",
+    "src/third_party/skia"]
+
+# Our base tag or commit no
+src_commit="104.0.5112.105"
--- /dev/null
+++ b/src/pi-util/pipewire_utils_h.patch
@@ -0,0 +1,11 @@
+--- a/build/linux/raspian_stretch_pi1-sysroot/usr/include/pipewire/utils.h
++++ b/build/linux/raspian_stretch_pi1-sysroot/usr/include/pipewire/utils.h
+@@ -52,7 +52,7 @@ static inline struct spa_pod *
+ pw_spa_pod_copy(const struct spa_pod *pod)
+ {
+ 	size_t size;
+-	struct spa_pod *c;
++	void *c;
+ 
+ 	if (pod == NULL)
+ 		return NULL;
--- /dev/null
+++ b/src/pi-util/rebase_liblinks.py
@@ -0,0 +1,37 @@
+#!/usr/bin/env python
+
+import os, sys
+from stat import *
+
+def walktree(top, callback, n, prefix):
+    '''recursively descend the directory tree rooted at top,
+       calling the callback function for each regular file'''
+
+    for f in os.listdir(top):
+        pathname = os.path.join(top, f)
+        mode = os.lstat(pathname).st_mode
+        if S_ISDIR(mode):
+            # It's a directory, recurse into it
+            walktree(pathname, callback, n+1, prefix)
+        elif S_ISLNK(mode):
+            # It's a file, call the callback function
+            callback(pathname, os.readlink(pathname), n, prefix)
+
+def visitfile(file, linkname, n, prefix):
+    if (linkname.startswith(prefix + 'lib/')):
+        newlink = "../" * n + linkname[len(prefix):]
+        print 'relinking', file, "->", newlink
+        os.remove(file)
+        os.symlink(newlink, file)
+
+if __name__ == '__main__':
+    argc = len(sys.argv)
+    if argc == 2:
+        walktree(sys.argv[1], visitfile, 0, "/")
+    elif argc == 3:
+        walktree(sys.argv[1], visitfile, 0, sys.argv[2])
+    else:
+        print "rebase_liblinks.py <local root> [<old sysroot>]"
+
+
+
--- /dev/null
+++ b/src/pi-util/rootgen.sh
@@ -0,0 +1,46 @@
+#!/bin/bash -e
+
+SRC_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && cd .. && pwd )"
+
+NOGEN=
+NOPATCH=
+if [ "$1" == "--nopatch" ]; then
+  NOPATCH=1
+  shift
+fi
+if [ "$1" == "--nogen" ]; then
+  NOGEN=1
+  shift
+fi
+
+
+if [ "$1" != "" ]; then
+  echo "Usage: $0 [--nopatch] [--nogen]"
+  exit 1
+fi
+
+if [ ! $NOPATCH ]; then
+  cd $SRC_DIR
+  cp -v build/linux/sysroot_scripts/sysroot-{creator,creator-pios}.sh
+  cp -v build/linux/sysroot_scripts/sysroot-creator-{bullseye,pios-bullseye}.sh
+  cp -v build/linux/sysroot_scripts/generate_{keyring,pios-keyring}.sh
+  patch -p0 < pi-util/sysroot-pios.patch
+  patch -p0 < pi-util/sysroot-bullseye.patch
+fi
+
+rm -rf $SRC_DIR/build/linux/sysroot_scripts/pios_archive.gpg $SRC_DIR/build/linux/pios_*-sysroot
+rm -rf $SRC_DIR/build/linux/sysroot_scripts/generated_package_lists/pios-*
+rm -rf $SRC_DIR/out/sysroot-build
+
+if [ ! $NOGEN ]; then
+  cd $SRC_DIR/build/linux/sysroot_scripts
+  ./generate_pios-keyring.sh
+  ./sysroot-creator-pios-bullseye.sh BuildSysrootARM
+  ./sysroot-creator-pios-bullseye.sh BuildSysrootARM64
+  mkdir -pv ../pios_bullseye_{arm,arm64}-sysroot
+  cd ../pios_bullseye_arm-sysroot
+  bsdtar xf ../../../out/sysroot-build/bullseye/pios_bullseye_arm_sysroot.tar.xz
+  cd ../pios_bullseye_arm64-sysroot
+  bsdtar xf ../../../out/sysroot-build/bullseye/pios_bullseye_arm64_sysroot.tar.xz
+fi
+
--- /dev/null
+++ b/src/pi-util/settag.py
@@ -0,0 +1,62 @@
+#!/usr/bin/env python3
+
+import sys, os, subprocess
+
+# Local
+import pipaths
+import gitscan
+import dodiff
+import argparse
+
+def set_version(verstr):
+    pathname = "components/version_info/pi_patch_version_values.h"
+
+    with open(pathname, "wt") as f:
+        f.write("// Pi patch version - generated by pi-util/settag.py\n")
+        f.write('#define PI_PATCH_VERSION_STRING "' + verstr + '"\n')
+
+    subprocess.check_call(["git", "add", pathname])
+    subprocess.check_call(["git", "commit", "-m", "Update pi patch version to " + verstr])
+
+
+def set_tag(verstr):
+    newtag = "pi/" + pipaths.src_commit + "/" + verstr
+    print("Setting tag: " + newtag)
+    if gitscan.gitscan(["tag", newtag], quiet=True) != 0:
+        print("Tagging failed")
+        sys.exit(1)
+
+def set_tag_and_version(verstr):
+    set_version(verstr)
+    set_tag(verstr)
+
+if __name__ == '__main__':
+    argp = argparse.ArgumentParser(
+        description="Sets version info in pi_patch_version_values & tags source tree with it")
+    argp.add_argument("-p", action='store_true', help="Generate patch file")
+    argp.add_argument("-n", action='store_true', help="Do not tag")
+    argp.add_argument("verstr", help="Pi patch version string")
+    args = argp.parse_args()
+
+    patchpath = os.path.join("..", "v" + pipaths.src_commit + "_" + args.verstr + ".patch")
+
+    if args.p and os.path.exists(patchpath):
+        print("Patchfile", patchpath, "already exists")
+        sys.exit(1)
+
+    if not args.n:
+        print("-- Checking all committed")
+        if gitscan.gitscan(["diff", "--name-status", "--exit-code"], quiet=True) != 0:
+            print("Status check failed - commit everything and try again")
+            sys.exit(1)
+
+        print("-- Generating & committing pi_patch_version_values.h")
+        set_version(args.verstr)
+        print("-- Generating tags")
+        set_tag(args.verstr)
+
+    if args.p:
+        print("-- Generating patch file: ", patchpath)
+        with open(patchpath, "wt") as f:
+            dodiff.doscan(f)
+
--- /dev/null
+++ b/src/pi-util/syncroot.sh
@@ -0,0 +1,70 @@
+set -e
+
+NEEDSVC=1
+TYPE=arm
+API=arm-linux-gnueabihf
+SYSROOT_DEFAULT=pios_buster_arm
+
+if [ "$1" == "--arm64" ]; then
+  shift
+  TYPE=arm64
+  NEEDSVC=
+  API=aarch64-linux-gnu
+  SYSROOT_DEFAULT=pios_buster_arm64
+fi
+
+if [ "$1" == "" ]; then
+  echo Usage: $0 [--arm64] \<src_dir\> [\<rootname\>]
+  echo src_dir is a source for rsync so may contain m/c name.
+  echo rootname will be set to \"pios_buster_arm\" if missing
+  echo e.g.: pi-util/syncroot.sh my-pi:
+  exit 1
+fi
+
+SYSROOT_NAME=$2
+if [ "$SYSROOT_NAME" == "" ]; then
+  SYSROOT_NAME=$SYSROOT_DEFAULT
+fi
+
+DST_ROOT=`gclient root`
+DST=$DST_ROOT/src/build/linux/$SYSROOT_NAME-sysroot
+SRC=$1
+
+if [ ! -d $DST_ROOT/src/build/linux ]; then
+  echo We don\'t appear to be in a Chrome build tree
+  exit 1
+fi
+
+echo Copying root for $TYPE
+echo Sync src:  $SRC
+echo Sync dest: $DST
+
+mkdir -p $DST/lib
+mkdir -p $DST/opt/vc/include
+mkdir -p $DST/usr/lib/pkgconfig
+mkdir -p $DST/usr/bin
+mkdir -p $DST/usr/share
+
+rsync -rl $SRC/lib $DST
+if [ $NEEDSVC ]; then
+  #### MUST NOT include /opt/vc/include/*GL*
+  # Creates conflicts with GL includes inside Chrome
+  rsync -rl $SRC/opt/vc/lib $DST/opt/vc
+  rsync -rl $SRC/opt/vc/include/interface $DST/opt/vc/include
+fi
+rsync -rl --exclude cups/backend $SRC/usr/lib $DST/usr
+rsync -rl $SRC/usr/include $DST/usr
+rsync -rl $SRC/usr/share/pkgconfig $DST/usr/share
+rsync -rl $SRC/usr/share/xcb $DST/usr/share
+rsync -rl $SRC/usr/bin/cups-config $DST/usr/bin
+
+# Fix up pipewire issue
+if [ -e $DST/usr/include/pipewire/utils.h ]; then
+  sed 's/struct spa_pod \*c/void \* c/' < $DST/usr/include/pipewire/utils.h > u.h
+  mv u.h $DST/usr/include/pipewire/utils.h
+fi
+
+cd $DST/usr/lib/pkgconfig
+ln -sf ../$API/pkgconfig/* .
+cd ../../../../../..
+pi-util/rebase_liblinks.py $DST
--- /dev/null
+++ b/src/pi-util/sysroot-bullseye.patch
@@ -0,0 +1,64 @@
+--- build/linux/sysroot_scripts/sysroot-creator-pios-bullseye.sh 2022-06-28 10:25:58.474586121 +0000
++++ build/linux/sysroot_scripts/sysroot-creator-pios-bullseye.sh 2022-06-28 10:25:58.474586121 +0000
+@@ -5,11 +5,14 @@
+ 
+ SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
+ 
+-DISTRO=debian
++DISTRO=pios
+ DIST=bullseye
+ 
+ ARCHIVE_TIMESTAMP=20220331T153654Z
+ ARCHIVE_URL="https://snapshot.debian.org/archive/debian/$ARCHIVE_TIMESTAMP/"
++PI_ARCHIVE_TIMESTAMP=latest
++PI_ARCHIVE_URL="https://snapshot.raspbian.org/$PI_ARCHIVE_TIMESTAMP/raspbian/"
++
+ APT_SOURCES_LIST=(
+   # Debian 12 (Bookworm) is needed for GTK4.  It should be kept before bullseye
+   # so that bullseye takes precedence.
+@@ -25,18 +28,24 @@
+   "${ARCHIVE_URL} bullseye main contrib non-free"
+   "${ARCHIVE_URL} bullseye-updates main contrib non-free"
+   "${ARCHIVE_URL} bullseye-backports main contrib non-free"
++
++  "http://archive.raspberrypi.org/debian/ $DIST main"
+ )
+ 
++if [ "$1" = "BuildSysrootARM" ]; then
++  APT_SOURCES_LIST+=("${PI_ARCHIVE_URL} $DIST main contrib non-free rpi")
++fi
++
+ # gpg keyring file generated using generate_keyring.sh
+-KEYRING_FILE="${SCRIPT_DIR}/keyring.gpg"
++KEYRING_FILE="${SCRIPT_DIR}/pios_keyring.gpg"
+ 
+-HAS_ARCH_AMD64=1
+-HAS_ARCH_I386=1
++HAS_ARCH_AMD64=0
++HAS_ARCH_I386=0
+ HAS_ARCH_ARM=1
+ HAS_ARCH_ARM64=1
+-HAS_ARCH_ARMEL=1
+-HAS_ARCH_MIPS=1
+-HAS_ARCH_MIPS64EL=1
++HAS_ARCH_ARMEL=0
++HAS_ARCH_MIPS=0
++HAS_ARCH_MIPS64EL=0
+ 
+ # Sysroot packages: these are the packages needed to build chrome.
+ DEBIAN_PACKAGES="\
+@@ -413,6 +422,8 @@
+   x11proto-dev
+   zlib1g
+   zlib1g-dev
++  libraspberrypi0
++  libraspberrypi-dev
+ "
+ 
+ DEBIAN_PACKAGES_AMD64="
+@@ -467,4 +478,4 @@
+   valgrind
+ "
+ 
+-. "${SCRIPT_DIR}/sysroot-creator.sh"
++. "${SCRIPT_DIR}/sysroot-creator-pios.sh"
--- /dev/null
+++ b/src/pi-util/sysroot-pios.patch
@@ -0,0 +1,135 @@
+--- build/linux/sysroot_scripts/sysroot-creator-pios.sh 2022-06-28 10:28:20.633604992 +0000
++++ build/linux/sysroot_scripts/sysroot-creator-pios.sh 2022-06-28 10:28:20.633604992 +0000
+@@ -58,17 +58,17 @@
+ # Package Config
+ ######################################################################
+ 
+-readonly PACKAGES_EXT=xz
++readonly PACKAGES_EXTS="xz gz"
+ readonly RELEASE_FILE="Release"
+ readonly RELEASE_FILE_GPG="Release.gpg"
+ 
+-readonly DEBIAN_DEP_LIST_AMD64="generated_package_lists/${DIST}.amd64"
+-readonly DEBIAN_DEP_LIST_I386="generated_package_lists/${DIST}.i386"
+-readonly DEBIAN_DEP_LIST_ARM="generated_package_lists/${DIST}.arm"
+-readonly DEBIAN_DEP_LIST_ARM64="generated_package_lists/${DIST}.arm64"
+-readonly DEBIAN_DEP_LIST_ARMEL="generated_package_lists/${DIST}.armel"
+-readonly DEBIAN_DEP_LIST_MIPS="generated_package_lists/${DIST}.mipsel"
+-readonly DEBIAN_DEP_LIST_MIPS64EL="generated_package_lists/${DIST}.mips64el"
++readonly DEBIAN_DEP_LIST_AMD64="generated_package_lists/pios-${DIST}.amd64"
++readonly DEBIAN_DEP_LIST_I386="generated_package_lists/pios-${DIST}.i386"
++readonly DEBIAN_DEP_LIST_ARM="generated_package_lists/pios-${DIST}.arm"
++readonly DEBIAN_DEP_LIST_ARM64="generated_package_lists/pios-${DIST}.arm64"
++readonly DEBIAN_DEP_LIST_ARMEL="generated_package_lists/pios-${DIST}.armel"
++readonly DEBIAN_DEP_LIST_MIPS="generated_package_lists/pios-${DIST}.mipsel"
++readonly DEBIAN_DEP_LIST_MIPS64EL="generated_package_lists/pios-${DIST}.mips64el"
+ 
+ 
+ ######################################################################
+@@ -125,7 +125,7 @@
+     local temp_file="${2}.partial.$$"
+     # curl --retry doesn't retry when the page gives a 4XX error, so we need to
+     # manually rerun.
+-    for i in {1..10}; do
++    for i in {1..2}; do
+       # --create-dirs is added in case there are slashes in the filename, as can
+       # happen with the "debian/security" release class.
+       local http_code=$(curl -L "$1" --create-dirs -o "${temp_file}" \
+@@ -138,7 +138,7 @@
+       sleep $i
+     done
+     if [ ! -f "${temp_file}" ]; then
+-      exit 1
++      return 1
+     fi
+     mv "${temp_file}" $2
+   else
+@@ -230,7 +230,16 @@
+   local src_file="$1"
+   local dst_file="$2"
+   local repo="$3"
+-  xzcat "${src_file}" | egrep '^(Package:|Filename:|SHA256:) ' |
++  local cat_tool
++  if [ "$PACKAGES_EXT" == "xz" ]; then
++    cat_tool="xzcat"
++  elif [ "$PACKAGES_EXT" == "gz" ]; then
++    cat_tool="zcat"
++  else
++    echo "ERROR: No tool to 'cat' archive type: $PACKAGES_EXT"
++    exit 1
++  fi
++  "$cat_tool" "${src_file}" | egrep '^(Package:|Filename:|SHA256:) ' |
+     sed "s|Filename: |Filename: ${repo}|" > "${dst_file}"
+ }
+ 
+@@ -240,16 +249,23 @@
+   local dist="$3"
+   local repo_name="$4"
+ 
++  for PACKAGES_EXT in $PACKAGES_EXTS FAIL; do
+   local tmp_package_list="${BUILD_DIR}/Packages.${dist}_${repo_name}_${arch}"
+   local repo_basedir="${repo}/dists/${dist}"
+   local package_list="${BUILD_DIR}/Packages.${dist}_${repo_name}_${arch}.${PACKAGES_EXT}"
+   local package_file_arch="${repo_name}/binary-${arch}/Packages.${PACKAGES_EXT}"
+   local package_list_arch="${repo_basedir}/${package_file_arch}"
+ 
+-  DownloadOrCopyNonUniqueFilename "${package_list_arch}" "${package_list}"
++  DownloadOrCopyNonUniqueFilename "${package_list_arch}" "${package_list}" || continue
+   VerifyPackageListing "${package_file_arch}" "${package_list}" ${repo} ${dist}
+   ExtractPackageXz "${package_list}" "${tmp_package_list}" ${repo}
+   cat "${tmp_package_list}" | ./merge-package-lists.py "${list_base}"
++  break
++  done
++  if [ "$PACKAGES_EXT" == "FAIL" ]; then
++    echo "ERROR: Command failed: $0 $@"
++    exit 1
++  fi
+ }
+ 
+ GeneratePackageListDist() {
+@@ -387,6 +403,8 @@
+   mkdir -p ${INSTALL_ROOT}/usr/lib/pkgconfig
+   mv ${INSTALL_ROOT}/usr/lib/${arch}-${os}/pkgconfig/* \
+       ${INSTALL_ROOT}/usr/lib/pkgconfig
++
++  rm -rf "${INSTALL_ROOT}/opt/vc/include/"*GL*
+ }
+ 
+ 
+@@ -894,14 +912,14 @@
+   shift
+   local failed=0
+   for pkg in $@ ; do
+-    local pkg_full=$(grep -A 1 " ${pkg}\$" "$input_file" | \
+-      egrep "pool/.*" | sed 's/.*Filename: //')
++    local pkg_full=$(grep -A 2 " ${pkg}\$" "$input_file" | \
++      egrep -m1 "pool/.*" | sed 's/.*Filename: //')
+     if [ -z "${pkg_full}" ]; then
+       echo "ERROR: missing package: $pkg"
+       local failed=1
+     else
+       local sha256sum=$(grep -A 4 " ${pkg}\$" "$input_file" | \
+-        grep ^SHA256: | sed 's/^SHA256: //')
++        grep -m1 ^SHA256: | sed 's/^SHA256: //')
+       if [ "${#sha256sum}" -ne "64" ]; then
+         echo "Bad sha256sum from Packages"
+         local failed=1
+--- build/linux/sysroot_scripts/generate_pios-keyring.sh 2022-06-28 10:25:58.474586121 +0000
++++ build/linux/sysroot_scripts/generate_pios-keyring.sh 2022-06-28 10:25:58.474586121 +0000
+@@ -9,6 +9,10 @@
+ SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
+ 
+ KEYS=(
++    # Raspbian
++    "A0DA38D0D76E8B5D638872819165938D90FDDD2E"
++    # Raspberry Pi OS
++    "CF8A1AF502A2AA2D763BAE7E82B129927FA3303E"
+     # Debian Archive Automatic Signing Key (11/bullseye)
+     "73A4F27B8DD47936"
+     # Debian Security Archive Automatic Signing Key (11/bullseye)
+@@ -38,4 +42,4 @@
+ )
+ 
+ gpg --keyserver keyserver.ubuntu.com --recv-keys ${KEYS[@]}
+-gpg --output "${SCRIPT_DIR}/keyring.gpg" --export ${KEYS[@]}
++gpg --output "${SCRIPT_DIR}/pios_keyring.gpg" --export ${KEYS[@]}
--- a/src/sandbox/policy/linux/bpf_gpu_policy_linux.cc
+++ b/src/sandbox/policy/linux/bpf_gpu_policy_linux.cc
@@ -85,6 +85,27 @@ ResultExpr GpuProcessPolicy::EvaluateSys
     case __NR_mmap:
       return Allow();
 #endif
+#if defined(USE_X11) || 1
+    // Wanted for MESA to fire up happily
+    // *** Should almost certainly arrange for the offending setup
+    //     to happen before sandbox is applied but I can't work out
+    //     what is needed
+    // Alternatively --in-process-gpu fixes the issue
+#ifdef __NR_readlink
+    case __NR_readlink:  // 85
+#else
+    case __NR_readlinkat:
+#endif
+#ifdef __NR_stat64
+    case __NR_stat64:    // 195
+#endif
+    case __NR_openat:    // 322 --- This one is clearly bad!
+    // V4L2 requires open/close - not sure how this works in chromeos without the holes
+#ifdef __NR_open
+    case __NR_open:
+#endif
+    case __NR_close:
+#endif
     // We also hit this on the linux_chromeos bot but don't yet know what
     // weird flags were involved.
     case __NR_mprotect:
--- a/src/third_party/libdrm/BUILD.gn
+++ b/src/third_party/libdrm/BUILD.gn
@@ -72,6 +72,7 @@ static_library("libdrm") {
     # glibc-2.24.  This causes a build error when using the Debian
     # Stretch sysroot.
     "-Wno-deprecated-declarations",
+    "-DMAJOR_IN_SYSMACROS=1",
   ]
 
   public_configs = [ ":libdrm_config" ]
--- a/src/third_party/widevine/cdm/widevine.gni
+++ b/src/third_party/widevine/cdm/widevine.gni
@@ -26,7 +26,7 @@ if (is_chromeos && !is_chromeos_device)
 library_widevine_cdm_available =
     (is_chromeos &&
      (target_cpu == "x64" || target_cpu == "arm" || target_cpu == "arm64")) ||
-    (target_os == "linux" && target_cpu == "x64") ||
+    (target_os == "linux" && (target_cpu == "x64" || target_cpu == "arm")) ||
     (target_os == "mac" && (target_cpu == "x64" || target_cpu == "arm64")) ||
     (target_os == "win" &&
      (target_cpu == "x86" || target_cpu == "x64" || target_cpu == "arm64"))
--- a/src/ui/gl/init/gl_factory.cc
+++ b/src/ui/gl/init/gl_factory.cc
@@ -112,6 +112,15 @@ GLImplementationParts GetRequestedGLImpl
   absl::optional<GLImplementationParts> impl_from_cmdline =
       GetRequestedGLImplementationFromCommandLine(cmd, fallback_to_software_gl);
 
+  // RPI: We always want EGL as our preferred render
+  // Easiest to simply add here - angle + GLES +/- EGL crashes
+  // so add here after the angle add.
+  //
+  // BEWARE: falling back from EGL to anything else with --in-process-gpu
+  // set produces a segfault when we exit so ideally we would only do this
+  // on Pi4/(F)KMS?
+  allowed_impls.insert(allowed_impls.begin(), GLImplementationParts(kGLImplementationEGLGLES2));
+
   // The default implementation is always the first one in list.
   if (!impl_from_cmdline)
     return allowed_impls[0];
--- a/src/native_client/src/include/concurrency_ops.h
+++ b/src/native_client/src/include/concurrency_ops.h
@@ -32,14 +32,13 @@ static INLINE void NaClWriteMemoryBarrie
 #elif NACL_ARCH(NACL_BUILD_ARCH) == NACL_arm
 
 static INLINE void NaClWriteMemoryBarrier(void) {
+#if __ARM_ARCH >= 7
   /* Note that this depends on ARMv7. */
   __asm__ __volatile__("dsb");
-
-  /*
-   * We could support ARMv6 by instead using:
-   * __asm__ __volatile__("mcr p15, 0, %0, c7, c10, 5"
-   *                      : : "r" (0) : "memory");
-   */
+#else
+ __asm__ __volatile__("mcr p15, 0, %0, c7, c10, 5"
+                      : : "r" (0) : "memory");
+#endif
 }
 
 #elif NACL_ARCH(NACL_BUILD_ARCH) == NACL_mips
--- a/src/third_party/ffmpeg/chromium/config/Chrome/linux/arm/config.h
+++ b/src/third_party/ffmpeg/chromium/config/Chrome/linux/arm/config.h
@@ -45,7 +45,7 @@
 #define ARCH_X86_64 0
 #define HAVE_ARMV5TE 1
 #define HAVE_ARMV6 1
-#define HAVE_ARMV6T2 1
+#define HAVE_ARMV6T2 0
 #define HAVE_ARMV8 0
 #define HAVE_NEON 0
 #define HAVE_VFP 1
@@ -93,7 +93,7 @@
 #define HAVE_LASX 0
 #define HAVE_ARMV5TE_EXTERNAL 1
 #define HAVE_ARMV6_EXTERNAL 1
-#define HAVE_ARMV6T2_EXTERNAL 1
+#define HAVE_ARMV6T2_EXTERNAL 0
 #define HAVE_ARMV8_EXTERNAL 0
 #define HAVE_NEON_EXTERNAL 0
 #define HAVE_VFP_EXTERNAL 1
@@ -141,7 +141,7 @@
 #define HAVE_LASX_EXTERNAL 0
 #define HAVE_ARMV5TE_INLINE 1
 #define HAVE_ARMV6_INLINE 1
-#define HAVE_ARMV6T2_INLINE 1
+#define HAVE_ARMV6T2_INLINE 0
 #define HAVE_ARMV8_INLINE 0
 #define HAVE_NEON_INLINE 0
 #define HAVE_VFP_INLINE 1
@@ -626,7 +626,7 @@
 #define CONFIG_OSSFUZZ 0
 #define CONFIG_PIC 1
 #define CONFIG_PTX_COMPRESSION 0
-#define CONFIG_THUMB 1
+#define CONFIG_THUMB 0
 #define CONFIG_VALGRIND_BACKTRACE 0
 #define CONFIG_XMM_CLOBBER_TEST 0
 #define CONFIG_BSFS 0
--- a/src/third_party/libyuv/BUILD.gn
+++ b/src/third_party/libyuv/BUILD.gn
@@ -208,6 +208,11 @@ if (libyuv_use_neon) {
 
     if (current_cpu != "arm64") {
       configs -= [ "//build/config/compiler:compiler_arm_fpu" ]
+      if (arm_version < 7) {
+        configs += [
+          "//build/config/compiler:force_march_armv7",
+        ]
+      }
       cflags = [ "-mfpu=neon" ]
     }
   }
--- a/src/third_party/libyuv/source/cpu_id.cc
+++ b/src/third_party/libyuv/source/cpu_id.cc
@@ -133,6 +133,18 @@ int GetXCR0() {
 #pragma optimize("g", on)
 #endif
 
+#ifdef __ARMEL__
+// This is (a) simpler and (b) works in sandbox vs the /proc/cpuinfo method
+#include <sys/auxv.h>
+
+int ArmCpuCaps(const char* cpuinfo_name) {
+  const unsigned long auxval = getauxval(AT_HWCAP);
+
+  // Documentation suggests that getauxval(AT_HWCAP) should return a pointer
+  // to a bit array, but evidence suggests it returns a simple bit field
+  return ((auxval & HWCAP_ARM_NEON) != 0 ? kCpuHasNEON : 0);
+}
+#else
 // Based on libvpx arm_cpudetect.c
 // For Arm, but public to allow testing on any CPU
 LIBYUV_API SAFEBUFFERS int ArmCpuCaps(const char* cpuinfo_name) {
@@ -161,6 +173,7 @@ LIBYUV_API SAFEBUFFERS int ArmCpuCaps(co
   fclose(f);
   return 0;
 }
+#endif
 
 // TODO(fbarchard): Consider read_msa_ir().
 LIBYUV_API SAFEBUFFERS int MipsCpuCaps(const char* cpuinfo_name) {
--- a/src/third_party/skia/src/core/SkBitmapProcState.cpp
+++ b/src/third_party/skia/src/core/SkBitmapProcState.cpp
@@ -18,6 +18,7 @@
 #include "src/core/SkOpts.h"
 #include "src/core/SkResourceCache.h"
 
+#if !defined(SK_ARM_HAS_NEON) || defined(__ARM_64BIT_STATE)
 // One-stop-shop shader for,
 //   - nearest-neighbor sampling (_nofilter_),
 //   - clamp tiling in X and Y both (Clamp_),
@@ -73,6 +74,199 @@ static void Clamp_S32_opaque_D32_nofilte
         }
     }
 }
+#endif
+
+// We define two variants of this: one for 32-bit ARM NEON, and one generic C:
+
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+static inline void Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core_neon(SkPMColor* __restrict__ &dst, const SkPMColor* __restrict__ src, int core, SkFractionalInt fx, const SkFractionalInt dx)
+{
+    const SkPMColor*p = src + (int32_t)(fx >> 32);
+    uint32_t accum = (uint32_t) fx;
+    const SkPMColor *p2;
+    __asm__ volatile (
+            "cmp     %[core], #0           \n\t"
+            "it      ne                    \n\t"
+            "tstne   %[dst], #0xc          \n\t"
+            "beq     2f                    \n\t"
+            "1:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[inc1]         \n\t"
+            "addcs   %[p], %[inc2]         \n\t"
+            "vstm    %[dst]!, {s0}         \n\t"
+            "subs    %[core], #1           \n\t"
+            "it      ne                    \n\t"
+            "tstne   %[dst], #0xc          \n\t"
+            "bne     1b                    \n\t"
+            "2:                            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "subs    %[core], #4           \n\t"
+            "bcc     4f                    \n\t"
+            "3:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[p2], %[inc1]  \n\t"
+            "addcs   %[p], %[p2], %[inc2]  \n\t"
+            "vldr    s1, [%[p2]]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vldr    s2, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[p2], %[inc1]  \n\t"
+            "addcs   %[p], %[p2], %[inc2]  \n\t"
+            "vldr    s3, [%[p2]]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vst1.32 {q0}, [%[dst] :128]!  \n\t"
+            "subs    %[core], #4           \n\t"
+            "bcs     3b                    \n\t"
+            "4:                            \n\t"
+            "adds    %[core], #4           \n\t"
+            "beq     6f                    \n\t"
+            "5:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "mov     %[p], %[p2]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vstm    %[dst]!, {s0}         \n\t"
+            "subs    %[core], #1           \n\t"
+            "bne     5b                    \n\t"
+            "6:                            \n\t"
+    : // Outputs
+            [accum]"+r"(accum),
+             [core]"+r"(core),
+              [dst]"+r"(dst),
+                [p]"+r"(p),
+               [p2]"=&r"(p2)
+    : // Inputs
+              [dx]"r"((int32_t) dx),
+            [inc1]"r"((int32_t)(dx >> 32) * 4),
+            [inc2]"r"(((int32_t)(dx >> 32) + 1) * 4)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+#endif
+
+#if 0
+static inline void Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core(SkPMColor* __restrict__ &dst, const SkPMColor* __restrict__ src, int core, SkFractionalInt fx, const SkFractionalInt dx)
+{
+    const SkPMColor*p = src + (int32_t)(fx >> 32);
+    uint32_t accum = (uint32_t) fx;
+    for (; core > 0; --core) {
+        *dst++ = *p;
+        uint32_t prev_accum = accum;
+        accum += (int32_t) dx;
+        if (accum < prev_accum) /* i.e. carry set */
+            p += (int32_t)(dx >> 32) + 1;
+        else
+            p += (int32_t)(dx >> 32);
+    }
+}
+#endif
+
+#define Clamp_S32_opaque_D32_nofilter_DX_shaderproc_template(SUFFIX)                               \
+static void Clamp_S32_opaque_D32_nofilter_DX_shaderproc(const void* sIn, int x, int y,             \
+                                                        SkPMColor* SK_RESTRICT dst,  int count) {  \
+    const SkBitmapProcState& s = *static_cast<const SkBitmapProcState*>(sIn);                      \
+    SkASSERT(s.fAlphaScale == 256);                                                                \
+                                                                                                   \
+    const unsigned maxX = s.fPixmap.width() - 1;                                                   \
+    SkFractionalInt fx;                                                                            \
+    int dstY;                                                                                      \
+    {                                                                                              \
+        const SkBitmapProcStateAutoMapper mapper(s, x, y);                                         \
+        const unsigned maxY = s.fPixmap.height() - 1;                                              \
+        dstY = SkTPin(mapper.intY(), 0, (int)maxY);                                                    \
+        fx = mapper.fractionalIntX();                                                              \
+    }                                                                                              \
+                                                                                                   \
+    const SkPMColor* SK_RESTRICT src = s.fPixmap.addr32(0, dstY);                                  \
+    const SkFractionalInt dx = s.fInvSxFractionalInt;                                              \
+                                                                                                   \
+    int core;                                                                                      \
+                                                                                                   \
+    /* The unscaled case is easily common enough to be worth special-casing.                       \
+     * The system memcpy() is typically already heavily optimized, so just use that.               \
+     */                                                                                            \
+    if (dx == 0x100000000ll) {                                                                     \
+        int32_t fx_integer = fx >> 32;                                                             \
+        if (fx_integer < 0) {                                                                      \
+            int left = std::min(-fx_integer, count);                                                \
+            fx_integer += left;                                                                    \
+            count -= left;                                                                         \
+            for (; left > 0; --left)                                                               \
+                *dst++ = src[0];                                                                   \
+        }                                                                                          \
+        if (fx_integer < (int)maxX) {                                                              \
+            core = std::min((int)maxX + 1 - fx_integer, count);                                     \
+            memcpy(dst, src + fx_integer, core * sizeof (uint32_t));                               \
+            dst += core;                                                                           \
+            count -= core;                                                                         \
+        }                                                                                          \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[maxX];                                                                    \
+        }                                                                                          \
+    }                                                                                              \
+                                                                                                   \
+    /* Handle other non-reflected scale factors. */                                                \
+    else if (dx >= 0) {                                                                            \
+        for (; fx < 0 && count > 0; --count) {                                                     \
+            *dst++ = src[0];                                                                       \
+            fx += dx;                                                                              \
+        }                                                                                          \
+        if ((int32_t)(fx >> 32) > (int)maxX)                                                       \
+            core = 0;                                                                              \
+        else if ((int32_t)((fx + (count - 1) * dx) >> 32) <= (int)maxX)                            \
+            core = count;                                                                          \
+        else                                                                                       \
+            core = (int32_t)(((((SkFractionalInt) maxX) << 32) + 0xffffffff - fx) / dx) + 1;       \
+        Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core##SUFFIX(dst, src, core, fx, dx);          \
+        count -= core;                                                                             \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[maxX];                                                                    \
+        }                                                                                          \
+    }                                                                                              \
+                                                                                                   \
+    /* It's not clear if reflection is used, but it's a relatively                                 \
+     * simple variation on the non-reflected case. */                                              \
+    else                                                                                           \
+    {                                                                                              \
+        for (; (int32_t)(fx >> 32) > (int)maxX && count > 0; --count) {                            \
+            *dst++ = src[maxX];                                                                    \
+            fx += dx;                                                                              \
+        }                                                                                          \
+        if (fx < 0)                                                                                \
+            core = 0;                                                                              \
+        else if (fx + (count - 1) * dx >= 0)                                                       \
+            core = count;                                                                          \
+        else                                                                                       \
+            core = (int32_t)(fx / -dx) + 1;                                                        \
+        Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core##SUFFIX(dst, src, core, fx, dx);          \
+        count -= core;                                                                             \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[0];                                                                       \
+        }                                                                                          \
+    }                                                                                              \
+}
+
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+Clamp_S32_opaque_D32_nofilter_DX_shaderproc_template(_neon)
+#endif
+
 
 static void S32_alpha_D32_nofilter_DX(const SkBitmapProcState& s,
                                       const uint32_t* xy, int count, SkPMColor* colors) {
@@ -272,7 +466,11 @@ bool SkBitmapProcState::chooseProcs() {
     SkASSERT(fMatrixProc);
 
     if (fInvMatrix.isScaleTranslate()) {
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+        fSampleProc32 = fBilerp ? (fAlphaScale == 256 ? SkOpts::S32_opaque_D32_filter_DX : SkOpts::S32_alpha_D32_filter_DX)   : S32_alpha_D32_nofilter_DX  ;
+#else
         fSampleProc32 = fBilerp ? SkOpts::S32_alpha_D32_filter_DX   : S32_alpha_D32_nofilter_DX  ;
+#endif
     } else {
         fSampleProc32 = fBilerp ? SkOpts::S32_alpha_D32_filter_DXDY : S32_alpha_D32_nofilter_DXDY;
     }
--- a/src/third_party/skia/src/core/SkBitmapProcState_matrixProcs.cpp
+++ b/src/third_party/skia/src/core/SkBitmapProcState_matrixProcs.cpp
@@ -247,6 +247,530 @@ static unsigned clamp(SkFixed fx, int ma
     return SkTPin(fx >> 16, 0, max);
 }
 
+// Clamp/Clamp and Repeat/Repeat have NEON or portable implementations.
+#if defined(SK_ARM_HAS_NEON)
+    #include <arm_neon.h>
+
+    // TODO: this is a fine drop-in for decal_nofilter_scale() generally.
+    static void decal_nofilter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count) {
+        if (count >= 8) {
+            // SkFixed is 16.16 fixed point
+            SkFixed dx8 = dx * 8;
+            int32x4_t vdx8 = vdupq_n_s32(dx8);
+
+            // setup lbase and hbase
+            int32x4_t lbase, hbase;
+            lbase = vdupq_n_s32(fx);
+            lbase = vsetq_lane_s32(fx + dx, lbase, 1);
+            lbase = vsetq_lane_s32(fx + dx + dx, lbase, 2);
+            lbase = vsetq_lane_s32(fx + dx + dx + dx, lbase, 3);
+            hbase = lbase + vdupq_n_s32(4 * dx);
+
+            do {
+                // store the upper 16 bits
+                vst1q_u32(dst, vreinterpretq_u32_s16(
+                    vuzpq_s16(vreinterpretq_s16_s32(lbase), vreinterpretq_s16_s32(hbase)).val[1]
+                ));
+
+                // on to the next group of 8
+                lbase += vdx8;
+                hbase += vdx8;
+                dst += 4; // we did 8 elements but the result is twice smaller
+                count -= 8;
+                fx += dx8;
+            } while (count >= 8);
+        }
+
+        uint16_t* xx = (uint16_t*)dst;
+        for (int i = count; i > 0; --i) {
+            *xx++ = SkToU16(fx >> 16); fx += dx;
+        }
+    }
+
+    static void decal_filter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count) {
+#ifndef __ARM_64BIT_STATE
+        SkASSERT(((fx + (count-1) * dx) >> (16 + 14)) == 0);
+        fx = (fx << 2) + 1;
+        dx <<= 2;
+        while (((uintptr_t) dst & 0xf) && --count >= 0) {
+            *dst++ = (fx & 0xffffc001) + (fx >> 18);
+            fx += dx;
+        }
+        if ((count -= 4) >= 0) {
+            uint32_t tmp;
+            __asm__ (
+                    "adr         %[tmp], 1f                  \n\t"
+                    "vmvn.i32    q10, #0x3fff                \n\t"
+                    "vld1.32     {q11}, [%[tmp]]             \n\t"
+                    "vdup.32     q8, %[fx]                   \n\t"
+                    "vdup.32     q9, %[dx]                   \n\t"
+                    "vsra.u32    q10, #31                    \n\t"
+                    "vmla.u32    q8, q9, q11                 \n\t"
+                    "vshl.u32    q9, #2                      \n\t"
+                    "b           2f                          \n\t"
+                    "1:                                      \n\t"
+                    ".long       0                           \n\t"
+                    ".long       1                           \n\t"
+                    ".long       2                           \n\t"
+                    ".long       3                           \n\t"
+                    "2:                                      \n\t"
+                    "vand        q11, q8, q10                \n\t"
+                    "vshr.u32    q12, q8, #18                \n\t"
+                    "vadd.i32    q11, q12                    \n\t"
+                    "vadd.i32    q8, q9                      \n\t"
+                    "subs        %[count], #4                \n\t"
+                    "vst1.32     {q11}, [%[dst]:128]!        \n\t"
+                    "bpl         2b                          \n\t"
+                    "vmov.32     %[fx], d16[0]               \n\t"
+            : // Outputs
+                    [count]"+l"(count),
+                      [dst]"+r"(dst),
+                       [fx]"+r"(fx),
+                      [tmp]"=&r"(tmp)
+            : // Inputs
+                    [dx]"r"(dx)
+            : // Clobbers
+                    "cc", "memory"
+            );
+        }
+        if ((count += 4-1) >= 0) {
+            do {
+                *dst++ = (fx & 0xffffc001) + (fx >> 18);
+                fx += dx;
+            } while (--count >= 0);
+        }
+#else // !defined(__ARM_64BIT_STATE)
+        if (count >= 8) {
+            SkFixed dx8 = dx * 8;
+            int32x4_t vdx8 = vdupq_n_s32(dx8);
+
+            int32x4_t wide_fx, wide_fx2;
+            wide_fx = vdupq_n_s32(fx);
+            wide_fx = vsetq_lane_s32(fx + dx, wide_fx, 1);
+            wide_fx = vsetq_lane_s32(fx + dx + dx, wide_fx, 2);
+            wide_fx = vsetq_lane_s32(fx + dx + dx + dx, wide_fx, 3);
+
+            wide_fx2 = vaddq_s32(wide_fx, vdupq_n_s32(4 * dx));
+
+            while (count >= 8) {
+                int32x4_t wide_out;
+                int32x4_t wide_out2;
+
+                wide_out = vshlq_n_s32(vshrq_n_s32(wide_fx, 12), 14);
+                wide_out = wide_out | (vshrq_n_s32(wide_fx,16) + vdupq_n_s32(1));
+
+                wide_out2 = vshlq_n_s32(vshrq_n_s32(wide_fx2, 12), 14);
+                wide_out2 = wide_out2 | (vshrq_n_s32(wide_fx2,16) + vdupq_n_s32(1));
+
+                vst1q_u32(dst, vreinterpretq_u32_s32(wide_out));
+                vst1q_u32(dst+4, vreinterpretq_u32_s32(wide_out2));
+
+                dst += 8;
+                fx += dx8;
+                wide_fx += vdx8;
+                wide_fx2 += vdx8;
+                count -= 8;
+            }
+        }
+
+        if (count & 1)
+        {
+            SkASSERT((fx >> (16 + 14)) == 0);
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+        }
+        while ((count -= 2) >= 0)
+        {
+            SkASSERT((fx >> (16 + 14)) == 0);
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+        }
+#endif
+    }
+
+    static inline int16x8_t clamp8(int32x4_t low, int32x4_t high, unsigned max) {
+        int16x8_t res;
+
+        // get the hi 16s of all those 32s
+        res = vuzpq_s16(vreinterpretq_s16_s32(low), vreinterpretq_s16_s32(high)).val[1];
+
+        // clamp
+        res = vmaxq_s16(res, vdupq_n_s16(0));
+        res = vminq_s16(res, vdupq_n_s16(max));
+
+        return res;
+    }
+
+    static inline int32x4_t clamp4(int32x4_t f, unsigned max) {
+        int32x4_t res;
+
+        // get the hi 16s of all those 32s
+        res = vshrq_n_s32(f, 16);
+
+        // clamp
+        res = vmaxq_s32(res, vdupq_n_s32(0));
+        res = vminq_s32(res, vdupq_n_s32(max));
+
+        return res;
+    }
+
+    static inline int32x4_t extract_low_bits_clamp4(int32x4_t fx, unsigned) {
+        int32x4_t ret;
+
+        ret = vshrq_n_s32(fx, 12);
+
+        /* We don't need the mask below because the caller will
+         * overwrite the non-masked bits
+         */
+        //ret = vandq_s32(ret, vdupq_n_s32(0xF));
+
+        return ret;
+    }
+
+    static inline int16x8_t repeat8(int32x4_t low, int32x4_t high, unsigned max) {
+        uint16x8_t res;
+        uint32x4_t tmpl, tmph;
+
+        // get the lower 16 bits
+        res = vuzpq_u16(vreinterpretq_u16_s32(low), vreinterpretq_u16_s32(high)).val[0];
+
+        // bare multiplication, not SkFixedMul
+        tmpl = vmull_u16(vget_low_u16(res), vdup_n_u16(max+1));
+        tmph = vmull_u16(vget_high_u16(res), vdup_n_u16(max+1));
+
+        // extraction of the 16 upper bits
+        res = vuzpq_u16(vreinterpretq_u16_u32(tmpl), vreinterpretq_u16_u32(tmph)).val[1];
+
+        return vreinterpretq_s16_u16(res);
+    }
+
+    static inline int32x4_t repeat4(int32x4_t f, unsigned max) {
+        uint16x4_t res;
+        uint32x4_t tmp;
+
+        // get the lower 16 bits
+        res = vmovn_u32(vreinterpretq_u32_s32(f));
+
+        // bare multiplication, not SkFixedMul
+        tmp = vmull_u16(res, vdup_n_u16(max+1));
+
+        // extraction of the 16 upper bits
+        tmp = vshrq_n_u32(tmp, 16);
+
+        return vreinterpretq_s32_u32(tmp);
+    }
+
+    static inline int32x4_t extract_low_bits_repeat_mirror4(int32x4_t fx, unsigned max) {
+        uint16x4_t res;
+        uint32x4_t tmp;
+        int32x4_t ret;
+
+        // get the lower 16 bits
+        res = vmovn_u32(vreinterpretq_u32_s32(fx));
+
+        // bare multiplication, not SkFixedMul
+        tmp = vmull_u16(res, vdup_n_u16(max + 1));
+
+        // shift and mask
+        ret = vshrq_n_s32(vreinterpretq_s32_u32(tmp), 12);
+
+        /* We don't need the mask below because the caller will
+         * overwrite the non-masked bits
+         */
+        //ret = vandq_s32(ret, vdupq_n_s32(0xF));
+
+        return ret;
+    }
+
+    template <unsigned   (*tile)(SkFixed, int),
+              int16x8_t (*tile8)(int32x4_t, int32x4_t, unsigned),
+             bool tryDecal>
+    static void nofilter_scale_neon(const SkBitmapProcState& s,
+                                    uint32_t xy[], int count, int x, int y) {
+
+        // we store y, x, x, x, x, x
+        const unsigned maxX = s.fPixmap.width() - 1;
+        SkFractionalInt fx;
+        {
+            const SkBitmapProcStateAutoMapper mapper(s, x, y);
+            const unsigned maxY = s.fPixmap.height() - 1;
+            *xy++ = tile(mapper.fixedY(), maxY);
+            fx = mapper.fractionalIntX();
+        }
+
+        if (0 == maxX) {
+            // all of the following X values must be 0
+            memset(xy, 0, count * sizeof(uint16_t));
+            return;
+        }
+
+        const SkFractionalInt dx = s.fInvSxFractionalInt;
+
+        // test if we don't need to apply the tile proc
+        const SkFixed fixedFx = SkFractionalIntToFixed(fx);
+        const SkFixed fixedDx = SkFractionalIntToFixed(dx);
+        if (tryDecal && can_truncate_to_fixed_for_decal(fixedFx, fixedDx, count, maxX)) {
+            decal_nofilter_scale_neon(xy, fixedFx, fixedDx, count);
+            return;
+        }
+
+        if (count >= 8) {
+            SkFractionalInt dx2 = dx+dx;
+            SkFractionalInt dx4 = dx2+dx2;
+            SkFractionalInt dx8 = dx4+dx4;
+
+            // now build fx/fx+dx/fx+2dx/fx+3dx
+            SkFractionalInt fx1, fx2, fx3;
+            int32x4_t lbase, hbase;
+            int16_t *dst16 = (int16_t *)xy;
+
+            fx1 = fx+dx;
+            fx2 = fx1+dx;
+            fx3 = fx2+dx;
+
+            lbase = vdupq_n_s32(SkFractionalIntToFixed(fx));
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx1), lbase, 1);
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx2), lbase, 2);
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx3), lbase, 3);
+            hbase = vaddq_s32(lbase, vdupq_n_s32(SkFractionalIntToFixed(dx4)));
+
+            // store & bump
+            while (count >= 8) {
+
+                int16x8_t fx8;
+
+                fx8 = tile8(lbase, hbase, maxX);
+
+                vst1q_s16(dst16, fx8);
+
+                // but preserving base & on to the next
+                lbase = vaddq_s32 (lbase, vdupq_n_s32(SkFractionalIntToFixed(dx8)));
+                hbase = vaddq_s32 (hbase, vdupq_n_s32(SkFractionalIntToFixed(dx8)));
+                dst16 += 8;
+                count -= 8;
+                fx += dx8;
+            }
+            xy = (uint32_t *) dst16;
+        }
+
+        uint16_t* xx = (uint16_t*)xy;
+        for (int i = count; i > 0; --i) {
+            *xx++ = tile(SkFractionalIntToFixed(fx), maxX);
+            fx += dx;
+        }
+    }
+
+    template <unsigned              (*tile )(SkFixed, int),
+              int32x4_t             (*tile4)(int32x4_t, unsigned),
+              unsigned  (*extract_low_bits )(SkFixed, int),
+              int32x4_t (*extract_low_bits4)(int32x4_t, unsigned),
+              bool tryDecal>
+    static void filter_scale_neon(const SkBitmapProcState& s,
+                                  unsigned int * xy, int count, int x, int y) {
+
+        auto pack = [&](SkFixed f, unsigned max, SkFixed one) {
+            unsigned i = tile(f, max);
+            i = (i << 4) | extract_low_bits(f, max);
+            return (i << 14) | (tile((f + one), max));
+        };
+
+        auto pack4 = [&](int32x4_t f, unsigned max, SkFixed one) {
+            int32x4_t ret, res;
+
+            res = tile4(f, max);
+
+            ret = extract_low_bits4(f, max);
+            ret = vsliq_n_s32(ret, res, 4);
+
+            res = tile4(f + vdupq_n_s32(one), max);
+            ret = vorrq_s32(vshlq_n_s32(ret, 14), res);
+
+            return ret;
+        };
+
+        const unsigned maxX = s.fPixmap.width() - 1;
+        const SkFixed one = s.fFilterOneX;
+        const SkFractionalInt dx = s.fInvSxFractionalInt;
+        SkFractionalInt fx;
+
+        {
+            const SkBitmapProcStateAutoMapper mapper(s, x, y);
+            const SkFixed fy = mapper.fixedY();
+            const unsigned maxY = s.fPixmap.height() - 1;
+            // compute our two Y values up front
+            *xy++ = pack(fy, maxY, s.fFilterOneY);
+            // now initialize fx
+            fx = mapper.fractionalIntX();
+        }
+
+        // test if we don't need to apply the tile proc
+        const SkFixed fixedFx = SkFractionalIntToFixed(fx);
+        const SkFixed fixedDx = SkFractionalIntToFixed(dx);
+        if (tryDecal && can_truncate_to_fixed_for_decal(fixedFx, fixedDx, count, maxX)) {
+            decal_filter_scale_neon(xy, fixedFx, fixedDx, count);
+            return;
+        }
+
+#ifndef __ARM_64BIT_STATE
+        if (tile == clamp && one == SK_Fixed1) {
+            SkASSERT(maxX < (1<<14)-1);
+            if (dx >= 0) {
+                --count;
+                while (count >= 0 && fx < 0) {
+                    *xy++ = 0;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 0 && ((uintptr_t) xy & 0xf) && fx < ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                if ((count -= 8-1) >= 0 && fx + 7*dx < ((SkFractionalInt) maxX << 32)) {
+                    SkFractionalInt rem = (((SkFractionalInt) maxX << 32) - 7*dx - fx - 1) / 8;
+                    int32_t rem_hi = rem >> 32;
+                    uint32_t rem_lo = (uint32_t) rem;
+                    int32_t fx_hi = fx >> 32;
+                    uint32_t fx_lo = (uint32_t) fx;
+                    __asm__ (
+                            "vmov        d16, %[fx_lo], %[fx_hi]     \n\t"
+                            "vmov        d24, %[dx_lo], %[dx_hi]     \n\t"
+                            "vadd.i64    d17, d16, d24               \n\t"
+                            "vmov        d25, %[dx_lo], %[dx_hi]     \n\t"
+                            "vmvn.i32    q13, #0x3fff                \n\t"
+                            "vadd.i64    d18, d17, d24               \n\t"
+                            "vmov.i32    q14, #1                     \n\t"
+                            "vadd.i64    d19, d18, d24               \n\t"
+                            "vshl.i64    q12, #2                     \n\t"
+                            "b           2f                          \n\t"
+                            "1:                                      \n\t"
+                            "vadd.i64    q8, q10, q12                \n\t"
+                            "vadd.i64    q9, q11, q12                \n\t"
+                            "2:                                      \n\t"
+                            "vadd.i64    q10, q8, q12                \n\t"
+                            "vadd.i64    q11, q9, q12                \n\t"
+                            "vshrn.i64   d16, q8, #14                \n\t"
+                            "vshrn.i64   d17, q9, #14                \n\t"
+                            "vand        q8, q13                     \n\t"
+                            "vorr        q8, q14                     \n\t"
+                            "vshrn.i64   d18, q10, #14               \n\t"
+                            "vshrn.i64   d19, q11, #14               \n\t"
+                            "vand        q9, q13                     \n\t"
+                            "subs        %[rem_lo], %[dx_lo]         \n\t"
+                            "vorr        q9, q14                     \n\t"
+                            "sbcs        %[rem_hi], %[dx_hi]         \n\t"
+                            "vsra.u32    q8, #18                     \n\t"
+                            "subs        %[count], #8                \n\t"
+                            "vsra.u32    q9, #18                     \n\t"
+                            "it          pl                          \n\t"
+                            "teqpl       %[rem_hi], #0               \n\t"
+                            "vst1.32     {q8-q9}, [%[dst]:128]!      \n\t"
+                            "bpl         1b                          \n\t"
+                            "vadd.i64    d16, d20, d24               \n\t"
+                            "vmov        %[fx_lo], %[fx_hi], d16     \n\t"
+                    : // Outputs
+                             [count]"+l"(count),
+                               [dst]"+r"(xy),
+                            [rem_hi]"+l"(rem_hi),
+                            [rem_lo]"+l"(rem_lo),
+                             [fx_hi]"+r"(fx_hi),
+                             [fx_lo]"+r"(fx_lo)
+                    : // Inputs
+                            [dx_hi]"l"((int32_t) (dx >> 32)),
+                            [dx_lo]"l"((uint32_t) dx)
+                    : // Clobbers
+                            "cc", "memory"
+                    );
+                    fx = ((SkFractionalInt) fx_hi << 32) | fx_lo;
+                }
+                count += 8-1;
+                while (count >= 0 && fx < ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 0) {
+                    *xy++ = (maxX << 18) + maxX;
+                    --count;
+                }
+            } else {
+                // Reflection case. Don't bother to optimize this as much -
+                // not even sure if it's used!
+                while (count >= 1 && fx >= ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = (maxX << 18) + maxX;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 1 && fx >= 0) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 1) {
+                    *xy++ = 0;
+                    --count;
+                }
+            }
+        }
+        else
+        {
+        // Drop back to old code for repeat or other values of 'one'
+#endif
+        if (count >= 4) {
+            int32x4_t wide_fx;
+
+            wide_fx = vdupq_n_s32(SkFractionalIntToFixed(fx));
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx), wide_fx, 1);
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx+dx), wide_fx, 2);
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx+dx+dx), wide_fx, 3);
+
+            while (count >= 4) {
+                int32x4_t res;
+
+                res = pack4(wide_fx, maxX, one);
+
+                vst1q_u32(xy, vreinterpretq_u32_s32(res));
+
+                wide_fx += vdupq_n_s32(SkFractionalIntToFixed(dx+dx+dx+dx));
+                fx += dx+dx+dx+dx;
+                xy += 4;
+                count -= 4;
+            }
+        }
+
+        while (--count >= 0) {
+            *xy++ = pack(SkFractionalIntToFixed(fx), maxX, one);
+            fx += dx;
+        }
+#ifndef __ARM_64BIT_STATE
+        }
+#endif
+    }
+
+    static const SkBitmapProcState::MatrixProc ClampX_ClampY_Procs[] = {
+        nofilter_scale_neon<clamp, clamp8, true>,
+        filter_scale_neon<clamp,
+                          clamp4,
+                          extract_low_bits_clamp_clamp,
+                          extract_low_bits_clamp4,
+                          true>,
+        nofilter_affine<clamp, clamp>,       filter_affine<clamp, clamp, extract_low_bits_clamp_clamp>,
+    };
+
+    static const SkBitmapProcState::MatrixProc RepeatX_RepeatY_Procs[] = {
+        nofilter_scale_neon<repeat, repeat8, false>,
+        filter_scale_neon<repeat,
+                          repeat4,
+                          extract_low_bits_general,
+                          extract_low_bits_repeat_mirror4,
+                          false>,
+        nofilter_affine<repeat, repeat>,        filter_affine<repeat, repeat, extract_low_bits_general>
+    };
+#else
+
 static const SkBitmapProcState::MatrixProc ClampX_ClampY_Procs[] = {
     nofilter_scale <clamp, clamp, true>, filter_scale <clamp, clamp, extract_low_bits_clamp_clamp, true>,
     nofilter_affine<clamp, clamp>,       filter_affine<clamp, clamp, extract_low_bits_clamp_clamp>,
@@ -255,6 +779,9 @@ static const SkBitmapProcState::MatrixPr
     nofilter_scale <repeat, repeat, false>, filter_scale <repeat, repeat, extract_low_bits_general, false>,
     nofilter_affine<repeat, repeat>,        filter_affine<repeat, repeat, extract_low_bits_general>
 };
+
+#endif
+
 static const SkBitmapProcState::MatrixProc MirrorX_MirrorY_Procs[] = {
     nofilter_scale <mirror, mirror,  false>, filter_scale <mirror, mirror, extract_low_bits_general, false>,
     nofilter_affine<mirror, mirror>,         filter_affine<mirror, mirror, extract_low_bits_general>,
--- a/src/third_party/skia/src/core/SkBlitter_ARGB32.cpp
+++ b/src/third_party/skia/src/core/SkBlitter_ARGB32.cpp
@@ -11,6 +11,7 @@
 #include "src/core/SkCoreBlitters.h"
 #include "src/core/SkOpts.h"
 #include "src/core/SkXfermodePriv.h"
+#include "src/opts/SkBlitMask_opts.h"
 
 static inline int upscale_31_to_32(int value) {
     SkASSERT((unsigned)value <= 31);
@@ -1184,6 +1185,7 @@ static void drive(SkPMColor* dst, const
     }
 }
 
+#if 0
 static void blend_row_A8(SkPMColor* dst, const void* mask, const SkPMColor* src, int n) {
     auto cov = (const uint8_t*)mask;
     drive(dst, src, cov, n, [](U8x4 d, U8x4 s, U8x4 c) {
@@ -1192,6 +1194,7 @@ static void blend_row_A8(SkPMColor* dst,
         return s_aa + skvx::approx_scale(d, 255 - alpha);
     });
 }
+#endif
 
 static void blend_row_A8_opaque(SkPMColor* dst, const void* mask, const SkPMColor* src, int n) {
     auto cov = (const uint8_t*)mask;
@@ -1296,7 +1299,8 @@ void SkARGB32_Shader_Blitter::blitMask(c
         if (mask.fFormat == SkMask::kA8_Format && opaque) {
             blend_row = blend_row_A8_opaque;
         } else if (mask.fFormat == SkMask::kA8_Format) {
-            blend_row = blend_row_A8;
+            // blend_row_A8 has been ported to SkOpts, but not the others yet
+            blend_row = SkOpts::blit_row_s32a_a8;
         } else if (mask.fFormat == SkMask::kLCD16_Format && opaque) {
             blend_row = blend_row_LCD16_opaque;
         } else if (mask.fFormat == SkMask::kLCD16_Format) {
--- a/src/third_party/skia/src/core/SkOpts.cpp
+++ b/src/third_party/skia/src/core/SkOpts.cpp
@@ -58,6 +58,7 @@ namespace SkOpts {
     DEFINE_DEFAULT(create_xfermode);
 
     DEFINE_DEFAULT(blit_mask_d32_a8);
+    DEFINE_DEFAULT(blit_row_s32a_a8);
 
     DEFINE_DEFAULT(blit_row_color32);
     DEFINE_DEFAULT(blit_row_s32a_opaque);
@@ -89,6 +90,11 @@ namespace SkOpts {
     DEFINE_DEFAULT(S32_alpha_D32_filter_DXDY);
 
     DEFINE_DEFAULT(interpret_skvm);
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+    DEFINE_DEFAULT(S32_opaque_D32_filter_DX);
+#else
+    decltype(S32_opaque_D32_filter_DX) S32_opaque_D32_filter_DX = SK_OPTS_NS::S32_alpha_D32_filter_DX;
+#endif
 #undef DEFINE_DEFAULT
 
 #define M(st) (StageFn)SK_OPTS_NS::st,
--- a/src/third_party/skia/src/core/SkOpts.h
+++ b/src/third_party/skia/src/core/SkOpts.h
@@ -32,6 +32,7 @@ namespace SkOpts {
 
     extern void (*blit_mask_d32_a8)(SkPMColor*, size_t, const SkAlpha*, size_t, SkColor, int, int);
     extern void (*blit_row_color32)(SkPMColor*, const SkPMColor*, int, SkPMColor);
+    extern void (*blit_row_s32a_a8)(SkPMColor*, const void*, const SkPMColor*, int);
     extern void (*blit_row_s32a_opaque)(SkPMColor*, const SkPMColor*, int, U8CPU);
 
     // Swizzle input into some sort of 8888 pixel, {premul,unpremul} x {rgba,bgra}.
@@ -69,6 +70,9 @@ namespace SkOpts {
     extern void (*S32_alpha_D32_filter_DXDY)(const SkBitmapProcState&,
                                              const uint32_t* xy, int count, SkPMColor*);
 
+    extern void (*S32_opaque_D32_filter_DX)(const SkBitmapProcState&,
+                                            const uint32_t* xy, int count, SkPMColor*);
+
 #define M(st) +1
     // We can't necessarily express the type of SkJumper stage functions here,
     // so we just use this void(*)(void) as a stand-in.
--- a/src/third_party/skia/src/opts/SkBitmapProcState_opts.h
+++ b/src/third_party/skia/src/opts/SkBitmapProcState_opts.h
@@ -387,6 +387,256 @@ static void decode_packed_coordinates_an
         }
     }
 
+#elif defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+#define S32_ALPHA_D32_FILTER_DX_1PIX_NEON(opt)               \
+            "ldr         %[x], [%[xy]], #4           \n\t"   \
+            "uxth        %[tmp2], %[x], ror #16      \n\t"   \
+            "lsl         %[tmp3], %[x], #2           \n\t"   \
+            "bic         %[tmp2], #3                 \n\t"   \
+            "uxth        %[tmp3], %[tmp3]            \n\t"   \
+            "add         %[tmp0], %[row0], %[tmp2]   \n\t"   \
+            "add         %[tmp1], %[row0], %[tmp3]   \n\t"   \
+            "add         %[tmp2], %[row1], %[tmp2]   \n\t"   \
+            "add         %[tmp3], %[row1], %[tmp3]   \n\t"   \
+            "lsr         %[x], #14                   \n\t"   \
+            "vldr        s0, [%[tmp0]]               \n\t"   \
+            "and         %[x], #0xf                  \n\t"   \
+            "vldr        s1, [%[tmp1]]               \n\t"   \
+            "vldr        s2, [%[tmp2]]               \n\t"   \
+            "vldr        s3, [%[tmp3]]               \n\t"   \
+            "vdup.16     d2, %[x]                    \n\t"   \
+            "vsub.i16    d3, d23, d2                 \n\t"   \
+            "vmull.u8    q2, d0, d31                 \n\t"   \
+            "vmlal.u8    q2, d1, d30                 \n\t"   \
+            "vmul.u16    d0, d4, d3                  \n\t"   \
+            "vmla.u16    d0, d5, d2                  \n\t"   \
+            "vshr.u16    d0, #8                      \n\t"   \
+            "vmul.u16    d0, d10                     \n\t"   \
+            opt"                                     \n\t"   \
+            "vshrn.u16   d0, q0, #8                  \n\t"   \
+            "vst1.32     {d0[0]}, [%[dst]:32]!       \n\t"   \
+
+void S32_alpha_D32_filter_DX(const SkBitmapProcState& s,
+                             const uint32_t* SK_RESTRICT xy,
+                             int count, SkPMColor* SK_RESTRICT colors) {
+    SkASSERT(count > 0 && colors != nullptr);
+    SkASSERT(4 == s.fPixmap.info().bytesPerPixel());
+    SkASSERT(s.fAlphaScale <= 256);
+
+    int y0, y1, wy;
+    decode_packed_coordinates_and_weight(*xy++, &y0, &y1, &wy);
+
+    auto row0 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y0 * s.fPixmap.rowBytes() ),
+         row1 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y1 * s.fPixmap.rowBytes() );
+
+    uint32_t tmp0, tmp1, tmp2, tmp3, x;
+    __asm__ volatile (
+            "vpush       {q4-q5}                     \n\t"
+            "vmov.i16    d22, #0xf                   \n\t"
+            "vmov.i16    d23, #0x10                  \n\t"
+            "vmov.i32    q12, #0x3fff                \n\t"
+            "vdup.32     q13, %[row0]                \n\t"
+            "vdup.32     q14, %[row1]                \n\t"
+            "vdup.i8     d30, %[subY]                \n\t"
+            "vmov.i8     d31, #16                    \n\t"
+            "vdup.16     q5, %[alpha]                \n\t"
+            "vshl.i32    q12, #2                     \n\t"
+            "tst         %[dst], #0xc                \n\t"
+            "vsub.i8     d31, d30                    \n\t"
+            "beq         2f                          \n\t"
+
+            "1:                                      \n\t"
+            S32_ALPHA_D32_FILTER_DX_1PIX_NEON(
+            "add         %[tmp0], %[dst], #4         \n\t"
+            "subs        %[len], #1                  \n\t"
+            "it          ne                          \n\t"
+            "tstne       %[tmp0], #0xc"
+            )
+            "bne         1b                          \n\t"
+
+            "2:"
+            "subs        %[len], #4                  \n\t"
+            "bmi         13f                         \n\t"
+
+            "vld1.32     {q8}, [%[xy]]!              \n\t"
+            "vshr.u32    q9, q8, #16                 \n\t"
+            "vand        q9, q12                     \n\t"
+            "vadd.i32    q1, q13, q9                 \n\t"
+            "vshl.i32    q0, q8, #2                  \n\t"
+            "vand        q0, q12                     \n\t"
+            "vadd.i32    q2, q13, q0                 \n\t"
+            "vmov        %[tmp0], s4                 \n\t"
+            "vmov        %[tmp1], s5                 \n\t"
+            "vadd.i32    q3, q14, q9                 \n\t"
+            "vmov        %[tmp2], %[tmp3], d3        \n\t"
+
+            "11:                                     \n\t"
+            "vadd.i32    q4, q14, q0                 \n\t"
+            "vldr        s4, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s8                 \n\t"
+            "vldr        s5, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s9                 \n\t"
+            "vldr        s6, [%[tmp2]]               \n\t"
+            "vmov        %[tmp2], s10                \n\t"
+            "vldr        s7, [%[tmp3]]               \n\t"
+            "vmov        %[tmp3], s11                \n\t"
+            "vldr        s8, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s12                \n\t"
+            "vldr        s9, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s13                \n\t"
+            "vldr        s10, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s14                \n\t"
+            "vldr        s11, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s15                \n\t"
+            "vldr        s12, [%[tmp0]]              \n\t"
+            "vmov        %[tmp0], s16                \n\t"
+            "vldr        s13, [%[tmp1]]              \n\t"
+            "vmov        %[tmp1], s17                \n\t"
+            "vldr        s14, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s18                \n\t"
+            "vldr        s15, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s19                \n\t"
+            "vldr        s16, [%[tmp0]]              \n\t"
+            "vshrn.i32   d1, q8, #14                 \n\t"
+            "vldr        s17, [%[tmp1]]              \n\t"
+            "vand        d1, d22                     \n\t"
+            "vldr        s18, [%[tmp2]]              \n\t"
+            "vsub.i16    d0, d23, d1                 \n\t"
+            "vldr        s19, [%[tmp3]]              \n\t"
+            "vmull.u8    q10, d2, d31                \n\t"
+            "vmlal.u8    q10, d6, d30                \n\t"
+            "vmull.u8    q1, d3, d31                 \n\t"
+            "vmlal.u8    q1, d7, d30                 \n\t"
+            "vmull.u8    q3, d4, d31                 \n\t"
+            "subs        %[len], #4                  \n\t"
+            "vmlal.u8    q3, d8, d30                 \n\t"
+            "bmi         12f                         \n\t"
+
+            "  vld1.32     {q8}, [%[xy]]!            \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "  vshr.u32    d18, d16, #16             \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "  vshr.u32    d19, d17, #16             \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "  vand        d18, d24                  \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "  vand        d19, d25                  \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "  vadd.i32    d2, d26, d18              \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "  vadd.i32    d3, d27, d19              \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "  vshl.i32    d0, d16, #2               \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "  vshl.i32    d1, d17, #2               \n\t"
+            "  vand        q0, q12                   \n\t"
+            "  vadd.i32    q2, q13, q0               \n\t"
+            "vshr.u16    q4, #8                      \n\t"
+            "vshr.u16    q10, #8                     \n\t"
+            "vmul.u16    q4, q5                      \n\t"
+            "vmul.u16    q10, q5                     \n\t"
+            "  vmov        %[tmp0], %[tmp1], d2      \n\t"
+            "  vadd.i32    q3, q14, q9               \n\t"
+            "  vmov        %[tmp2], %[tmp3], d3      \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+            "b           11b                         \n\t"
+
+            "12:                                     \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "vshr.u16    q4, #8                      \n\t"
+            "vshr.u16    q10, #8                     \n\t"
+            "vmul.u16    q4, q5                      \n\t"
+            "vmul.u16    q10, q5                     \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+
+            "13:                                     \n\t"
+            "adds        %[len], #4-1                \n\t"
+            "bmi         22f                         \n\t"
+
+            "21:                                     \n\t"
+            S32_ALPHA_D32_FILTER_DX_1PIX_NEON("subs %[len], #1")
+            "bpl         21b                         \n\t"
+
+            "22:                                     \n\t"
+            "vpop        {q4-q5}                     \n\t"
+    : // Outputs
+             [dst]"+r"(colors),
+              [xy]"+r"(xy),
+             [len]"+r"(count),
+            [tmp0]"=&r"(tmp0),
+            [tmp1]"=&r"(tmp1),
+            [tmp2]"=&r"(tmp2),
+            [tmp3]"=&r"(tmp3),
+               [x]"=&r"(x)
+    : // Inputs
+            [alpha]"r"(s.fAlphaScale),
+             [row0]"r"(row0),
+             [row1]"r"(row1),
+             [subY]"r"(wy)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+
+        // Copied from just below
+        static void filter_and_scale_by_alpha(unsigned x, unsigned y,
+                                              SkPMColor a00, SkPMColor a01,
+                                              SkPMColor a10, SkPMColor a11,
+                                              SkPMColor *dst,
+                                              uint16_t scale) {
+            uint8x8_t vy, vconst16_8, v16_y, vres;
+            uint16x4_t vx, vconst16_16, v16_x, tmp, vscale;
+            uint32x2_t va0, va1;
+            uint16x8_t tmp1, tmp2;
+
+            vy = vdup_n_u8(y);                // duplicate y into vy
+            vconst16_8 = vmov_n_u8(16);       // set up constant in vconst16_8
+            v16_y = vsub_u8(vconst16_8, vy);  // v16_y = 16-y
+
+            va0 = vdup_n_u32(a00);            // duplicate a00
+            va1 = vdup_n_u32(a10);            // duplicate a10
+            va0 = vset_lane_u32(a01, va0, 1); // set top to a01
+            va1 = vset_lane_u32(a11, va1, 1); // set top to a11
+
+            tmp1 = vmull_u8(vreinterpret_u8_u32(va0), v16_y); // tmp1 = [a01|a00] * (16-y)
+            tmp2 = vmull_u8(vreinterpret_u8_u32(va1), vy);    // tmp2 = [a11|a10] * y
+
+            vx = vdup_n_u16(x);                // duplicate x into vx
+            vconst16_16 = vmov_n_u16(16);      // set up constant in vconst16_16
+            v16_x = vsub_u16(vconst16_16, vx); // v16_x = 16-x
+
+            tmp = vmul_u16(vget_high_u16(tmp1), vx);        // tmp  = a01 * x
+            tmp = vmla_u16(tmp, vget_high_u16(tmp2), vx);   // tmp += a11 * x
+            tmp = vmla_u16(tmp, vget_low_u16(tmp1), v16_x); // tmp += a00 * (16-x)
+            tmp = vmla_u16(tmp, vget_low_u16(tmp2), v16_x); // tmp += a10 * (16-x)
+
+            if (scale < 256) {
+                vscale = vdup_n_u16(scale);        // duplicate scale
+                tmp = vshr_n_u16(tmp, 8);          // shift down result by 8
+                tmp = vmul_u16(tmp, vscale);       // multiply result by scale
+            }
+
+            vres = vshrn_n_u16(vcombine_u16(tmp, vcreate_u16(0)), 8); // shift down result by 8
+            vst1_lane_u32(dst, vreinterpret_u32_u8(vres), 0);         // store result
+        }
+
+
 #else
 
     // The NEON code only actually differs from the portable code in the
@@ -533,6 +783,202 @@ static void decode_packed_coordinates_an
                                                        const uint32_t*, int, SkPMColor*) = nullptr;
 #endif
 
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+#define S32_OPAQUE_D32_FILTER_DX_1PIX_NEON(opt)              \
+            "ldr         %[x], [%[xy]], #4           \n\t"   \
+            "uxth        %[tmp2], %[x], ror #16      \n\t"   \
+            "lsl         %[tmp3], %[x], #2           \n\t"   \
+            "bic         %[tmp2], #3                 \n\t"   \
+            "uxth        %[tmp3], %[tmp3]            \n\t"   \
+            "add         %[tmp0], %[row0], %[tmp2]   \n\t"   \
+            "add         %[tmp1], %[row0], %[tmp3]   \n\t"   \
+            "add         %[tmp2], %[row1], %[tmp2]   \n\t"   \
+            "add         %[tmp3], %[row1], %[tmp3]   \n\t"   \
+            "lsr         %[x], #14                   \n\t"   \
+            "vldr        s0, [%[tmp0]]               \n\t"   \
+            "and         %[x], #0xf                  \n\t"   \
+            "vldr        s1, [%[tmp1]]               \n\t"   \
+            "vldr        s2, [%[tmp2]]               \n\t"   \
+            "vldr        s3, [%[tmp3]]               \n\t"   \
+            "vdup.16     d2, %[x]                    \n\t"   \
+            "vsub.i16    d3, d23, d2                 \n\t"   \
+            "vmull.u8    q2, d0, d31                 \n\t"   \
+            "vmlal.u8    q2, d1, d30                 \n\t"   \
+            "vmul.u16    d0, d4, d3                  \n\t"   \
+            "vmla.u16    d0, d5, d2                  \n\t"   \
+            opt"                                     \n\t"   \
+            "vshrn.u16   d0, q0, #8                  \n\t"   \
+            "vst1.32     {d0[0]}, [%[dst]:32]!       \n\t"   \
+
+void S32_opaque_D32_filter_DX(const SkBitmapProcState& s,
+                              const uint32_t* SK_RESTRICT xy,
+                              int count, SkPMColor* SK_RESTRICT colors) {
+    SkASSERT(count > 0 && colors != nullptr);
+    SkASSERT(4 == s.fPixmap.info().bytesPerPixel());
+    SkASSERT(s.fAlphaScale == 256);
+
+    int y0, y1, wy;
+    decode_packed_coordinates_and_weight(*xy++, &y0, &y1, &wy);
+
+    auto row0 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y0 * s.fPixmap.rowBytes() ),
+         row1 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y1 * s.fPixmap.rowBytes() );
+
+    uint32_t tmp0, tmp1, tmp2, tmp3, x;
+    __asm__ volatile (
+            "vpush       {q4}                        \n\t"
+            "vmov.i16    d22, #0xf                   \n\t"
+            "vmov.i16    d23, #0x10                  \n\t"
+            "vmov.i32    q12, #0x3fff                \n\t"
+            "vdup.32     q13, %[row0]                \n\t"
+            "vdup.32     q14, %[row1]                \n\t"
+            "vdup.i8     d30, %[subY]                \n\t"
+            "vmov.i8     d31, #16                    \n\t"
+            "vshl.i32    q12, #2                     \n\t"
+            "tst         %[dst], #0xc                \n\t"
+            "vsub.i8     d31, d30                    \n\t"
+            "beq         2f                          \n\t"
+
+            "1:                                      \n\t"
+            S32_OPAQUE_D32_FILTER_DX_1PIX_NEON(
+            "add         %[tmp0], %[dst], #4         \n\t"
+            "subs        %[len], #1                  \n\t"
+            "it          ne                          \n\t"
+            "tstne       %[tmp0], #0xc"
+            )
+            "bne         1b                          \n\t"
+
+            "2:"
+            "subs        %[len], #4                  \n\t"
+            "bmi         13f                         \n\t"
+
+            "vld1.32     {q8}, [%[xy]]!              \n\t"
+            "vshr.u32    q9, q8, #16                 \n\t"
+            "vand        q9, q12                     \n\t"
+            "vadd.i32    q1, q13, q9                 \n\t"
+            "vshl.i32    q0, q8, #2                  \n\t"
+            "vand        q0, q12                     \n\t"
+            "vadd.i32    q2, q13, q0                 \n\t"
+            "vmov        %[tmp0], s4                 \n\t"
+            "vmov        %[tmp1], s5                 \n\t"
+
+            "11:                                     \n\t"
+            "vadd.i32    q3, q14, q9                 \n\t"
+            "vmov        %[tmp2], %[tmp3], d3        \n\t"
+            "vadd.i32    q4, q14, q0                 \n\t"
+            "vldr        s4, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s8                 \n\t"
+            "vldr        s5, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s9                 \n\t"
+            "vldr        s6, [%[tmp2]]               \n\t"
+            "vmov        %[tmp2], s10                \n\t"
+            "vldr        s7, [%[tmp3]]               \n\t"
+            "vmov        %[tmp3], s11                \n\t"
+            "vldr        s8, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s12                \n\t"
+            "vldr        s9, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s13                \n\t"
+            "vldr        s10, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s14                \n\t"
+            "vldr        s11, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s15                \n\t"
+            "vldr        s12, [%[tmp0]]              \n\t"
+            "vmov        %[tmp0], s16                \n\t"
+            "vldr        s13, [%[tmp1]]              \n\t"
+            "vmov        %[tmp1], s17                \n\t"
+            "vldr        s14, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s18                \n\t"
+            "vldr        s15, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s19                \n\t"
+            "vldr        s16, [%[tmp0]]              \n\t"
+            "vshrn.i32   d1, q8, #14                 \n\t"
+            "vldr        s17, [%[tmp1]]              \n\t"
+            "vand        d1, d22                     \n\t"
+            "vldr        s18, [%[tmp2]]              \n\t"
+            "vsub.i16    d0, d23, d1                 \n\t"
+            "vldr        s19, [%[tmp3]]              \n\t"
+            "vmull.u8    q10, d2, d31                \n\t"
+            "vmlal.u8    q10, d6, d30                \n\t"
+            "vmull.u8    q1, d3, d31                 \n\t"
+            "vmlal.u8    q1, d7, d30                 \n\t"
+            "vmull.u8    q3, d4, d31                 \n\t"
+            "subs        %[len], #4                  \n\t"
+            "vmlal.u8    q3, d8, d30                 \n\t"
+            "bmi         12f                         \n\t"
+
+            "  vld1.32     {q8}, [%[xy]]!            \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "  vshr.u32    d18, d16, #16             \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "  vshr.u32    d19, d17, #16             \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "  vand        d18, d24                  \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "  vand        d19, d25                  \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "  vadd.i32    d2, d26, d18              \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "  vadd.i32    d3, d27, d19              \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "  vshl.i32    d0, d16, #2               \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "  vshl.i32    d1, d17, #2               \n\t"
+            "  vand        q0, q12                   \n\t"
+            "  vadd.i32    q2, q13, q0               \n\t"
+            "  vmov        %[tmp0], s4               \n\t"
+            "  vmov        %[tmp1], s5               \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+            "b           11b                         \n\t"
+
+            "12:                                     \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+
+            "13:                                     \n\t"
+            "adds        %[len], #4-1                \n\t"
+            "bmi         22f                         \n\t"
+
+            "21:                                     \n\t"
+            S32_OPAQUE_D32_FILTER_DX_1PIX_NEON("subs %[len], #1")
+            "bpl         21b                         \n\t"
+
+            "22:                                     \n\t"
+            "vpop        {q4}                        \n\t"
+    : // Outputs
+             [dst]"+r"(colors),
+              [xy]"+r"(xy),
+             [len]"+r"(count),
+            [tmp0]"=&r"(tmp0),
+            [tmp1]"=&r"(tmp1),
+            [tmp2]"=&r"(tmp2),
+            [tmp3]"=&r"(tmp3),
+               [x]"=&r"(x)
+    : // Inputs
+            [row0]"r"(row0),
+            [row1]"r"(row1),
+            [subY]"r"(wy)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+
+#endif
+
 }  // namespace SK_OPTS_NS
 
 #endif
--- a/src/third_party/skia/src/opts/SkBlitMask_opts.h
+++ b/src/third_party/skia/src/opts/SkBlitMask_opts.h
@@ -228,6 +228,322 @@ namespace SK_OPTS_NS {
     }
 }
 
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+// These macros permit optionally-included features to be switched using a parameter to another macro
+#define ARM_YES(x) x
+#define ARM_NO(x)
+
+// How far ahead (pixels) to preload (undefine to disable prefetch) - determined empirically
+#define PREFETCH_DISTANCE "52"
+
+#ifdef PREFETCH_DISTANCE
+#define IF_PRELOAD ARM_YES
+#else
+#define IF_PRELOAD ARM_NO
+#endif
+
+/// Macro to load 1..7 source and mask pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_A8_LOAD_SM_LEADING_7(r0, r1, r2, r3, s_base, r4, m_base, opt1, opt2)                       \
+                opt1"                                                                           \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                opt2"                                                                           \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[1]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[2]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[3]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[4]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[5]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[6]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[7]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load or store 1..7 destination pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_A8_LOADSTORE_D_LEADING_7(ls, r0, r1, r2, r3, d_base)                                       \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#d_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "add         %[tmp], %["#d_base"], #4                                           \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load 1..7 source and mask pixels in shrinking powers-of-2 in size - suitable for trailing pixels
+#define S32A_A8_LOAD_SM_TRAILING_7(r0, r1, r2, r3, s_base, r4, m_base, opt1, opt2)                      \
+                opt1"                                                                           \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                opt2"                                                                           \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[0]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[1]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[2]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[3]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[4]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[5]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[6]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load or store 1..7 destination pixels in shrinking powers-of-2 in size - suitable for trailing pixels
+#define S32A_A8_LOADSTORE_D_TRAILING_7(ls, r0, r1, r2, r3, d_base)                                      \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "add         %[tmp], %["#d_base"], #4                                           \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#d_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to do shortcut testing for "over" compositing of 32bpp premultiplied ARGB source and 8-bit alpha mask
+#define S32A_A8_TEST(dst_adjust)                                                                        \
+                "vmov        %[mlo], %[mhi], d16                                                \n\t"   \
+                "vmov        %[alo], s6                                                         \n\t"   \
+                "vmov        %[ahi], s7                                                         \n\t"   \
+                "and         %[tmp], %[mlo], %[mhi]                                             \n\t"   \
+                "orrs        %[mlo], %[mhi]                                                     \n\t"   \
+                "it          ne                                                                 \n\t"   \
+                "orrsne      %[mlo], %[alo], %[ahi]                                             \n\t"   \
+                "it          eq                                                                 \n\t"   \
+                "addeq       %[dst], " dst_adjust "                                             \n\t"   \
+                "beq         9f                                                                 \n\t"   \
+                "and         %[tmp], %[alo]                                                     \n\t"   \
+                "and         %[tmp], %[ahi]                                                     \n\t"   \
+                "cmp         %[tmp], #-1                                                        \n\t"   \
+                "beq         5f                                                                 \n\t"   \
+
+/// Macro to do testing and "over" compositing of a group of 1..7 32bpp premultiplied ARGB source and 1..7 8-bit alpha mask leading or trailing pixels
+#define S32A_A8_7PIX_PROCESS(load_sm_7, loadstore_d_7, size)                                            \
+    do {                                                                                                \
+        __asm__ volatile (                                                                              \
+                /* Load the leading/trailing source pixels,                                             \
+                 * after initialising all the unused indexes from the first pixel                       \
+                 * so the all-opaque and all-transparent tests still work */                            \
+                load_sm_7(d0, d1, d2, d3, src, d16, msk,                                                \
+                "vld1.8      {d16[]}, [%[msk]]",                                                        \
+                "vld4.8      {d0[], d1[], d2[], d3[]}, [%[src]]")                                       \
+                S32A_A8_TEST("%[group_size], lsl #2")                                                   \
+                /* Translucency used, or a mixture of opaque and transparent */                         \
+                loadstore_d_7(ld, d4, d5, d6, d7, dst)                                                  \
+                "sub         %[dst], %[group_size], lsl #2                                      \n\t"   \
+                S32A_A8_8PIX_BLEND(, ARM_NO, ARM_NO)                                                      \
+                loadstore_d_7(st, d0, d1, d2, d3, dst)                                                  \
+                /* Drop through */                                                                      \
+                "9:                                                                             \n\t"   \
+        : /* Outputs */                                                                                 \
+                [mlo]"=&r"(mlo),                                                                        \
+                [mhi]"=&r"(mhi),                                                                        \
+                [alo]"=&r"(alo),                                                                        \
+                [ahi]"=&r"(ahi),                                                                        \
+                [tmp]"=&r"(tmp),                                                                        \
+                [src]"+r"(src),                                                                         \
+                [msk]"+r"(msk),                                                                         \
+                [dst]"+r"(dst)                                                                          \
+        : /* Inputs */                                                                                  \
+                [group_size]"r"(size),                                                                  \
+                     [eight]"r"(eight)                                                                  \
+        : /* Clobbers */                                                                                \
+                "cc", "memory"                                                                          \
+        );                                                                                              \
+    } while (0)
+
+/// Macro to do "over" compositing blending on 8 32bpp premultiplied ARGB source and 8 8-bit alpha mask pixels
+/// which are with either translucent or a mixture of opaque and transparent.
+/// Relies on A(x) to determine whether to emit code in ARM state (as opposed to Thumb state).
+/// @arg align           bit-alignment specifier on destination loads/stores (optional)
+/// @arg if_loadstore    ARM_YES or ARM_NO: whether to do load/store of destination
+/// @arg if_preload      ARM_YES or ARM_NO: whether to insert prefetch instructions
+#define S32A_A8_8PIX_BLEND(align, if_loadstore, if_preload)                                        \
+if_loadstore(   "vld4.8      {d4-d7}, [%[dst]"#align"]                                          \n\t")  \
+if_preload(     "sub         %[tmp], %[len], #1                                                 \n\t")  \
+                "vmull.u8    q9, d3, d16                                                        \n\t"   \
+if_preload(     "cmp         %[tmp], #" PREFETCH_DISTANCE "                                     \n\t")  \
+                "vmull.u8    q10, d0, d16                                                       \n\t"   \
+if_preload(     "it          cs                                                                 \n\t")  \
+if_preload(     "movcs       %[tmp], #" PREFETCH_DISTANCE "                                     \n\t")  \
+                "vmull.u8    q11, d1, d16                                                       \n\t"   \
+                "vmull.u8    q8, d2, d16                                                        \n\t"   \
+                "vrshr.u16   q1, q9, #8                                                         \n\t"   \
+if_preload(     "pld         [%[msk], %[tmp]]                                                   \n\t")  \
+                "vrshr.u16   q0, q10, #8                                                        \n\t"   \
+if_preload(     "pld         [%[src], %[tmp], lsl #2]                                           \n\t")  \
+                "vraddhn.u16 d3, q9, q1                                                         \n\t"   \
+if_preload(     "add         %[tmp], #32/4                                                      \n\t")  \
+                "vrshr.u16   q9, q11, #8                                                        \n\t"   \
+                "vrshr.u16   q12, q8, #8                                                        \n\t"   \
+                "vmvn        d2, d3                                                             \n\t"   \
+if_preload(     "pld         [%[dst], %[tmp], lsl #2]                                           \n\t")  \
+                "vraddhn.u16 d0, q10, q0                                                        \n\t"   \
+                "vmull.u8    q10, d4, d2                                                        \n\t"   \
+                "vmull.u8    q13, d5, d2                                                        \n\t"   \
+                "vmull.u8    q14, d6, d2                                                        \n\t"   \
+                "vmull.u8    q15, d7, d2                                                        \n\t"   \
+                "vrshr.u16   q2, q10, #8                                                        \n\t"   \
+                "vrshr.u16   q3, q13, #8                                                        \n\t"   \
+                "vraddhn.u16 d1, q11, q9                                                        \n\t"   \
+                "vrshr.u16   q9, q14, #8                                                        \n\t"   \
+                "vrshr.u16   q11, q15, #8                                                       \n\t"   \
+                "vraddhn.u16 d4, q10, q2                                                        \n\t"   \
+                "vraddhn.u16 d5, q13, q3                                                        \n\t"   \
+                "vraddhn.u16 d2, q8, q12                                                        \n\t"   \
+                "vraddhn.u16 d6, q14, q9                                                        \n\t"   \
+                "vraddhn.u16 d7, q15, q11                                                       \n\t"   \
+                "vadd.u8     q0, q2                                                             \n\t"   \
+                "vadd.u8     q1, q3                                                             \n\t"   \
+                "5:                                                                             \n\t"   \
+if_loadstore(   "vst4.8      {d0-d3}, [%[dst]"#align"]!                                         \n\t")  \
+
+#endif
+
+/*not static*/ inline
+void blit_row_s32a_a8(SkPMColor* dst, const void* vmask, const SkPMColor* src, int n) {
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+    const SkAlpha* msk = static_cast<const SkAlpha*>(vmask);
+    uint32_t tmp, mlo, mhi, alo, ahi;
+    const int eight = 8;
+    if (n < 15) {
+        // Too short to attempt aligned processing
+        if (n & 8) {
+            __asm__ (
+                    "vld1.8      {d16}, [%[msk]]!                                                   \n\t"
+                    "vld4.8      {d0-d3}, [%[src]]!                                                 \n\t"
+                    S32A_A8_TEST("#8*4")
+                    /* Translucency used, or a mixture of opaque and transparent */
+                    S32A_A8_8PIX_BLEND(, ARM_YES, ARM_NO)
+                    /* Drop through */
+                    "9:                                                                             \n\t"
+            :  /* Outputs */
+                    [mlo]"=&r"(mlo),
+                    [mhi]"=&r"(mhi),
+                    [alo]"=&r"(alo),
+                    [ahi]"=&r"(ahi),
+                    [tmp]"=&r"(tmp),
+                    [src]"+r"(src),
+                    [msk]"+r"(msk),
+                    [dst]"+r"(dst)
+            : /* Inputs */
+            : /* Clobbers */
+                    "cc", "memory"
+            );
+        }
+        if (n & 7)
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_TRAILING_7, S32A_A8_LOADSTORE_D_TRAILING_7, n & 7);
+    } else {
+        // The last 0 - 7 pixels (starting from a 4-pixel boundary) are handled together
+        uintptr_t startrup = (uintptr_t) dst / sizeof (*dst) + 3;
+        uintptr_t end = (uintptr_t) dst / sizeof (*dst) + n;
+        size_t trailing;
+        if ((end & 3) == 0)
+            // No blocks of <8 pixels used at end in these cases
+            trailing = 0;
+        else
+            // If length (discounting alignment to 4-pixel boundaries) is an odd number of 4-pixels,
+            // assign 4 pixels to trailing end to avoid possibility of a leading run of exactly 4,
+            // otherwise use <4 trailing pixels to maximise central 8-pixel blocks
+            trailing = ((startrup ^ end) & 4) + (end & 3);
+        // The inner loop handles an integer number (0+) of 8-pixel blocks at 4-pixel boundaries
+        // The 0 - 7 pixels leading up to this are handled together
+        size_t leading = (n - trailing) & 7;
+
+        // Do leading pixels
+        if (leading != 0) {
+            n -= leading;
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_LEADING_7, S32A_A8_LOADSTORE_D_LEADING_7, leading);
+        }
+
+        // Do inner loop
+        __asm__ (
+                "subs        %[len], #8                                                         \n\t"
+                "bcc         50f                                                                \n\t"
+
+                "10:                                                                            \n\t"
+                "vld1.8      {d16}, [%[msk]]!                                                   \n\t"
+                "vld4.8      {d0-d3}, [%[src]]!                                                 \n\t"
+                S32A_A8_TEST("#8*4")
+                /* Translucency used, or a mixture of opaque and transparent */
+                S32A_A8_8PIX_BLEND(:128, ARM_YES, IF_PRELOAD)
+                /* Drop through */
+                "9:                                                                             \n\t"
+                "subs        %[len], #8                                                         \n\t"
+                "bcs         10b                                                                \n\t"
+                "50:                                                                            \n\t"
+        : // Outputs
+                [mlo]"=&r"(mlo),
+                [mhi]"=&r"(mhi),
+                [alo]"=&r"(alo),
+                [ahi]"=&r"(ahi),
+                [tmp]"=&r"(tmp),
+                [src]"+r"(src),
+                [msk]"+r"(msk),
+                [dst]"+r"(dst),
+                [len]"+r"(n)
+        : // Inputs
+        : // Clobbers
+                "cc", "memory"
+        );
+
+        // Do trailing pixels.
+        if (n & 7)
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_TRAILING_7, S32A_A8_LOADSTORE_D_TRAILING_7, n & 7);
+    }
+#else
+    auto mask = (const uint8_t*)vmask;
+
+#ifdef SK_SUPPORT_LEGACY_A8_MASKBLITTER
+    for (int i = 0; i < n; ++i) {
+        if (mask[i]) {
+            dst[i] = SkBlendARGB32(src[i], dst[i], mask[i]);
+        }
+    }
+#else
+    Sk4px::MapDstSrcAlpha(n, dst, src, mask, [](const Sk4px& d, const Sk4px& s, const Sk4px& aa) {
+        const auto s_aa = s.approxMulDiv255(aa);
+        return s_aa + d.approxMulDiv255(s_aa.alphas().inv());
+    });
+#endif
+#endif
+}
+
 }  // namespace SK_OPTS_NS
 
 #endif//SkBlitMask_opts_DEFINED
--- a/src/third_party/skia/src/opts/SkBlitRow_opts.h
+++ b/src/third_party/skia/src/opts/SkBlitRow_opts.h
@@ -120,6 +120,10 @@
 #endif
 
 #if defined(SK_ARM_HAS_NEON)
+#ifdef __ARM_64BIT_STATE
+// No attempt has been made to adapt the inline assembly version for AArch64
+// so fall back to the less performant version that uses intrinsics instead
+
     #include <arm_neon.h>
 
     // SkMulDiv255Round() applied to each lane.
@@ -145,8 +149,193 @@
         return vadd_u8(src, SkMulDiv255Round_neon8(nalphas, dst));
     }
 
+#else // __ARM_64BIT_STATE
+// Inline ARM AArch32 assembly version
+
+// Macros to specify instructions to only include if targeting ARM or Thumb instruction sets
+#ifdef __thumb__
+#define arm_a(x)
+#define arm_t(x) x
+#else
+#define arm_a(x) x
+#define arm_t(x)
+#endif
+
+// These macros permit optionally-included features to be switched using a parameter to another macro
+#define ARM_YES(x) x
+#define ARM_NO(x)
+
+// How far ahead (pixels) to preload (undefine to disable prefetch) - determined empirically
+#undef PREFETCH_DISTANCE
+#define PREFETCH_DISTANCE "24"
+
+#ifdef PREFETCH_DISTANCE
+#define IF_PRELOAD ARM_YES
+#else
+#define IF_PRELOAD ARM_NO
 #endif
 
+/// Macro to load or store 1..7 pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_LOADSTORE_LEADING_7(ls, r0, r1, r2, r3, base, opt)                                       \
+                "tst         %[group_size], #1                                                \n\t"   \
+                opt"                                                                          \n\t"   \
+                "beq         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#base"]:32]!          \n\t"   \
+                "1:                                                                           \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                       \n\t"   \
+                "add         %[tmp], %["#base"], #4                                           \n\t"   \
+                "bpl         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "bcc         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+
+/// Macro to load or store 1..7 pixels in shrink powers-of-2 in size - suitable for trailing pixels
+#define S32A_LOADSTORE_TRAILING_7(ls, r0, r1, r2, r3, base, opt)                                      \
+                "lsls        %[tmp], %[group_size], #30                                       \n\t"   \
+                "add         %[tmp], %["#base"], #4                                           \n\t"   \
+                opt"                                                                          \n\t"   \
+                "bcc         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "bpl         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "tst         %[group_size], #1                                                \n\t"   \
+                "beq         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#base"]:32]!          \n\t"   \
+                "1:                                                                           \n\t"   \
+
+/// Macro to do testing and "over" compositing of a group of 1..7 32bpp premultiplied ARGB leading or trailing pixels
+#define S32A_OPAQUE_7PIX_PROCESS(loadstore_7, size)                                                   \
+    do {                                                                                              \
+        __asm__ volatile (                                                                            \
+                /* Load the leading/trailing source pixels,                                           \
+                 * after initialising all the unused indexes from the first pixel                     \
+                 * so the all-opaque and all-transparent tests still work */                          \
+                loadstore_7(ld, d0, d1, d2, d3, src,                                                  \
+                "vld4.8      {d0[],d1[],d2[],d3[]}, [%[src]]")                                        \
+                /* Test for all-opaque or all-transparent */                                          \
+                "vmov        %[alo], s6                                                       \n\t"   \
+                "vmov        %[ahi], s7                                                       \n\t"   \
+                "vmvn        d31, d3                                                          \n\t"   \
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "addeq       %[dst], %[group_size], lsl #2                                    \n\t"   \
+                "beq         9f                                                               \n\t"   \
+                "cmp         %[alo], #-1                                                      \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "cmpeq       %[ahi], #-1                                                      \n\t"   \
+                "beq         5f                                                               \n\t"   \
+                /* Translucency used, or a mixture of opaque and transparent */                       \
+                loadstore_7(ld, d20, d21, d22, d23, dst, )                                            \
+                "sub         %[dst], %[group_size], lsl #2                                    \n\t"   \
+                S32A_OPAQUE_8PIX_BLEND(, , q0, q1,, ARM_NO, ARM_NO, ARM_NO)                           \
+                "5:                                                                           \n\t"   \
+                loadstore_7(st, d0, d1, d2, d3, dst, )                                                \
+                /* Drop through */                                                                    \
+                "9:                                                                           \n\t"   \
+        : /* Outputs */                                                                               \
+                [alo]"=&r"(alo),                                                                      \
+                [ahi]"=&r"(ahi),                                                                      \
+                [tmp]"=&r"(tmp),                                                                      \
+                [src]"+r"(src),                                                                       \
+                [dst]"+r"(dst)                                                                        \
+        : /* Inputs */                                                                                \
+                [group_size]"r"(size),                                                                \
+                     [eight]"r"(eight)                                                                \
+        : /* Clobbers */                                                                              \
+                "cc", "memory"                                                                        \
+        );                                                                                            \
+    } while (0)
+
+/// Macro to do testing and "over" compositing of an aligned group of 8 32bpp premultiplied ARGB leading or trailing pixels
+#define S32A_OPAQUE_8PIX_PROCESS(align, if_load)                                                      \
+    do {                                                                                              \
+        __asm__ (                                                                                     \
+if_load(        "vld4.8      {d0-d3}, [%[src]]!                                               \n\t")  \
+                /* Test for all-opaque or all-transparent */                                          \
+                "vmov        %[alo], s6                                                       \n\t"   \
+                "vmov        %[ahi], s7                                                       \n\t"   \
+                "vmvn        d31, d3                                                          \n\t"   \
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "addeq       %[dst], #8*4                                                     \n\t"   \
+                "beq         9f                                                               \n\t"   \
+                "cmp         %[alo], #-1                                                      \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "cmpeq       %[ahi], #-1                                                      \n\t"   \
+                "beq         5f                                                               \n\t"   \
+                /* Translucency used, or a mixture of opaque and transparent */                       \
+                S32A_OPAQUE_8PIX_BLEND(align, , q0, q1, "5:", ARM_YES, ARM_NO, ARM_NO)                \
+                /* Drop through */                                                                    \
+                "9:                                                                           \n\t"   \
+        :  /* Outputs */                                                                              \
+                [alo]"=&r"(alo),                                                                      \
+                [ahi]"=&r"(ahi),                                                                      \
+                [tmp]"=&r"(tmp),                                                                      \
+                [src]"+r"(src),                                                                       \
+                [dst]"+r"(dst)                                                                        \
+        : /* Inputs */                                                                                \
+        : /* Clobbers */                                                                              \
+                "cc", "memory"                                                                        \
+        );                                                                                            \
+    } while (0)
+
+/// Macro to do "over" compositing blending on 8 32bpp premultiplied ARGB pixels
+/// which are with either translucent or a mixture of opaque and transparent.
+/// Relies on A(x) to determine whether to emit code in ARM state (as opposed to Thumb state).
+/// @arg align           bit-alignment specifier on destination loads/stores (optional)
+/// @arg other_src_alpha D-register specifier for alpha source in other bank (only IF_OVERLAP)
+/// @arg src0            Q-register specifier for blue/green source in this bank
+/// @arg src1            Q-register specifier for red/alpha source in this bank
+/// @arg opt             optional instruction to emit
+/// @arg if_loadstore    ARM_YES or ARM_NO: whether to do load/store
+/// @arg if_overlap      ARM_YES or ARM_NO: whether to interleave processing of next iteration
+/// @arg if_preload      ARM_YES or ARM_NO: whether to insert prefetch instructions
+#define S32A_OPAQUE_8PIX_BLEND(align, other_src_alpha, src0, src1, opt, if_loadstore, if_overlap, if_preload) \
+if_loadstore(   "vld4.8      {d20-d23}, [%[dst]"#align"]                                      \n\t")  \
+if_preload(     "sub         %[tmp], %[len], #1                                               \n\t")  \
+if_overlap(     "vmov        %[alo], %[ahi], "#other_src_alpha"                               \n\t")  \
+if_preload(     "cmp         %[tmp], #" PREFETCH_DISTANCE "                                   \n\t")  \
+                "vmull.u8    q8, d20, d31                                                     \n\t"   \
+if_preload(     "it          cs                                                               \n\t")  \
+if_preload(     "movcs       %[tmp], #" PREFETCH_DISTANCE "                                   \n\t")  \
+                "vmull.u8    q9, d21, d31                                                     \n\t"   \
+                "vmull.u8    q10, d22, d31                                                    \n\t"   \
+                "vmull.u8    q11, d23, d31                                                    \n\t"   \
+if_preload(     "pld         [%[src], %[tmp], lsl #2]                                         \n\t")  \
+                "vrshr.u16   q12, q8, #8                                                      \n\t"   \
+if_preload(     "add         %[tmp], #(32+32)/4                                               \n\t")  \
+                "vrshr.u16   q13, q9, #8                                                      \n\t"   \
+                "vrshr.u16   q14, q10, #8                                                     \n\t"   \
+                "vrshr.u16   q15, q11, #8                                                     \n\t"   \
+if_preload(     "pld         [%[dst], %[tmp], lsl #2]                                         \n\t")  \
+                "vraddhn.u16 d16, q8, q12                                                     \n\t"   \
+                "vraddhn.u16 d17, q9, q13                                                     \n\t"   \
+                "vraddhn.u16 d18, q10, q14                                                    \n\t"   \
+                "vraddhn.u16 d19, q11, q15                                                    \n\t"   \
+if_overlap(     "mvn         %[tmp], %[alo]                                                   \n\t")  \
+if_overlap(     "vmvn        d31, "#other_src_alpha"                                          \n\t")  \
+if_overlap(arm_a("orr         %[alo], %[ahi]                                                  \n\t")) \
+                "vadd.i8     "#src0", q8                                                      \n\t"   \
+if_overlap(arm_a("mvn         %[ahi], %[ahi]                                                  \n\t")) \
+                "vadd.i8     "#src1", q9                                                      \n\t"   \
+                opt"                                                                          \n\t"   \
+if_loadstore(   "vst4.8      {"#src0", "#src1"}, [%[dst]"#align"]!                            \n\t")  \
+
+#endif // __ARM_64BIT_STATE
+#endif // defined(SK_ARM_HAS_NEON)
+
 namespace SK_OPTS_NS {
 
 /*not static*/
@@ -187,6 +376,10 @@ inline void blit_row_s32a_opaque(SkPMCol
 #endif
 
 #if defined(SK_ARM_HAS_NEON)
+#ifdef __ARM_64BIT_STATE
+    // No attempt has been made to adapt the inline assembly version for AArch64
+    // so fall back to the less performant version that uses intrinsics instead
+
     while (len >= 8) {
         vst4_u8((uint8_t*)dst, SkPMSrcOver_neon8(vld4_u8((const uint8_t*)dst),
                                                  vld4_u8((const uint8_t*)src)));
@@ -209,6 +402,154 @@ inline void blit_row_s32a_opaque(SkPMCol
         vst1_lane_u32(dst, vreinterpret_u32_u8(result), 0);
     }
     return;
+
+#else // __ARM_64BIT_STATE
+    // Inline ARM AArch32 assembly version
+    uint32_t tmp, alo, ahi;
+    const int eight = 8;
+    if (len < 15) {
+        // Too short to attempt aligned processing
+        if (len & 8)
+            S32A_OPAQUE_8PIX_PROCESS(, ARM_YES);
+        if (len & 7)
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_TRAILING_7, len & 7);
+    } else {
+        // The last 8 - 15 pixels (starting from a 4-pixel boundary) are handled together
+        uintptr_t startrup = (uintptr_t) dst / sizeof (*dst) + 3;
+        uintptr_t end = (uintptr_t) dst / sizeof (*dst) + len;
+        size_t trailing;
+        if ((end & 3) == 0)
+            // No blocks of <8 pixels used at end in these cases
+            trailing = 8;
+        else
+            // If length (discounting alignment to 4-pixel boundaries) is an odd number of 4-pixels,
+            // assign this to trailing end to avoid possibility of a leading run of exactly 4
+            trailing = 8 + ((startrup ^ end) & 4) + (end & 3);
+        // The inner loop handles an integer number (0+) of 16-pixel blocks at 4-pixel boundaries
+        // The 0..15 pixels leading up to this are handled together
+        size_t leading8 = (len - trailing) & 8;
+        size_t leading7 = (len - trailing) & 7;
+
+        // Do leading pixels
+        if (leading7 != 0) {
+            len -= leading7;
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_LEADING_7, leading7);
+        }
+        if (leading8 != 0) {
+            len -= 8;
+            S32A_OPAQUE_8PIX_PROCESS(:128, ARM_YES);
+        }
+
+        // Do inner loop
+        __asm__ (
+                // We enter and leave each iteration of the inner loop with the source
+                // pointer 8 pixels ahead and the destination pointer 8 pixels behind
+                // in order to permit good pipelining. The count of remaining pixels is
+                // reduced by 16 to allow the loop termination test to be combined with
+                // the decrementing of the remaining length.
+                "sub         %[dst], #8*4                                                     \n\t"
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "subs        %[len], #16                                                      \n\t"
+                "bcc         49f                                                              \n\t"
+
+                "10:                                                                          \n\t"
+                // Move alpha to ARM registers for comparison
+                "vmov        %[alo], s6                                                       \n\t"
+                "vmov        %[ahi], s7                                                       \n\t"
+                // Fetch source data for next iteration
+                "vld4.8      {d4-d7}, [%[src]]!                                               \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                // Test if all source pixels are transparent (alpha=0)
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"
+                "beq         19f                                                              \n\t"
+                // Find inverse alpha in case full blending required
+                "vmvn        d31, d3                                                          \n\t"
+                // Test if all source pixels are opaque (alpha=0xff)
+                "cmp         %[alo], #-1                                                      \n\t"
+                "it          eq                                                               \n\t"
+                "cmpeq       %[ahi], #-1                                                      \n\t"
+                "bne         30f                                                              \n\t"
+                // Opaque case: copy source to destination
+                "vst4.8      {d0-d3}, [%[dst]:128]                                            \n\t"
+                // Drop through
+                "19:                                                                          \n\t"
+
+                // Move alpha to ARM registers for comparison
+                "vmov        %[alo], s14                                                      \n\t"
+                "vmov        %[ahi], s15                                                      \n\t"
+                // Fetch source data for next iteration
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                // Test if all source pixels are transparent (alpha=0)
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"
+                "beq         29f                                                              \n\t"
+                // Find inverse alpha in case full blending required
+                "vmvn        d31, d7                                                          \n\t"
+                // Test if all source pixels are opaque (alpha=0xff)
+                "cmp         %[alo], #-1                                                      \n\t"
+                "it          eq                                                               \n\t"
+                "cmpeq       %[ahi], #-1                                                      \n\t"
+                "bne         40f                                                              \n\t"
+                // Opaque case: copy source to destination
+                "vst4.8      {d4-d7}, [%[dst]:128]                                            \n\t"
+                // Drop through
+                "29:                                                                          \n\t"
+                "subs        %[len], #16                                                      \n\t"
+                "bcs         10b                                                              \n\t"
+                "b           49f                                                              \n\t"
+
+                // Mixed or translucent pixels in d0-d3
+                "30:                                                                          \n\t"
+                S32A_OPAQUE_8PIX_BLEND(:128, d7, q0, q1,, ARM_YES, ARM_YES, IF_PRELOAD)
+arm_a(          "teq         %[alo], #0                                                       \n\t")
+arm_t(          "orrs        %[alo], %[alo], %[ahi]                                           \n\t")
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "beq         29b                                                              \n\t"
+arm_a(          "orrs        %[tmp], %[tmp], %[ahi]                                           \n\t")
+arm_t(          "orns        %[tmp], %[tmp], %[ahi]                                           \n\t")
+                "bne         40f                                                              \n\t"
+                "vst4.8      {d4-d7}, [%[dst]:128]                                            \n\t"
+                "b           29b                                                              \n\t"
+
+                // Mixed or translucent pixels in d4-d7
+                "40:                                                                          \n\t"
+                S32A_OPAQUE_8PIX_BLEND(:128, d3, q2, q3, \
+                "subs        %[len], #16", ARM_YES, ARM_YES, ARM_NO)
+                "bcc         50f                                                              \n\t"
+arm_a(          "teq         %[alo], #0                                                       \n\t")
+arm_t(          "orrs        %[alo], %[alo], %[ahi]                                           \n\t")
+                "vld4.8      {d4-d7}, [%[src]]!                                               \n\t"
+                "beq         19b                                                              \n\t"
+arm_a(          "orrs        %[tmp], %[tmp], %[ahi]                                           \n\t")
+arm_t(          "orns        %[tmp], %[tmp], %[ahi]                                           \n\t")
+                "bne         30b                                                              \n\t"
+                "vst4.8      {d0-d3}, [%[dst]:128]                                            \n\t"
+                "b           19b                                                              \n\t"
+
+                "49:                                                                          \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                "50:                                                                          \n\t"
+        : // Outputs
+                [dst]"+r"(dst),
+                [src]"+r"(src),
+                [len]"+r"(len),
+                [alo]"+r"(alo),
+                [ahi]"+r"(ahi),
+                [tmp]"+r"(tmp)
+        : // Inputs
+        : // Clobbers
+                "cc", "memory"
+        );
+
+        // Do trailing pixels.
+        // There will always be more than 8 of these, and the first 8 are already in d0-d3
+        S32A_OPAQUE_8PIX_PROCESS(:128, ARM_NO);
+        if (len & 7)
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_TRAILING_7, len & 7);
+    }
+    return;
+
+#endif // __ARM_64BIT_STATE
 #endif
 
     while (len --> 0) {
--- a/src/third_party/skia/src/opts/SkUtils_opts.h
+++ b/src/third_party/skia/src/opts/SkUtils_opts.h
@@ -34,7 +34,81 @@ namespace SK_OPTS_NS {
         memsetT(buffer, value, count);
     }
     /*not static*/ inline void memset32(uint32_t buffer[], uint32_t value, int count) {
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+        uint32_t *p1 = buffer;
+        uint32_t off;
+        __asm__ volatile (
+                "vdup.32     q0, %[p2]                     \n\t"
+                "cmp         %[n], #3+16                   \n\t"
+                "vdup.32     q1, %[p2]                     \n\t"
+                "blo         20f                           \n\t"
+
+                // Long case (at least one 16-byte-aligned 64-byte block)
+                "ands        %[off], %[buffer], #12        \n\t"
+                "bne         15f                           \n\t"
+
+                // 16-byte aligned. Set up inner loop
+                "10:                                       \n\t"
+                "mov         %[off], #64                   \n\t"
+                "sub         %[n], #16                     \n\t"
+                "add         %[p2], %[p1], #32             \n\t"
+
+                // Inner loop
+                "11:                                       \n\t"
+                "vst1.32     {q0-q1}, [%[p1] :128], %[off] \n\t"
+                "subs        %[n], #16                     \n\t"
+                "vst1.32     {q0-q1}, [%[p2] :128], %[off] \n\t"
+                "bhs         11b                           \n\t"
+
+                // Handle trailing 1..15 words
+                "12:                                       \n\t"
+                "lsls        %[n], #29                     \n\t"
+                "bcc         1f                            \n\t"
+                "vst1.32     {q0-q1}, [%[p1]]!             \n\t"
+                "1:                                        \n\t"
+                "bpl         1f                            \n\t"
+                "vst1.32     {q0}, [%[p1]]!                \n\t"
+                "1:                                        \n\t"
+                "lsls        %[n], #2                      \n\t"
+                "it          cs                            \n\t"
+                "vstmcs      %[p1]!, {d0}                  \n\t"
+                "it          mi                            \n\t"
+                "vstmmi      %[p1]!, {s0}                  \n\t"
+                "b           90f                           \n\t"
+
+                // Handle first 1..3 words to achieve 16-byte alignment
+                "15:                                       \n\t"
+                "rsb         %[off], #16                   \n\t"
+                "sub         %[n], %[off], lsr #2          \n\t"
+                "lsls        %[off], #29                   \n\t"
+                "it          mi                            \n\t"
+                "vstmmi      %[p1]!, {s0}                  \n\t"
+                "it          cs                            \n\t"
+                "vstmcs      %[p1]!, {d0}                  \n\t"
+                "b           10b                           \n\t"
+
+                // Short case
+                "20:                                       \n\t"
+                "cmp         %[n], #8                      \n\t"
+                "blo         12b                           \n\t"
+                "sub         %[n], #8                      \n\t"
+                "vst1.8      {q0-q1}, [%[p1]]!             \n\t"
+                "b           12b                           \n\t"
+
+                "90:                                       \n\t"
+        : // Outputs
+                 [p2]"+r"(value),
+                  [n]"+r"(count),
+                 [p1]"+r"(p1),
+                [off]"=&r"(off)
+        : // Inputs
+                [buffer]"r"(buffer)
+        : // Clobbers
+                "cc", "memory"
+        );
+#else
         memsetT(buffer, value, count);
+#endif
     }
     /*not static*/ inline void memset64(uint64_t buffer[], uint64_t value, int count) {
         memsetT(buffer, value, count);
