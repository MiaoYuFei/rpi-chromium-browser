--- a/src/build/.gitignore
+++ b/src/build/.gitignore
@@ -23,6 +23,11 @@ ciopfs
 /x64/
 /linux/debian_*-sysroot/
 /linux/ubuntu_*-sysroot/
+# We've built anything with pios in the name
+/linux/pios_*-sysroot/
+/linux/sysroot_scripts/*pios*
+/linux/sysroot_scripts/generated_package_lists/*pios*
+
 /ios_files
 /mac_files
 
--- a/src/build/config/linux/BUILD.gn
+++ b/src/build/config/linux/BUILD.gn
@@ -5,6 +5,7 @@
 import("//build/config/c++/c++.gni")
 import("//build/config/chromeos/ui_mode.gni")
 import("//build/config/linux/pkg_config.gni")
+import("//build/config/sysroot.gni")
 import("//build/config/ui.gni")
 
 group("linux") {
--- a/src/build/linux/sysroot_scripts/generate_keyring.sh
+++ b/src/build/linux/sysroot_scripts/generate_keyring.sh
@@ -27,5 +27,19 @@ KEYS=(
     "4DFAB270CAA96DFA"
 )
 
+KEYFILE=keyring.gpg
+
+if [ $# -ge 1 ] && [ "$1" == "--pios" ]; then
+    KEYS+=(
+        # Raspbian
+        "A0DA38D0D76E8B5D638872819165938D90FDDD2E"
+        # Raspberry Pi OS
+        "CF8A1AF502A2AA2D763BAE7E82B129927FA3303E"
+    )
+    KEYFILE=pios_keyring.gpg
+    shift
+fi
+echo "Build keyring: ${SCRIPT_DIR}/${KEYFILE}"
+
 gpg --keyserver keyserver.ubuntu.com --recv-keys ${KEYS[@]}
-gpg --output "${SCRIPT_DIR}/keyring.gpg" --export ${KEYS[@]}
+gpg --output "${SCRIPT_DIR}/${KEYFILE}" --export ${KEYS[@]}
--- a/src/build/linux/sysroot_scripts/sysroot_creator.py
+++ b/src/build/linux/sysroot_scripts/sysroot_creator.py
@@ -7,6 +7,7 @@ This script is used to build Debian sysr
 """
 
 import argparse
+import gzip
 import hashlib
 import lzma
 import os
@@ -663,17 +664,19 @@ def create_tarball(install_root: str, ar
 
 
 def generate_package_list_dist_repo(arch: str, dist: str,
-                                    repo_name: str) -> list[dict[str, str]]:
-    repo_basedir = f"{ARCHIVE_URL}/dists/{dist}"
-    package_list = f"{BUILD_DIR}/Packages.{dist}_{repo_name}_{arch}"
-    package_list = f"{package_list}.{PACKAGES_EXT}"
-    package_file_arch = f"{repo_name}/binary-{arch}/Packages.{PACKAGES_EXT}"
+                                    repo_name: str, repo_src: str, repo_pre: str, repo_ext: str) -> list:
+    repo_basedir = f"{repo_src}/dists/{dist}"
+    package_list = f"{BUILD_DIR}/Packages.{repo_pre}{dist}_{repo_name}_{arch}"
+    package_list = f"{package_list}.{repo_ext}"
+    package_file_arch = f"{repo_name}/binary-{arch}/Packages.{repo_ext}"
     package_list_arch = f"{repo_basedir}/{package_file_arch}"
 
     download_or_copy_non_unique_filename(package_list_arch, package_list)
-    verify_package_listing(package_file_arch, package_list, dist)
+    verify_package_listing(package_file_arch, package_list, dist, repo_basedir, repo_pre)
 
-    with lzma.open(package_list, "rt") as src:
+    algo = lzma if repo_ext != "gz" else gzip
+
+    with algo.open(package_list, "rt") as src:
         return [
             dict(
                 line.split(": ", 1) for line in package_meta.splitlines()
@@ -682,11 +685,17 @@ def generate_package_list_dist_repo(arch
         ]
 
 
-def generate_package_list(arch: str) -> dict[str, str]:
+def generate_package_list(arch: str) -> dict:
     package_meta = {}
-    for dist, repos in APT_SOURCES_LIST:
+    for a in APT_SOURCES_LIST:
+        dist = a[0]
+        repos = a[1]
+        repo_src = ARCHIVE_URL if len(a) <= 2 else a[2]
+        repo_pre = "" if len(a) <= 3 else a[3] + "_"
+        repo_ext = PACKAGES_EXT if len(a) <= 4 else a[4]
         for repo_name in repos:
-            for meta in generate_package_list_dist_repo(arch, dist, repo_name):
+            for meta in generate_package_list_dist_repo(arch, dist, repo_name, repo_src, repo_pre, repo_ext):
+                meta["URL"] = repo_src
                 package_meta[meta["Package"]] = meta
 
     # Read the input file and create a dictionary mapping package names to URLs
@@ -697,7 +706,7 @@ def generate_package_list(arch: str) ->
         package = meta["Package"]
         if package in missing:
             missing.remove(package)
-            url = ARCHIVE_URL + meta["Filename"]
+            url = meta["URL"] + meta["Filename"]
             package_dict[url] = meta["SHA256"]
     if missing:
         raise Exception(f"Missing packages: {', '.join(missing)}")
@@ -783,7 +792,7 @@ def replace_in_file(file_path: str, sear
 
 
 def install_into_sysroot(build_dir: str, install_root: str,
-                         packages: dict[str, str]) -> None:
+                         packages: dict) -> None:
     """
     Installs libraries and headers into the sysroot environment.
     """
@@ -937,17 +946,16 @@ def upload_sysroot(arch: str) -> None:
 
 
 def verify_package_listing(file_path: str, output_file: str,
-                           dist: str) -> None:
+                           dist: str, repo_basedir:str, repo_pre: str) -> None:
     """
     Verifies the downloaded Packages.xz file against its checksum and GPG keys.
     """
     # Paths for Release and Release.gpg files
-    repo_basedir = f"{ARCHIVE_URL}/dists/{dist}"
     release_list = f"{repo_basedir}/{RELEASE_FILE}"
     release_list_gpg = f"{repo_basedir}/{RELEASE_FILE_GPG}"
 
-    release_file = os.path.join(BUILD_DIR, f"{dist}-{RELEASE_FILE}")
-    release_file_gpg = os.path.join(BUILD_DIR, f"{dist}-{RELEASE_FILE_GPG}")
+    release_file = os.path.join(BUILD_DIR, f"{repo_pre}{dist}-{RELEASE_FILE}")
+    release_file_gpg = os.path.join(BUILD_DIR, f"{repo_pre}{dist}-{RELEASE_FILE_GPG}")
 
     if not os.path.exists(KEYRING_FILE):
         raise Exception(f"KEYRING_FILE not found: {KEYRING_FILE}")
@@ -980,12 +988,35 @@ def verify_package_listing(file_path: st
 
 
 def main():
+    global APT_SOURCES_LIST
+    global RELEASE
+    global KEYRING_FILE
+
     parser = argparse.ArgumentParser(
         description="Build and upload Debian sysroot images for Chromium.")
     parser.add_argument("command", choices=["build", "upload"])
     parser.add_argument("architecture", choices=list(TRIPLES))
+    parser.add_argument("--pios", action="store_true")
     args = parser.parse_args()
 
+    if args.pios:
+        # Interleave our repos with those in the starting list
+        APT_PIOS_SOURCES_LIST = [
+            ("bookworm", ["main"], "http://archive.raspberrypi.org/debian/", "pios", "gz"),
+            ("bullseye", ["main"], "http://archive.raspberrypi.org/debian/", "pios", "gz")]
+        newlist = []
+        curdist = "xxx"
+        for a in APT_SOURCES_LIST:
+            if not a[0].startswith(curdist):
+                newlist += [p for p in APT_PIOS_SOURCES_LIST if p[0].startswith(curdist)]
+                curdist = a[0].partition('-')[0]
+            newlist += [a]
+        newlist += [p for p in APT_PIOS_SOURCES_LIST if p[0].startswith(curdist)]
+        APT_SOURCES_LIST = newlist
+
+        RELEASE = "pios-" + RELEASE
+        KEYRING_FILE = os.path.join(SCRIPT_DIR, "pios_keyring.gpg")
+
     sanity_check()
 
     if args.command == "build":
--- a/src/chrome/app/chrome_main_delegate.cc
+++ b/src/chrome/app/chrome_main_delegate.cc
@@ -78,6 +78,7 @@
 #include "components/nacl/common/buildflags.h"
 #include "components/startup_metric_utils/common/startup_metric_utils.h"
 #include "components/version_info/channel.h"
+#include "components/version_info/pi_patch_version_info.h"
 #include "components/version_info/version_info.h"
 #include "content/public/app/initialize_mojo_core.h"
 #include "content/public/common/content_client.h"
@@ -419,6 +420,15 @@ bool HandleVersionSwitches(const base::C
   }
 #endif
 
+  if (command_line.HasSwitch(switches::kPiPatchVersion)) {
+    printf("%s %s %s\nPi patch: %s\n",
+           version_info::GetProductName().data(),
+           version_info::GetVersionNumber().data(),
+           chrome::GetChannelName(chrome::WithExtendedStable(true)).c_str(),
+           version_info::GetPiPatchVersionString().c_str());
+    return true;
+  }
+
   if (command_line.HasSwitch(switches::kVersion)) {
     printf("%s %s %s\n", version_info::GetProductName().data(),
            version_info::GetVersionNumber().data(),
--- a/src/chrome/browser/about_flags.cc
+++ b/src/chrome/browser/about_flags.cc
@@ -7496,15 +7496,17 @@ const FeatureEntry kFeatureEntries[] = {
      FEATURE_VALUE_TYPE(ash::features::kArcInputOverlayAlphaV2)},
 #endif  // BUILDFLAG(IS_CHROMEOS_ASH)
 
-#if BUILDFLAG(IS_CHROMEOS) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
+#if (BUILDFLAG(IS_CHROMEOS) || BUILDFLAG(IS_LINUX)) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
 #if !BUILDFLAG(USE_VAAPI)
     {"chromeos-direct-video-decoder",
      flag_descriptions::kChromeOSDirectVideoDecoderName,
      flag_descriptions::kChromeOSDirectVideoDecoderDescription,
-     kOsCrOS | kOsLacros,
+     kOsCrOS | kOsLacros | kOsLinux,
      FEATURE_VALUE_TYPE(media::kUseChromeOSDirectVideoDecoder)},
 #endif  // !BUILDFLAG(USE_VAAPI)
+#endif
 
+#if BUILDFLAG(IS_CHROMEOS) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
     {"enable-vbr-encode-acceleration",
      flag_descriptions::kChromeOSHWVBREncodingName,
      flag_descriptions::kChromeOSHWVBREncodingDescription, kOsCrOS | kOsLacros,
--- a/src/chrome/browser/chrome_browser_main_extra_parts_linux.cc
+++ b/src/chrome/browser/chrome_browser_main_extra_parts_linux.cc
@@ -168,7 +168,7 @@ ChromeBrowserMainExtraPartsLinux::Chrome
 
 ChromeBrowserMainExtraPartsLinux::~ChromeBrowserMainExtraPartsLinux() = default;
 
-void ChromeBrowserMainExtraPartsLinux::PreEarlyInitialization() {
+void ChromeBrowserMainExtraPartsLinux::FixOzoneCmdLine() {
 #if BUILDFLAG(IS_LINUX)
   // On the desktop, we fix the platform name if necessary.
   // See https://crbug.com/1246928.
@@ -176,10 +176,10 @@ void ChromeBrowserMainExtraPartsLinux::P
   if (!command_line->HasSwitch(switches::kOzonePlatform)) {
     const auto ozone_platform_hint =
         command_line->GetSwitchValueASCII(switches::kOzonePlatformHint);
-    if (!ozone_platform_hint.empty()) {
-      command_line->AppendSwitchASCII(
-          switches::kOzonePlatform, MaybeFixPlatformName(ozone_platform_hint));
-    }
+    command_line->AppendSwitchASCII(
+      switches::kOzonePlatform,
+      MaybeFixPlatformName(ozone_platform_hint.empty() ?
+          std::string("auto") : ozone_platform_hint));
   }
 
   auto env = base::Environment::Create();
@@ -190,6 +190,10 @@ void ChromeBrowserMainExtraPartsLinux::P
 #endif  // BUILDFLAG(IS_LINUX)
 }
 
+void ChromeBrowserMainExtraPartsLinux::PreEarlyInitialization() {
+  FixOzoneCmdLine();
+}
+
 void ChromeBrowserMainExtraPartsLinux::PostBrowserStart() {
   RecordDisplayServerProtocolSupport();
   ChromeBrowserMainExtraPartsOzone::PostBrowserStart();
--- a/src/chrome/browser/chrome_browser_main_extra_parts_linux.h
+++ b/src/chrome/browser/chrome_browser_main_extra_parts_linux.h
@@ -17,6 +17,7 @@ class ChromeBrowserMainExtraPartsLinux
       const ChromeBrowserMainExtraPartsLinux&) = delete;
   ~ChromeBrowserMainExtraPartsLinux() override;
 
+  static void FixOzoneCmdLine();
  private:
   // ChromeBrowserMainExtraParts overrides.
   void PreEarlyInitialization() override;
--- a/src/chrome/browser/flag_descriptions.cc
+++ b/src/chrome/browser/flag_descriptions.cc
@@ -7707,8 +7707,7 @@ const char kWebPrintingApiDescription[]
     "https://github.com/WICG/web-printing for details.";
 #endif  // BUILDFLAG(IS_CHROMEOS)
 
-#if BUILDFLAG(IS_CHROMEOS) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
-#if !BUILDFLAG(USE_VAAPI)
+#if (BUILDFLAG(IS_CHROMEOS) || BUILDFLAG(IS_LINUX)) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
 const char kChromeOSDirectVideoDecoderName[] = "ChromeOS Direct Video Decoder";
 const char kChromeOSDirectVideoDecoderDescription[] =
     "Enables the hardware-accelerated ChromeOS direct media::VideoDecoder "
@@ -7717,6 +7716,8 @@ const char kChromeOSDirectVideoDecoderDe
     "disable_cros_video_decoder USE flag in ChromeOS). This flag only has an "
     "effect on non-Intel and non-AMD devices (i.e. on ARM-based SoCs).";
 #endif  // !BUILDFLAG(USE_VAAPI)
+
+#if BUILDFLAG(IS_CHROMEOS) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
 const char kChromeOSHWVBREncodingName[] =
     "ChromeOS Hardware Variable Bitrate Encoding";
 const char kChromeOSHWVBREncodingDescription[] =
--- a/src/chrome/browser/flag_descriptions.h
+++ b/src/chrome/browser/flag_descriptions.h
@@ -4447,9 +4447,11 @@ extern const char kAudioFlexibleLoopback
 extern const char kAudioFlexibleLoopbackForSystemLoopbackDescription[];
 #endif  // BUILDFLAG(IS_CHROMEOS)
 
-#if BUILDFLAG(IS_CHROMEOS) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
+#if (BUILDFLAG(IS_CHROMEOS) || BUILDFLAG(IS_LINUX)) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
 extern const char kChromeOSDirectVideoDecoderName[];
 extern const char kChromeOSDirectVideoDecoderDescription[];
+#endif
+#if BUILDFLAG(IS_CHROMEOS) && BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
 extern const char kChromeOSHWVBREncodingName[];
 extern const char kChromeOSHWVBREncodingDescription[];
 #if defined(ARCH_CPU_ARM_FAMILY)
--- a/src/chrome/common/chrome_paths.cc
+++ b/src/chrome/common/chrome_paths.cc
@@ -410,6 +410,10 @@ bool PathProvider(int key, base::FilePat
 
 #if BUILDFLAG(ENABLE_WIDEVINE)
     case chrome::DIR_BUNDLED_WIDEVINE_CDM:
+      cur = base::FilePath(FILE_PATH_LITERAL("/opt"));
+      cur = cur.Append(kWidevineCdmBaseDirectory);
+      if (base::PathExists(cur))
+        break;
       if (!GetComponentDirectory(&cur)) {
         return false;
       }
--- a/src/chrome/common/chrome_switches.cc
+++ b/src/chrome/common/chrome_switches.cc
@@ -467,6 +467,9 @@ const char kPackExtensionKey[] = "pack-e
 // crashpad (or breakpad) is initialized.
 const char kPreCrashpadCrashTest[] = "pre-crashpad-crash-test";
 
+// Print the patch version and return
+const char kPiPatchVersion[] = "pi-patch-version";
+
 // Used to mock the response received from the Web Permission Prediction
 // Service. Used for testing.
 const char kPredictionServiceMockLikelihood[] =
--- a/src/chrome/common/chrome_switches.h
+++ b/src/chrome/common/chrome_switches.h
@@ -150,6 +150,7 @@ extern const char kOnTheFlyMhtmlHashComp
 extern const char kOpenInNewWindow[];
 extern const char kPackExtension[];
 extern const char kPackExtensionKey[];
+extern const char kPiPatchVersion[];
 extern const char kPreCrashpadCrashTest[];
 extern const char kPredictionServiceMockLikelihood[];
 extern const char kPreinstalledWebAppsDir[];
--- a/src/chrome/common/media/cdm_registration.cc
+++ b/src/chrome/common/media/cdm_registration.cc
@@ -54,9 +54,7 @@ namespace {
 using Robustness = content::CdmInfo::Robustness;
 
 #if BUILDFLAG(ENABLE_WIDEVINE)
-#if (BUILDFLAG(BUNDLE_WIDEVINE_CDM) ||            \
-     BUILDFLAG(ENABLE_WIDEVINE_CDM_COMPONENT)) && \
-    (BUILDFLAG(IS_LINUX) || BUILDFLAG(IS_CHROMEOS))
+#if BUILDFLAG(IS_LINUX) || BUILDFLAG(IS_CHROMEOS)
 // Create a CdmInfo for a Widevine CDM, using |version|, |cdm_library_path|, and
 // |capability|.
 std::unique_ptr<content::CdmInfo> CreateWidevineCdmInfo(
@@ -100,7 +98,7 @@ std::unique_ptr<content::CdmInfo> Create
         // BUILDFLAG(ENABLE_WIDEVINE_CDM_COMPONENT)) && (BUILDFLAG(IS_LINUX) ||
         // BUILDFLAG(IS_CHROMEOS))
 
-#if BUILDFLAG(BUNDLE_WIDEVINE_CDM) && \
+#if BUILDFLAG(ENABLE_WIDEVINE) && \
     (BUILDFLAG(IS_LINUX) || BUILDFLAG(IS_CHROMEOS))
 // On Linux/ChromeOS we have to preload the CDM since it uses the zygote
 // sandbox. On Windows and Mac, the bundled CDM is handled by the component
@@ -181,7 +179,7 @@ void AddSoftwareSecureWidevine(std::vect
   // case both versions will be the same and point to the same directory, so
   // it doesn't matter which one is loaded.
   content::CdmInfo* bundled_widevine = nullptr;
-#if BUILDFLAG(BUNDLE_WIDEVINE_CDM)
+#if BUILDFLAG(ENABLE_WIDEVINE)
   bundled_widevine = GetBundledWidevine();
 #endif
 
--- a/src/components/version_info/BUILD.gn
+++ b/src/components/version_info/BUILD.gn
@@ -10,6 +10,9 @@ source_set("version_info") {
   sources = [
     "version_info.h",
     "version_info_values.h",
+    "pi_patch_version_info.cc",
+    "pi_patch_version_info.h",
+    "pi_patch_version_values.h",
   ]
   public_deps = [
     ":channel",
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_info.cc
@@ -0,0 +1,11 @@
+#include "components/version_info/pi_patch_version_info.h"
+#include "components/version_info/pi_patch_version_values.h"
+
+namespace version_info {
+
+std::string GetPiPatchVersionString() {
+  return PI_PATCH_VERSION_STRING;
+}
+
+}  // namespace version_info
+
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_info.h
@@ -0,0 +1,12 @@
+#ifndef COMPONENTS_PI_PATCH_VERSION_INFO_VERSION_INFO_H_
+#define COMPONENTS_PI_PATCH_VERSION_INFO_VERSION_INFO_H_
+
+#include <string>
+
+namespace version_info {
+
+// Returns a string with the patch tag for our patches
+std::string GetPiPatchVersionString();
+
+}  // namespace version_info
+#endif  // COMPONENTS_VERSION_INFO_VERSION_INFO_H_
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_values.h
@@ -0,0 +1,2 @@
+// Pi patch version - generated by pi-util/settag.py
+#define PI_PATCH_VERSION_STRING "rpi_2.66"
--- a/src/content/app/content_main_runner_impl.cc
+++ b/src/content/app/content_main_runner_impl.cc
@@ -50,6 +50,10 @@
 #include "base/trace_event/trace_event.h"
 #include "build/build_config.h"
 #include "build/chromeos_buildflags.h"
+#if BUILDFLAG(IS_LINUX)
+// RPI: Kludge to fix up ozone selection - bugged in current release
+#include "chrome/browser/chrome_browser_main_extra_parts_linux.h"
+#endif
 #include "components/discardable_memory/service/discardable_shared_memory_manager.h"
 #include "components/download/public/common/download_task_runner.h"
 #include "components/power_monitor/make_power_monitor_device_source.h"
@@ -1205,6 +1209,14 @@ int ContentMainRunnerImpl::RunBrowser(Ma
           variations::VariationsIdsProvider::Mode::kUseSignedInState);
     }
 
+#if BUILDFLAG(IS_LINUX)
+// RPI - Ozone kludge for google setup bug since v122 or v123
+// The following PostEarlyInitialization sets up Ozone in a manner that depends
+// on platform flags that are set later
+// Remove once fixed
+    ChromeBrowserMainExtraPartsLinux::FixOzoneCmdLine();
+#endif
+
     std::optional<int> post_early_initialization_exit_code =
         delegate_->PostEarlyInitialization(invoked_in_browser);
     if (post_early_initialization_exit_code.has_value())
--- a/src/content/common/user_agent.cc
+++ b/src/content/common/user_agent.cc
@@ -63,7 +63,7 @@ std::string GetUserAgentPlatform() {
 std::string GetUnifiedPlatform() {
 #if BUILDFLAG(IS_ANDROID)
   return "Linux; Android 10; K";
-#elif BUILDFLAG(IS_CHROMEOS)
+#elif BUILDFLAG(IS_CHROMEOS) || BUILDFLAG(IS_POSIX)
   return "X11; CrOS x86_64 14541.0.0";
 #elif BUILDFLAG(IS_MAC)
   return "Macintosh; Intel Mac OS X 10_15_7";
@@ -252,7 +252,7 @@ std::string GetOSVersion(IncludeAndroidB
                       "%s%s", android_version_str.c_str(),
                       android_info_str.c_str()
 #else
-                      ""
+                      "13597.84.0"
 #endif
   );
   return os_version;
@@ -287,7 +287,7 @@ std::string BuildOSCpuInfoFromOSVersionA
   base::StringAppendF(&os_cpu,
 #if BUILDFLAG(IS_MAC)
                       "%s Mac OS X %s", cpu_type.c_str(), os_version.c_str()
-#elif BUILDFLAG(IS_CHROMEOS)
+#elif BUILDFLAG(IS_CHROMEOS) || BUILDFLAG(IS_POSIX)
                       "CrOS "
                       "%s %s",
                       cpu_type.c_str(),  // e.g. i686
--- a/src/content/renderer/render_thread_impl.cc
+++ b/src/content/renderer/render_thread_impl.cc
@@ -119,6 +119,7 @@
 #include "media/base/decoder_factory.h"
 #include "media/base/media.h"
 #include "media/base/media_switches.h"
+#include "media/gpu/buildflags.h"
 #include "media/media_buildflags.h"
 #include "media/renderers/default_decoder_factory.h"
 #include "media/video/gpu_video_accelerator_factories.h"
@@ -996,7 +997,7 @@ media::GpuVideoAcceleratorFactories* Ren
                              kGpuStreamIdMedia, kGpuStreamPriorityMedia);
 
   const bool enable_video_decode_accelerator =
-#if BUILDFLAG(IS_LINUX)
+#if BUILDFLAG(IS_LINUX) && !BUILDFLAG(USE_V4L2_CODEC)
       base::FeatureList::IsEnabled(media::kVaapiVideoDecodeLinux) &&
 #endif  // BUILDFLAG(IS_LINUX)
       !cmd_line->HasSwitch(switches::kDisableAcceleratedVideoDecode) &&
--- a/src/media/base/media_switches.cc
+++ b/src/media/base/media_switches.cc
@@ -1310,6 +1310,8 @@ BASE_FEATURE(kUSeSequencedTaskRunnerForV
 BASE_FEATURE(kUseGLForScaling,
              "UseGLForScaling",
              base::FEATURE_DISABLED_BY_DEFAULT);
+#endif
+#if defined(ARCH_CPU_ARM_FAMILY) || BUILDFLAG(USE_V4L2_CODEC)
 // Experimental support for GL based image processing. On some architectures,
 // the hardware accelerated video decoder outputs frames in a format not
 // understood by the display controller. We usually use LibYUV to convert these
@@ -1317,6 +1319,8 @@ BASE_FEATURE(kUseGLForScaling,
 BASE_FEATURE(kPreferGLImageProcessor,
              "PreferGLImageProcessor",
              base::FEATURE_DISABLED_BY_DEFAULT);
+#endif
+#if defined(ARCH_CPU_ARM_FAMILY)
 // Experimental support for software based MT21 conversion. On some (older)
 // architectures, the hardware video decoder outputs frames in a pixel format
 // known as MT21. Normally a hardware block performs to the conversion between
--- a/src/media/base/media_switches.h
+++ b/src/media/base/media_switches.h
@@ -421,6 +421,10 @@ MEDIA_EXPORT BASE_DECLARE_FEATURE(kEnabl
 MEDIA_EXPORT BASE_DECLARE_FEATURE(kUseAlternateVideoDecoderImplementation);
 #endif  // BUILDFLAG(IS_CHROMEOS) && !BUILDFLAG(USE_VAAPI)
 #endif  // BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
+#if BUILDFLAG(USE_V4L2_CODEC)
+MEDIA_EXPORT BASE_DECLARE_FEATURE(kPreferLibYuvImageProcessor);
+MEDIA_EXPORT BASE_DECLARE_FEATURE(kPreferGLImageProcessor);
+#endif  // defined(ARCH_CPU_ARM_FAMILY)
 
 #if BUILDFLAG(IS_WIN)
 MEDIA_EXPORT BASE_DECLARE_FEATURE(kDirectShowGetPhotoState);
--- a/src/media/gpu/BUILD.gn
+++ b/src/media/gpu/BUILD.gn
@@ -21,6 +21,7 @@ buildflag_header("buildflags") {
     "USE_VAAPI=$use_vaapi",
     "USE_VAAPI_IMAGE_CODECS=$use_vaapi_image_codecs",
     "USE_V4L2_CODEC=$use_v4l2_codec",
+    "USE_V4L2_CODEC_RPI=$use_v4l2_codec_rpi",
     "USE_LIBV4L2=$use_v4lplugin",
   ]
 }
--- a/src/media/gpu/args.gni
+++ b/src/media/gpu/args.gni
@@ -14,6 +14,10 @@ declare_args() {
   use_v4l2_codec =
       is_chromeos_lacros && (target_cpu == "arm" || target_cpu == "arm64")
 
+  # Indicates if this is V4L2 on RPi.  Only compiles stateful V4L2 code
+  # and removes all legacy codecs
+  use_v4l2_codec_rpi = false
+
   # Indicates if VA-API-based hardware acceleration is to be used. This
   # is typically the case on x86-based ChromeOS devices.
   # VA-API should also be compiled by default on x11/wayland linux devices
--- a/src/media/gpu/chromeos/fourcc.cc
+++ b/src/media/gpu/chromeos/fourcc.cc
@@ -34,6 +34,7 @@ std::optional<Fourcc> Fourcc::FromUint32
     case MM21:
     case P010:
     case MT2T:
+    case BGR4:
     case AR24:
     case Q08C:
     case Q10C:
@@ -188,6 +189,7 @@ VideoPixelFormat Fourcc::ToVideoPixelFor
       return PIXEL_FORMAT_P016LE;
     case MT2T:
       return PIXEL_FORMAT_P016LE;
+    case BGR4:
     case AR24:
       return PIXEL_FORMAT_ARGB;
     // V4L2_PIX_FMT_QC08C is a proprietary Qualcomm compressed format that can
@@ -292,6 +294,7 @@ std::optional<Fourcc> Fourcc::ToSinglePl
     case P010:
     case MM21:
     case MT2T:
+    case BGR4:
     case AR24:
       return Fourcc(value_);
     case YM12:
@@ -327,6 +330,7 @@ bool Fourcc::IsMultiPlanar() const {
     case YU16:
     case P010:
     case MT2T:
+    case BGR4:
     case AR24:
     case Q08C:
     case Q10C:
--- a/src/media/gpu/chromeos/fourcc.h
+++ b/src/media/gpu/chromeos/fourcc.h
@@ -100,6 +100,9 @@ class MEDIA_GPU_EXPORT Fourcc {
 
     // Single plane 8-bit little-endian ARGB (bytes in reverse B-G-R-A order).
     AR24 = ComposeFourcc('A', 'R', '2', '4'),
+    // Single plane 8-bit little-endian XRGB (bytes in reverse B-G-R-X order).
+    BGR4 = ComposeFourcc('B', 'G', 'R', '4'),
+
     // V4L2 proprietary format.
     // https://linuxtv.org/downloads/v4l-dvb-apis-new/userspace-api/v4l/pixfmt-reserved.html
     // Opaque format that can only be scanned out as an overlay or composited by
--- a/src/media/gpu/chromeos/image_processor_factory.cc
+++ b/src/media/gpu/chromeos/image_processor_factory.cc
@@ -84,7 +84,6 @@ std::unique_ptr<ImageProcessor> CreateVa
 }
 
 #elif BUILDFLAG(USE_V4L2_CODEC)
-
 std::unique_ptr<ImageProcessor> CreateV4L2ImageProcessorWithInputCandidates(
     const std::vector<PixelLayoutCandidate>& input_candidates,
     const gfx::Rect& visible_rect,
@@ -209,7 +208,7 @@ std::unique_ptr<ImageProcessor> CreateLi
       std::move(client_task_runner));
 }
 
-#if defined(ARCH_CPU_ARM_FAMILY)
+#if defined(ARCH_CPU_ARM_FAMILY) && BUILDFLAG(USE_V4L2_CODEC)
 std::unique_ptr<ImageProcessor> CreateGLImageProcessorWithInputCandidates(
     const std::vector<PixelLayoutCandidate>& input_candidates,
     const gfx::Rect& input_visible_rect,
--- a/src/media/gpu/v4l2/BUILD.gn
+++ b/src/media/gpu/v4l2/BUILD.gn
@@ -65,12 +65,18 @@ source_set("v4l2") {
     "v4l2_video_decoder_delegate_h264.h",
     "v4l2_video_decoder_delegate_vp8.cc",
     "v4l2_video_decoder_delegate_vp8.h",
-    "v4l2_video_decoder_delegate_vp9.cc",
-    "v4l2_video_decoder_delegate_vp9.h",
     "v4l2_vp9_helpers.cc",
     "v4l2_vp9_helpers.h",
   ]
 
+  if (!use_v4l2_codec_rpi) {
+    sources += [
+    # RPI doesn't have VP9 headers
+    "v4l2_video_decoder_delegate_vp9.cc",
+    "v4l2_video_decoder_delegate_vp9.h",
+    ]
+  }
+
   if (enable_hevc_parser_and_hw_decoder) {
     sources += [
       "stateless/h265_delegate.cc",
--- a/src/media/gpu/v4l2/legacy/v4l2_video_decode_accelerator.cc
+++ b/src/media/gpu/v4l2/legacy/v4l2_video_decode_accelerator.cc
@@ -1214,6 +1214,26 @@ bool V4L2VideoDecodeAccelerator::FlushIn
   return (decoder_state_ != kError);
 }
 
+void V4L2VideoDecodeAccelerator::CheckResolutionChangePending() {
+  struct v4l2_format format;
+  gfx::Size visible_size;
+  bool again;
+  GetFormatInfo(&format, &visible_size, &again);
+  gfx::Size new_coded(format.fmt.pix_mp.width, format.fmt.pix_mp.height);
+  if (resolution_change_pending_) {
+    if (coded_size_ == new_coded) {
+      LOG(INFO) << __func__ << ": New resolution " << new_coded.ToString() << " == Old resolution: Cancel change";
+      resolution_change_pending_ = false;
+    }
+  } else {
+    if (coded_size_ != new_coded) {
+      LOG(INFO) << __func__ << ": New resolution " << new_coded.ToString() <<
+        "!= Old resolution: " << coded_size_.ToString() << " Start change";
+      resolution_change_pending_ = true;
+    }
+  }
+}
+
 void V4L2VideoDecodeAccelerator::ServiceDeviceTask(bool event_pending) {
   DVLOGF(4);
   DCHECK(decoder_thread_.task_runner()->BelongsToCurrentThread());
@@ -1237,11 +1257,11 @@ void V4L2VideoDecodeAccelerator::Service
     return;
   }
 
-  bool resolution_change_pending = false;
+  resolution_change_pending_ = false;
   if (event_pending)
-    resolution_change_pending = DequeueResolutionChangeEvent();
+    resolution_change_pending_ = DequeueResolutionChangeEvent();
 
-  if (!resolution_change_pending && coded_size_.IsEmpty()) {
+  if (!resolution_change_pending_ && coded_size_.IsEmpty()) {
     // Some platforms do not send an initial resolution change event.
     // To work around this, we need to keep checking if the initial resolution
     // is known already by explicitly querying the format after each decode,
@@ -1254,11 +1274,15 @@ void V4L2VideoDecodeAccelerator::Service
     gfx::Size visible_size;
     bool again;
     if (GetFormatInfo(&format, &visible_size, &again) && !again) {
-      resolution_change_pending = true;
+      resolution_change_pending_ = true;
       DequeueResolutionChangeEvent();
     }
   }
 
+  if (resolution_change_pending_) {
+    LOG(INFO) << "Resolution change pending";
+  }
+
   Dequeue();
   Enqueue();
 
@@ -1300,7 +1324,7 @@ void V4L2VideoDecodeAccelerator::Service
             << buffers_at_client_.size() << "]";
 
   ScheduleDecodeBufferTaskIfNeeded();
-  if (resolution_change_pending)
+  if (resolution_change_pending_)
     StartResolutionChange();
 }
 
@@ -1587,8 +1611,11 @@ bool V4L2VideoDecodeAccelerator::Enqueue
   }
 
   if (!ret) {
-    LOG(ERROR) << "Error in Dequeue output buffer";
-    NOTIFY_ERROR(PLATFORM_FAILURE);
+    CheckResolutionChangePending();
+    if (!resolution_change_pending_) {
+      LOG(ERROR) << "Error in Enqueue output buffer";
+      NOTIFY_ERROR(PLATFORM_FAILURE);
+    }
     return false;
   }
 
@@ -1749,7 +1776,7 @@ bool V4L2VideoDecodeAccelerator::IsDecod
   memset(&cmd, 0, sizeof(cmd));
   cmd.cmd = V4L2_DEC_CMD_STOP;
   if (device_->Ioctl(VIDIOC_TRY_DECODER_CMD, &cmd) != 0) {
-    VLOGF(2) "V4L2_DEC_CMD_STOP is not supported.";
+    VLOGF(2) << "V4L2_DEC_CMD_STOP is not supported.";
     return false;
   }
 
--- a/src/media/gpu/v4l2/legacy/v4l2_video_decode_accelerator.h
+++ b/src/media/gpu/v4l2/legacy/v4l2_video_decode_accelerator.h
@@ -286,6 +286,9 @@ class MEDIA_GPU_EXPORT V4L2VideoDecodeAc
                       int32_t picture_buffer_id,
                       EGLImageKHR egl_image);
 
+
+  void CheckResolutionChangePending();
+
   // Service I/O on the V4L2 devices.  This task should only be scheduled from
   // DevicePollTask().  If |event_pending| is true, one or more events
   // on file descriptor are pending.
@@ -451,7 +454,11 @@ class MEDIA_GPU_EXPORT V4L2VideoDecodeAc
   // |num_instances_| tracks the number of simultaneous decoders.
   // |can_use_decoder_| is true iff we haven't reached the maximum number of
   // instances at the time this decoder is created.
+#if BUILDFLAG(USE_V4L2_CODEC_RPI)
+  static constexpr int kMaxNumOfInstances = 2;
+#else
   static constexpr int kMaxNumOfInstances = 10;
+#endif
   static base::AtomicRefCount num_instances_;
   const bool can_use_decoder_;
 
@@ -588,6 +595,9 @@ class MEDIA_GPU_EXPORT V4L2VideoDecodeAc
   // The number of pictures that are sent to PictureReady and will be cleared.
   int picture_clearing_count_;
 
+  // We've spotted that we need a res change
+  bool resolution_change_pending_;
+
   // Output picture coded size.
   gfx::Size coded_size_;
 
--- /dev/null
+++ b/src/media/gpu/v4l2/missing-stateless-ctrl.h
@@ -0,0 +1,608 @@
+#include <linux/videodev2.h>
+
+#ifndef V4L2_CTRL_CLASS_CODEC_STATELESS
+#define V4L2_CTRL_CLASS_CODEC_STATELESS 0x00a40000	/* Stateless codecs controls */
+#endif
+
+#ifndef V4L2_CID_CODEC_STATELESS_BASE
+#define V4L2_CID_CODEC_STATELESS_BASE          (V4L2_CTRL_CLASS_CODEC_STATELESS | 0x900)
+#define V4L2_CID_CODEC_STATELESS_CLASS         (V4L2_CTRL_CLASS_CODEC_STATELESS | 1)
+#endif
+
+#ifndef V4L2_PIX_FMT_VP8_FRAME
+#define V4L2_PIX_FMT_VP8_FRAME v4l2_fourcc('V', 'P', '8', 'F') /* VP8 parsed frame */
+
+#define V4L2_CTRL_TYPE_VP8_FRAME            0x0240
+
+/* Stateless VP8 control */
+
+#define V4L2_VP8_SEGMENT_FLAG_ENABLED              0x01
+#define V4L2_VP8_SEGMENT_FLAG_UPDATE_MAP           0x02
+#define V4L2_VP8_SEGMENT_FLAG_UPDATE_FEATURE_DATA  0x04
+#define V4L2_VP8_SEGMENT_FLAG_DELTA_VALUE_MODE     0x08
+
+/**
+ * struct v4l2_vp8_segment - VP8 segment-based adjustments parameters
+ *
+ * @quant_update: update values for the segment quantizer.
+ * @lf_update: update values for the loop filter level.
+ * @segment_probs: branch probabilities of the segment_id decoding tree.
+ * @padding: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_VP8_SEGMENT_FLAG_{}.
+ *
+ * This structure contains segment-based adjustments related parameters.
+ * See the 'update_segmentation()' part of the frame header syntax,
+ * and section '9.3. Segment-Based Adjustments' of the VP8 specification
+ * for more details.
+ */
+struct v4l2_vp8_segment {
+	__s8 quant_update[4];
+	__s8 lf_update[4];
+	__u8 segment_probs[3];
+	__u8 padding;
+	__u32 flags;
+};
+
+#define V4L2_VP8_LF_ADJ_ENABLE	0x01
+#define V4L2_VP8_LF_DELTA_UPDATE	0x02
+#define V4L2_VP8_LF_FILTER_TYPE_SIMPLE	0x04
+
+/**
+ * struct v4l2_vp8_loop_filter - VP8 loop filter parameters
+ *
+ * @ref_frm_delta: Reference frame signed delta values.
+ * @mb_mode_delta: MB prediction mode signed delta values.
+ * @sharpness_level: matches sharpness_level syntax element.
+ * @level: matches loop_filter_level syntax element.
+ * @padding: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_VP8_LF_FLAG_{}.
+ *
+ * This structure contains loop filter related parameters.
+ * See the 'mb_lf_adjustments()' part of the frame header syntax,
+ * and section '9.4. Loop Filter Type and Levels' of the VP8 specification
+ * for more details.
+ */
+struct v4l2_vp8_loop_filter {
+	__s8 ref_frm_delta[4];
+	__s8 mb_mode_delta[4];
+	__u8 sharpness_level;
+	__u8 level;
+	__u16 padding;
+	__u32 flags;
+};
+
+/**
+ * struct v4l2_vp8_quantization - VP8 quantizattion indices
+ *
+ * @y_ac_qi: luma AC coefficient table index.
+ * @y_dc_delta: luma DC delta vaue.
+ * @y2_dc_delta: y2 block DC delta value.
+ * @y2_ac_delta: y2 block AC delta value.
+ * @uv_dc_delta: chroma DC delta value.
+ * @uv_ac_delta: chroma AC delta value.
+ * @padding: padding field. Should be zeroed by applications.
+ *
+ * This structure contains the quantization indices present
+ * in 'quant_indices()' part of the frame header syntax.
+ * See section '9.6. Dequantization Indices' of the VP8 specification
+ * for more details.
+ */
+struct v4l2_vp8_quantization {
+	__u8 y_ac_qi;
+	__s8 y_dc_delta;
+	__s8 y2_dc_delta;
+	__s8 y2_ac_delta;
+	__s8 uv_dc_delta;
+	__s8 uv_ac_delta;
+	__u16 padding;
+};
+
+#define V4L2_VP8_COEFF_PROB_CNT 11
+#define V4L2_VP8_MV_PROB_CNT 19
+
+/**
+ * struct v4l2_vp8_entropy - VP8 update probabilities
+ *
+ * @coeff_probs: coefficient probability update values.
+ * @y_mode_probs: luma intra-prediction probabilities.
+ * @uv_mode_probs: chroma intra-prediction probabilities.
+ * @mv_probs: mv decoding probability.
+ * @padding: padding field. Should be zeroed by applications.
+ *
+ * This structure contains the update probabilities present in
+ * 'token_prob_update()' and 'mv_prob_update()' part of the frame header.
+ * See section '17.2. Probability Updates' of the VP8 specification
+ * for more details.
+ */
+struct v4l2_vp8_entropy {
+	__u8 coeff_probs[4][8][3][V4L2_VP8_COEFF_PROB_CNT];
+	__u8 y_mode_probs[4];
+	__u8 uv_mode_probs[3];
+	__u8 mv_probs[2][V4L2_VP8_MV_PROB_CNT];
+	__u8 padding[3];
+};
+
+/**
+ * struct v4l2_vp8_entropy_coder_state - VP8 boolean coder state
+ *
+ * @range: coder state value for "Range"
+ * @value: coder state value for "Value"
+ * @bit_count: number of bits left in range "Value".
+ * @padding: padding field. Should be zeroed by applications.
+ *
+ * This structure contains the state for the boolean coder, as
+ * explained in section '7. Boolean Entropy Decoder' of the VP8 specification.
+ */
+struct v4l2_vp8_entropy_coder_state {
+	__u8 range;
+	__u8 value;
+	__u8 bit_count;
+	__u8 padding;
+};
+
+#define V4L2_VP8_FRAME_FLAG_KEY_FRAME		0x01
+#define V4L2_VP8_FRAME_FLAG_EXPERIMENTAL		0x02
+#define V4L2_VP8_FRAME_FLAG_SHOW_FRAME		0x04
+#define V4L2_VP8_FRAME_FLAG_MB_NO_SKIP_COEFF	0x08
+#define V4L2_VP8_FRAME_FLAG_SIGN_BIAS_GOLDEN	0x10
+#define V4L2_VP8_FRAME_FLAG_SIGN_BIAS_ALT	0x20
+
+#define V4L2_VP8_FRAME_IS_KEY_FRAME(hdr) \
+	(!!((hdr)->flags & V4L2_VP8_FRAME_FLAG_KEY_FRAME))
+
+#define V4L2_CID_STATELESS_VP8_FRAME (V4L2_CID_CODEC_STATELESS_BASE + 200)
+/**
+ * struct v4l2_ctrl_vp8_frame - VP8 frame parameters
+ *
+ * @segment: segmentation parameters. See &v4l2_vp8_segment for more details
+ * @lf: loop filter parameters. See &v4l2_vp8_loop_filter for more details
+ * @quant: quantization parameters. See &v4l2_vp8_quantization for more details
+ * @entropy: update probabilities. See &v4l2_vp8_entropy for more details
+ * @coder_state: boolean coder state. See &v4l2_vp8_entropy_coder_state for more details
+ * @width: frame width.
+ * @height: frame height.
+ * @horizontal_scale: horizontal scaling factor.
+ * @vertical_scale: vertical scaling factor.
+ * @version: bitstream version.
+ * @prob_skip_false: frame header syntax element.
+ * @prob_intra: frame header syntax element.
+ * @prob_last: frame header syntax element.
+ * @prob_gf: frame header syntax element.
+ * @num_dct_parts: number of DCT coefficients partitions.
+ * @first_part_size: size of the first partition, i.e. the control partition.
+ * @first_part_header_bits: size in bits of the first partition header portion.
+ * @dct_part_sizes: DCT coefficients sizes.
+ * @last_frame_ts: "last" reference buffer timestamp.
+ * The timestamp refers to the timestamp field in struct v4l2_buffer.
+ * Use v4l2_timeval_to_ns() to convert the struct timeval to a __u64.
+ * @golden_frame_ts: "golden" reference buffer timestamp.
+ * @alt_frame_ts: "alt" reference buffer timestamp.
+ * @flags: see V4L2_VP8_FRAME_FLAG_{}.
+ */
+struct v4l2_ctrl_vp8_frame {
+	struct v4l2_vp8_segment segment;
+	struct v4l2_vp8_loop_filter lf;
+	struct v4l2_vp8_quantization quant;
+	struct v4l2_vp8_entropy entropy;
+	struct v4l2_vp8_entropy_coder_state coder_state;
+
+	__u16 width;
+	__u16 height;
+
+	__u8 horizontal_scale;
+	__u8 vertical_scale;
+
+	__u8 version;
+	__u8 prob_skip_false;
+	__u8 prob_intra;
+	__u8 prob_last;
+	__u8 prob_gf;
+	__u8 num_dct_parts;
+
+	__u32 first_part_size;
+	__u32 first_part_header_bits;
+	__u32 dct_part_sizes[8];
+
+	__u64 last_frame_ts;
+	__u64 golden_frame_ts;
+	__u64 alt_frame_ts;
+
+	__u64 flags;
+};
+
+#endif // VP8
+
+//=============================================================================
+
+#ifndef V4L2_PIX_FMT_H264_SLICE
+#define V4L2_PIX_FMT_H264_SLICE v4l2_fourcc('S', '2', '6', '4') /* H264 parsed slices */
+
+#define V4L2_CTRL_TYPE_H264_SPS             0x0200,
+#define V4L2_CTRL_TYPE_H264_PPS		    0x0201,
+#define V4L2_CTRL_TYPE_H264_SCALING_MATRIX  0x0202,
+#define V4L2_CTRL_TYPE_H264_SLICE_PARAMS    0x0203,
+#define V4L2_CTRL_TYPE_H264_DECODE_PARAMS   0x0204,
+#define V4L2_CTRL_TYPE_H264_PRED_WEIGHTS    0x0205,
+
+#define V4L2_CID_STATELESS_H264_DECODE_MODE	(V4L2_CID_CODEC_STATELESS_BASE + 0)
+/**
+ * enum v4l2_stateless_h264_decode_mode - Decoding mode
+ *
+ * @V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED: indicates that decoding
+ * is performed one slice at a time. In this mode,
+ * V4L2_CID_STATELESS_H264_SLICE_PARAMS must contain the parsed slice
+ * parameters and the OUTPUT buffer must contain a single slice.
+ * V4L2_BUF_CAP_SUPPORTS_M2M_HOLD_CAPTURE_BUF feature is used
+ * in order to support multislice frames.
+ * @V4L2_STATELESS_H264_DECODE_MODE_FRAME_BASED: indicates that
+ * decoding is performed per frame. The OUTPUT buffer must contain
+ * all slices and also both fields. This mode is typically supported
+ * by device drivers that are able to parse the slice(s) header(s)
+ * in hardware. When this mode is selected,
+ * V4L2_CID_STATELESS_H264_SLICE_PARAMS is not used.
+ */
+enum v4l2_stateless_h264_decode_mode {
+	V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED,
+	V4L2_STATELESS_H264_DECODE_MODE_FRAME_BASED,
+};
+
+#define V4L2_CID_STATELESS_H264_START_CODE	(V4L2_CID_CODEC_STATELESS_BASE + 1)
+/**
+ * enum v4l2_stateless_h264_start_code - Start code
+ *
+ * @V4L2_STATELESS_H264_START_CODE_NONE: slices are passed
+ * to the driver without any start code.
+ * @V4L2_STATELESS_H264_START_CODE_ANNEX_B: slices are passed
+ * to the driver with an Annex B start code prefix
+ * (legal start codes can be 3-bytes 0x000001 or 4-bytes 0x00000001).
+ * This mode is typically supported by device drivers that parse
+ * the start code in hardware.
+ */
+enum v4l2_stateless_h264_start_code {
+	V4L2_STATELESS_H264_START_CODE_NONE,
+	V4L2_STATELESS_H264_START_CODE_ANNEX_B,
+};
+
+#define V4L2_H264_SPS_CONSTRAINT_SET0_FLAG			0x01
+#define V4L2_H264_SPS_CONSTRAINT_SET1_FLAG			0x02
+#define V4L2_H264_SPS_CONSTRAINT_SET2_FLAG			0x04
+#define V4L2_H264_SPS_CONSTRAINT_SET3_FLAG			0x08
+#define V4L2_H264_SPS_CONSTRAINT_SET4_FLAG			0x10
+#define V4L2_H264_SPS_CONSTRAINT_SET5_FLAG			0x20
+
+#define V4L2_H264_SPS_FLAG_SEPARATE_COLOUR_PLANE		0x01
+#define V4L2_H264_SPS_FLAG_QPPRIME_Y_ZERO_TRANSFORM_BYPASS	0x02
+#define V4L2_H264_SPS_FLAG_DELTA_PIC_ORDER_ALWAYS_ZERO		0x04
+#define V4L2_H264_SPS_FLAG_GAPS_IN_FRAME_NUM_VALUE_ALLOWED	0x08
+#define V4L2_H264_SPS_FLAG_FRAME_MBS_ONLY			0x10
+#define V4L2_H264_SPS_FLAG_MB_ADAPTIVE_FRAME_FIELD		0x20
+#define V4L2_H264_SPS_FLAG_DIRECT_8X8_INFERENCE			0x40
+
+#define V4L2_H264_SPS_HAS_CHROMA_FORMAT(sps) \
+	((sps)->profile_idc == 100 || (sps)->profile_idc == 110 || \
+	 (sps)->profile_idc == 122 || (sps)->profile_idc == 244 || \
+	 (sps)->profile_idc == 44  || (sps)->profile_idc == 83  || \
+	 (sps)->profile_idc == 86  || (sps)->profile_idc == 118 || \
+	 (sps)->profile_idc == 128 || (sps)->profile_idc == 138 || \
+	 (sps)->profile_idc == 139 || (sps)->profile_idc == 134 || \
+	 (sps)->profile_idc == 135)
+
+#define V4L2_CID_STATELESS_H264_SPS		(V4L2_CID_CODEC_STATELESS_BASE + 2)
+/**
+ * struct v4l2_ctrl_h264_sps - H264 sequence parameter set
+ *
+ * All the members on this sequence parameter set structure match the
+ * sequence parameter set syntax as specified by the H264 specification.
+ *
+ * @profile_idc: see H264 specification.
+ * @constraint_set_flags: see H264 specification.
+ * @level_idc: see H264 specification.
+ * @seq_parameter_set_id: see H264 specification.
+ * @chroma_format_idc: see H264 specification.
+ * @bit_depth_luma_minus8: see H264 specification.
+ * @bit_depth_chroma_minus8: see H264 specification.
+ * @log2_max_frame_num_minus4: see H264 specification.
+ * @pic_order_cnt_type: see H264 specification.
+ * @log2_max_pic_order_cnt_lsb_minus4: see H264 specification.
+ * @max_num_ref_frames: see H264 specification.
+ * @num_ref_frames_in_pic_order_cnt_cycle: see H264 specification.
+ * @offset_for_ref_frame: see H264 specification.
+ * @offset_for_non_ref_pic: see H264 specification.
+ * @offset_for_top_to_bottom_field: see H264 specification.
+ * @pic_width_in_mbs_minus1: see H264 specification.
+ * @pic_height_in_map_units_minus1: see H264 specification.
+ * @flags: see V4L2_H264_SPS_FLAG_{}.
+ */
+struct v4l2_ctrl_h264_sps {
+	__u8 profile_idc;
+	__u8 constraint_set_flags;
+	__u8 level_idc;
+	__u8 seq_parameter_set_id;
+	__u8 chroma_format_idc;
+	__u8 bit_depth_luma_minus8;
+	__u8 bit_depth_chroma_minus8;
+	__u8 log2_max_frame_num_minus4;
+	__u8 pic_order_cnt_type;
+	__u8 log2_max_pic_order_cnt_lsb_minus4;
+	__u8 max_num_ref_frames;
+	__u8 num_ref_frames_in_pic_order_cnt_cycle;
+	__s32 offset_for_ref_frame[255];
+	__s32 offset_for_non_ref_pic;
+	__s32 offset_for_top_to_bottom_field;
+	__u16 pic_width_in_mbs_minus1;
+	__u16 pic_height_in_map_units_minus1;
+	__u32 flags;
+};
+
+#define V4L2_H264_PPS_FLAG_ENTROPY_CODING_MODE				0x0001
+#define V4L2_H264_PPS_FLAG_BOTTOM_FIELD_PIC_ORDER_IN_FRAME_PRESENT	0x0002
+#define V4L2_H264_PPS_FLAG_WEIGHTED_PRED				0x0004
+#define V4L2_H264_PPS_FLAG_DEBLOCKING_FILTER_CONTROL_PRESENT		0x0008
+#define V4L2_H264_PPS_FLAG_CONSTRAINED_INTRA_PRED			0x0010
+#define V4L2_H264_PPS_FLAG_REDUNDANT_PIC_CNT_PRESENT			0x0020
+#define V4L2_H264_PPS_FLAG_TRANSFORM_8X8_MODE				0x0040
+#define V4L2_H264_PPS_FLAG_SCALING_MATRIX_PRESENT			0x0080
+
+#define V4L2_CID_STATELESS_H264_PPS		(V4L2_CID_CODEC_STATELESS_BASE + 3)
+/**
+ * struct v4l2_ctrl_h264_pps - H264 picture parameter set
+ *
+ * Except where noted, all the members on this picture parameter set
+ * structure match the picture parameter set syntax as specified
+ * by the H264 specification.
+ *
+ * In particular, V4L2_H264_PPS_FLAG_SCALING_MATRIX_PRESENT flag
+ * has a specific meaning. This flag should be set if a non-flat
+ * scaling matrix applies to the picture. In this case, applications
+ * are expected to use V4L2_CID_STATELESS_H264_SCALING_MATRIX,
+ * to pass the values of the non-flat matrices.
+ *
+ * @pic_parameter_set_id: see H264 specification.
+ * @seq_parameter_set_id: see H264 specification.
+ * @num_slice_groups_minus1: see H264 specification.
+ * @num_ref_idx_l0_default_active_minus1: see H264 specification.
+ * @num_ref_idx_l1_default_active_minus1: see H264 specification.
+ * @weighted_bipred_idc: see H264 specification.
+ * @pic_init_qp_minus26: see H264 specification.
+ * @pic_init_qs_minus26: see H264 specification.
+ * @chroma_qp_index_offset: see H264 specification.
+ * @second_chroma_qp_index_offset: see H264 specification.
+ * @flags: see V4L2_H264_PPS_FLAG_{}.
+ */
+struct v4l2_ctrl_h264_pps {
+	__u8 pic_parameter_set_id;
+	__u8 seq_parameter_set_id;
+	__u8 num_slice_groups_minus1;
+	__u8 num_ref_idx_l0_default_active_minus1;
+	__u8 num_ref_idx_l1_default_active_minus1;
+	__u8 weighted_bipred_idc;
+	__s8 pic_init_qp_minus26;
+	__s8 pic_init_qs_minus26;
+	__s8 chroma_qp_index_offset;
+	__s8 second_chroma_qp_index_offset;
+	__u16 flags;
+};
+
+#define V4L2_CID_STATELESS_H264_SCALING_MATRIX	(V4L2_CID_CODEC_STATELESS_BASE + 4)
+/**
+ * struct v4l2_ctrl_h264_scaling_matrix - H264 scaling matrices
+ *
+ * @scaling_list_4x4: scaling matrix after applying the inverse
+ * scanning process. Expected list order is Intra Y, Intra Cb,
+ * Intra Cr, Inter Y, Inter Cb, Inter Cr. The values on each
+ * scaling list are expected in raster scan order.
+ * @scaling_list_8x8: scaling matrix after applying the inverse
+ * scanning process. Expected list order is Intra Y, Inter Y,
+ * Intra Cb, Inter Cb, Intra Cr, Inter Cr. The values on each
+ * scaling list are expected in raster scan order.
+ *
+ * Note that the list order is different for the 4x4 and 8x8
+ * matrices as per the H264 specification, see table 7-2 "Assignment
+ * of mnemonic names to scaling list indices and specification of
+ * fall-back rule".
+ */
+struct v4l2_ctrl_h264_scaling_matrix {
+	__u8 scaling_list_4x4[6][16];
+	__u8 scaling_list_8x8[6][64];
+};
+
+struct v4l2_h264_weight_factors {
+	__s16 luma_weight[32];
+	__s16 luma_offset[32];
+	__s16 chroma_weight[32][2];
+	__s16 chroma_offset[32][2];
+};
+
+#define V4L2_H264_CTRL_PRED_WEIGHTS_REQUIRED(pps, slice) \
+	((((pps)->flags & V4L2_H264_PPS_FLAG_WEIGHTED_PRED) && \
+	 ((slice)->slice_type == V4L2_H264_SLICE_TYPE_P || \
+	  (slice)->slice_type == V4L2_H264_SLICE_TYPE_SP)) || \
+	 ((pps)->weighted_bipred_idc == 1 && \
+	  (slice)->slice_type == V4L2_H264_SLICE_TYPE_B))
+
+#define V4L2_CID_STATELESS_H264_PRED_WEIGHTS	(V4L2_CID_CODEC_STATELESS_BASE + 5)
+/**
+ * struct v4l2_ctrl_h264_pred_weights - Prediction weight table
+ *
+ * Prediction weight table, which matches the syntax specified
+ * by the H264 specification.
+ *
+ * @luma_log2_weight_denom: see H264 specification.
+ * @chroma_log2_weight_denom: see H264 specification.
+ * @weight_factors: luma and chroma weight factors.
+ */
+struct v4l2_ctrl_h264_pred_weights {
+	__u16 luma_log2_weight_denom;
+	__u16 chroma_log2_weight_denom;
+	struct v4l2_h264_weight_factors weight_factors[2];
+};
+
+#define V4L2_H264_SLICE_TYPE_P				0
+#define V4L2_H264_SLICE_TYPE_B				1
+#define V4L2_H264_SLICE_TYPE_I				2
+#define V4L2_H264_SLICE_TYPE_SP				3
+#define V4L2_H264_SLICE_TYPE_SI				4
+
+#define V4L2_H264_SLICE_FLAG_DIRECT_SPATIAL_MV_PRED	0x01
+#define V4L2_H264_SLICE_FLAG_SP_FOR_SWITCH		0x02
+
+#define V4L2_H264_TOP_FIELD_REF				0x1
+#define V4L2_H264_BOTTOM_FIELD_REF			0x2
+#define V4L2_H264_FRAME_REF				0x3
+
+/**
+ * struct v4l2_h264_reference - H264 picture reference
+ *
+ * @fields: indicates how the picture is referenced.
+ * Valid values are V4L2_H264_{}_REF.
+ * @index: index into v4l2_ctrl_h264_decode_params.dpb[].
+ */
+struct v4l2_h264_reference {
+	__u8 fields;
+	__u8 index;
+};
+
+/*
+ * Maximum DPB size, as specified by section 'A.3.1 Level limits
+ * common to the Baseline, Main, and Extended profiles'.
+ */
+#define V4L2_H264_NUM_DPB_ENTRIES 16
+#define V4L2_H264_REF_LIST_LEN (2 * V4L2_H264_NUM_DPB_ENTRIES)
+
+#define V4L2_CID_STATELESS_H264_SLICE_PARAMS	(V4L2_CID_CODEC_STATELESS_BASE + 6)
+/**
+ * struct v4l2_ctrl_h264_slice_params - H264 slice parameters
+ *
+ * This structure holds the H264 syntax elements that are specified
+ * as non-invariant for the slices in a given frame.
+ *
+ * Slice invariant syntax elements are contained in struct
+ * v4l2_ctrl_h264_decode_params. This is done to reduce the API surface
+ * on frame-based decoders, where slice header parsing is done by the
+ * hardware.
+ *
+ * Slice invariant syntax elements are specified in specification section
+ * "7.4.3 Slice header semantics".
+ *
+ * Except where noted, the members on this struct match the slice header syntax.
+ *
+ * @header_bit_size: offset in bits to slice_data() from the beginning of this slice.
+ * @first_mb_in_slice: see H264 specification.
+ * @slice_type: see H264 specification.
+ * @colour_plane_id: see H264 specification.
+ * @redundant_pic_cnt: see H264 specification.
+ * @cabac_init_idc: see H264 specification.
+ * @slice_qp_delta: see H264 specification.
+ * @slice_qs_delta: see H264 specification.
+ * @disable_deblocking_filter_idc: see H264 specification.
+ * @slice_alpha_c0_offset_div2: see H264 specification.
+ * @slice_beta_offset_div2: see H264 specification.
+ * @num_ref_idx_l0_active_minus1: see H264 specification.
+ * @num_ref_idx_l1_active_minus1: see H264 specification.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @ref_pic_list0: reference picture list 0 after applying the per-slice modifications.
+ * @ref_pic_list1: reference picture list 1 after applying the per-slice modifications.
+ * @flags: see V4L2_H264_SLICE_FLAG_{}.
+ */
+struct v4l2_ctrl_h264_slice_params {
+	__u32 header_bit_size;
+	__u32 first_mb_in_slice;
+	__u8 slice_type;
+	__u8 colour_plane_id;
+	__u8 redundant_pic_cnt;
+	__u8 cabac_init_idc;
+	__s8 slice_qp_delta;
+	__s8 slice_qs_delta;
+	__u8 disable_deblocking_filter_idc;
+	__s8 slice_alpha_c0_offset_div2;
+	__s8 slice_beta_offset_div2;
+	__u8 num_ref_idx_l0_active_minus1;
+	__u8 num_ref_idx_l1_active_minus1;
+
+	__u8 reserved;
+
+	struct v4l2_h264_reference ref_pic_list0[V4L2_H264_REF_LIST_LEN];
+	struct v4l2_h264_reference ref_pic_list1[V4L2_H264_REF_LIST_LEN];
+
+	__u32 flags;
+};
+
+#define V4L2_H264_DPB_ENTRY_FLAG_VALID		0x01
+#define V4L2_H264_DPB_ENTRY_FLAG_ACTIVE		0x02
+#define V4L2_H264_DPB_ENTRY_FLAG_LONG_TERM	0x04
+#define V4L2_H264_DPB_ENTRY_FLAG_FIELD		0x08
+
+/**
+ * struct v4l2_h264_dpb_entry - H264 decoded picture buffer entry
+ *
+ * @reference_ts: timestamp of the V4L2 capture buffer to use as reference.
+ * The timestamp refers to the timestamp field in struct v4l2_buffer.
+ * Use v4l2_timeval_to_ns() to convert the struct timeval to a __u64.
+ * @pic_num: matches PicNum variable assigned during the reference
+ * picture lists construction process.
+ * @frame_num: frame identifier which matches frame_num syntax element.
+ * @fields: indicates how the DPB entry is referenced. Valid values are
+ * V4L2_H264_{}_REF.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @top_field_order_cnt: matches TopFieldOrderCnt picture value.
+ * @bottom_field_order_cnt: matches BottomFieldOrderCnt picture value.
+ * Note that picture field is indicated by v4l2_buffer.field.
+ * @flags: see V4L2_H264_DPB_ENTRY_FLAG_{}.
+ */
+struct v4l2_h264_dpb_entry {
+	__u64 reference_ts;
+	__u32 pic_num;
+	__u16 frame_num;
+	__u8 fields;
+	__u8 reserved[5];
+	__s32 top_field_order_cnt;
+	__s32 bottom_field_order_cnt;
+	__u32 flags;
+};
+
+#define V4L2_H264_DECODE_PARAM_FLAG_IDR_PIC		0x01
+#define V4L2_H264_DECODE_PARAM_FLAG_FIELD_PIC		0x02
+#define V4L2_H264_DECODE_PARAM_FLAG_BOTTOM_FIELD	0x04
+
+#define V4L2_CID_STATELESS_H264_DECODE_PARAMS	(V4L2_CID_CODEC_STATELESS_BASE + 7)
+/**
+ * struct v4l2_ctrl_h264_decode_params - H264 decoding parameters
+ *
+ * @dpb: decoded picture buffer.
+ * @nal_ref_idc: slice header syntax element.
+ * @frame_num: slice header syntax element.
+ * @top_field_order_cnt: matches TopFieldOrderCnt picture value.
+ * @bottom_field_order_cnt: matches BottomFieldOrderCnt picture value.
+ * Note that picture field is indicated by v4l2_buffer.field.
+ * @idr_pic_id: slice header syntax element.
+ * @pic_order_cnt_lsb: slice header syntax element.
+ * @delta_pic_order_cnt_bottom: slice header syntax element.
+ * @delta_pic_order_cnt0: slice header syntax element.
+ * @delta_pic_order_cnt1: slice header syntax element.
+ * @dec_ref_pic_marking_bit_size: size in bits of dec_ref_pic_marking()
+ * syntax element.
+ * @pic_order_cnt_bit_size: size in bits of pic order count syntax.
+ * @slice_group_change_cycle: slice header syntax element.
+ * @reserved: padding field. Should be zeroed by applications.
+ * @flags: see V4L2_H264_DECODE_PARAM_FLAG_{}.
+ */
+struct v4l2_ctrl_h264_decode_params {
+	struct v4l2_h264_dpb_entry dpb[V4L2_H264_NUM_DPB_ENTRIES];
+	__u16 nal_ref_idc;
+	__u16 frame_num;
+	__s32 top_field_order_cnt;
+	__s32 bottom_field_order_cnt;
+	__u16 idr_pic_id;
+	__u16 pic_order_cnt_lsb;
+	__s32 delta_pic_order_cnt_bottom;
+	__s32 delta_pic_order_cnt0;
+	__s32 delta_pic_order_cnt1;
+	__u32 dec_ref_pic_marking_bit_size;
+	__u32 pic_order_cnt_bit_size;
+	__u32 slice_group_change_cycle;
+
+	__u32 reserved;
+	__u32 flags;
+};
+
+#endif
--- a/src/media/gpu/v4l2/v4l2_device.cc
+++ b/src/media/gpu/v4l2/v4l2_device.cc
@@ -53,6 +53,17 @@ uint32_t V4L2PixFmtToDrmFormat(uint32_t
       return DRM_FORMAT_YVU420;
 
     case V4L2_PIX_FMT_RGB32:
+    case V4L2_PIX_FMT_XRGB32:
+      return DRM_FORMAT_BGRX8888;
+
+    case V4L2_PIX_FMT_ARGB32:
+      return DRM_FORMAT_BGRA8888;
+
+    case V4L2_PIX_FMT_BGR32:
+    case V4L2_PIX_FMT_BGRX32:
+      return DRM_FORMAT_XRGB8888;
+
+    case V4L2_PIX_FMT_BGRA32:
       return DRM_FORMAT_ARGB8888;
 
     default:
@@ -913,11 +924,19 @@ void V4L2Device::CloseDevice() {
 }
 
 void V4L2Device::EnumerateDevicesForType(Type type) {
+#if BUILDFLAG(USE_V4L2_CODEC_RPI)
+  static const std::string kDecoderDevicePattern = "/dev/video";
+  static const std::string kEncoderDevicePattern = "/dev/video";
+  static const std::string kImageProcessorDevicePattern = "/dev/video";
+  static const std::string kJpegDecoderDevicePattern = "/dev/video";
+  static const std::string kJpegEncoderDevicePattern = "/dev/video";
+#else
   static const std::string kDecoderDevicePattern = "/dev/video-dec";
   static const std::string kEncoderDevicePattern = "/dev/video-enc";
   static const std::string kImageProcessorDevicePattern = "/dev/image-proc";
   static const std::string kJpegDecoderDevicePattern = "/dev/jpeg-dec";
   static const std::string kJpegEncoderDevicePattern = "/dev/jpeg-enc";
+#endif
 
   std::string device_pattern;
   v4l2_buf_type buf_type;
@@ -953,7 +972,11 @@ void V4L2Device::EnumerateDevicesForType
   // We are sandboxed, so we can't query directory contents to check which
   // devices are actually available. Try to open the first 10; if not present,
   // we will just fail to open immediately.
+#if BUILDFLAG(USE_V4L2_CODEC_RPI)
+  for (int i = 10; i < 35; ++i) {
+#else
   for (int i = 0; i < 10; ++i) {
+#endif
     candidate_paths.push_back(
         base::StringPrintf("%s%d", device_pattern.c_str(), i));
   }
--- a/src/media/gpu/v4l2/v4l2_device.h
+++ b/src/media/gpu/v4l2/v4l2_device.h
@@ -34,6 +34,7 @@
 #include "media/base/video_decoder_config.h"
 #include "media/base/video_frame.h"
 #include "media/base/video_frame_layout.h"
+#include "media/gpu/buildflags.h"
 #include "media/gpu/chromeos/fourcc.h"
 #include "media/gpu/media_gpu_export.h"
 #include "media/gpu/v4l2/v4l2_device_poller.h"
@@ -44,6 +45,11 @@
 #include "ui/gfx/geometry/size.h"
 #include "ui/gl/gl_bindings.h"
 
+// RPI doesn't know about this yet
+#ifndef V4L2_PIX_FMT_VP9_FRAME
+#define V4L2_PIX_FMT_VP9_FRAME v4l2_fourcc('V', 'P', '9', 'F')
+#endif
+
 // This has not been accepted upstream.
 #ifndef V4L2_PIX_FMT_AV1
 #define V4L2_PIX_FMT_AV1 v4l2_fourcc('A', 'V', '0', '1') /* AV1 */
--- a/src/media/gpu/v4l2/v4l2_utils.cc
+++ b/src/media/gpu/v4l2/v4l2_utils.cc
@@ -503,7 +503,13 @@ struct timeval TimeDeltaToTimeVal(base::
 std::optional<SupportedVideoDecoderConfigs> GetSupportedV4L2DecoderConfigs() {
   SupportedVideoDecoderConfigs supported_media_configs;
 
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   constexpr char kVideoDeviceDriverPath[] = "/dev/video-dec0";
+#else
+  // Pi stateful decoder here  current google code doesn't look like it can
+  // cope with multiple devioces
+  constexpr char kVideoDeviceDriverPath[] = "/dev/video10";
+#endif
   base::ScopedFD device_fd(HANDLE_EINTR(
       open(kVideoDeviceDriverPath, O_RDWR | O_NONBLOCK | O_CLOEXEC)));
   if (!device_fd.is_valid()) {
@@ -548,7 +554,13 @@ std::optional<SupportedVideoDecoderConfi
 }
 
 bool IsV4L2DecoderStateful() {
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   constexpr char kVideoDeviceDriverPath[] = "/dev/video-dec0";
+#else
+  // Pi stateful decoder here  current google code doesn't look like it can
+  // cope with multiple devioces
+  constexpr char kVideoDeviceDriverPath[] = "/dev/video10";
+#endif
   base::ScopedFD device_fd(HANDLE_EINTR(
       open(kVideoDeviceDriverPath, O_RDWR | O_NONBLOCK | O_CLOEXEC)));
   if (!device_fd.is_valid()) {
--- a/src/media/gpu/v4l2/v4l2_video_decoder.h
+++ b/src/media/gpu/v4l2/v4l2_video_decoder.h
@@ -6,6 +6,7 @@
 #define MEDIA_GPU_V4L2_V4L2_VIDEO_DECODER_H_
 
 #include <linux/videodev2.h>
+#include "missing-stateless-ctrl.h"
 
 #include <map>
 #include <memory>
--- a/src/media/gpu/v4l2/v4l2_video_decoder_backend_stateless.cc
+++ b/src/media/gpu/v4l2/v4l2_video_decoder_backend_stateless.cc
@@ -736,10 +736,12 @@ bool V4L2StatelessVideoDecoderBackend::C
     decoder_ = std::make_unique<VP8Decoder>(
         std::make_unique<V4L2VideoDecoderDelegateVP8>(this, device_.get()),
         color_space_);
+#if !BUILDFLAG(USE_V4L2_CODEC_RPI)
   } else if (profile_ >= VP9PROFILE_MIN && profile_ <= VP9PROFILE_MAX) {
     decoder_ = std::make_unique<VP9Decoder>(
         std::make_unique<V4L2VideoDecoderDelegateVP9>(this, device_.get()),
         profile_, color_space_);
+#endif
 #if BUILDFLAG(IS_CHROMEOS)
   } else if (profile_ >= AV1PROFILE_MIN && profile_ <= AV1PROFILE_MAX) {
     decoder_ = std::make_unique<AV1Decoder>(
--- a/src/media/gpu/v4l2/v4l2_video_decoder_delegate_h264.h
+++ b/src/media/gpu/v4l2/v4l2_video_decoder_delegate_h264.h
@@ -16,6 +16,8 @@
 #include "media/gpu/h264_dpb.h"
 #include "media/video/h264_parser.h"
 
+#include "missing-stateless-ctrl.h"
+
 namespace media {
 
 class V4L2Device;
--- a/src/media/gpu/v4l2/v4l2_video_decoder_delegate_vp8.h
+++ b/src/media/gpu/v4l2/v4l2_video_decoder_delegate_vp8.h
@@ -9,6 +9,8 @@
 #include "base/memory/scoped_refptr.h"
 #include "media/gpu/vp8_decoder.h"
 
+#include "missing-stateless-ctrl.h"
+
 namespace media {
 
 class V4L2Device;
--- a/src/media/mojo/services/gpu_mojo_media_client_linux.cc
+++ b/src/media/mojo/services/gpu_mojo_media_client_linux.cc
@@ -13,16 +13,19 @@
 #include "media/gpu/chromeos/mailbox_video_frame_converter.h"
 #include "media/gpu/chromeos/platform_video_frame_pool.h"
 #include "media/gpu/chromeos/video_decoder_pipeline.h"
+#include "media/gpu/ipc/service/vda_video_decoder.h"
 
 namespace media {
 
 namespace {
 
 VideoDecoderType GetPreferredLinuxDecoderImplementation() {
+#if BUILDFLAG(USE_VAAPI)
   // VaapiVideoDecoder flag is required for VaapiVideoDecoder.
   if (!base::FeatureList::IsEnabled(kVaapiVideoDecodeLinux)) {
     return VideoDecoderType::kUnknown;
   }
+#endif
 
   switch (media::GetOutOfProcessVideoDecodingMode()) {
     case media::OOPVDMode::kEnabledWithGpuProcessAsProxy:
@@ -35,6 +38,11 @@ VideoDecoderType GetPreferredLinuxDecode
       break;
   }
 
+  // If direct video decoder is disabled, revert to using the VDA
+  // implementation.
+  if (!base::FeatureList::IsEnabled(kUseChromeOSDirectVideoDecoder)) {
+    return VideoDecoderType::kVda;
+  }
 #if BUILDFLAG(USE_VAAPI)
   return VideoDecoderType::kVaapi;
 #elif BUILDFLAG(USE_V4L2_CODEC)
@@ -54,6 +62,7 @@ std::vector<Fourcc> GetPreferredRenderab
 
   // Support 1-copy argb textures.
   renderable_fourccs.emplace_back(Fourcc::AR24);
+  renderable_fourccs.emplace_back(Fourcc::BGR4);
 
   return renderable_fourccs;
 }
@@ -61,7 +70,7 @@ std::vector<Fourcc> GetPreferredRenderab
 VideoDecoderType GetActualPlatformDecoderImplementation(
     const gpu::GpuPreferences& gpu_preferences,
     const gpu::GPUInfo& gpu_info) {
-  // On linux, Vaapi has GL restrictions.
+  // On linux, VDA and Vaapi have GL restrictions.
   switch (GetPreferredLinuxDecoderImplementation()) {
     case VideoDecoderType::kUnknown:
       return VideoDecoderType::kUnknown;
@@ -69,6 +78,11 @@ VideoDecoderType GetActualPlatformDecode
       return VideoDecoderType::kOutOfProcess;
     case VideoDecoderType::kV4L2:
       return VideoDecoderType::kV4L2;
+    case VideoDecoderType::kVda: {
+      return gpu_preferences.gr_context_type == gpu::GrContextType::kGL
+                 ? VideoDecoderType::kVda
+                 : VideoDecoderType::kUnknown;
+    }
     case VideoDecoderType::kVaapi: {
       // Allow VaapiVideoDecoder on GL.
       if (gpu_preferences.gr_context_type == gpu::GrContextType::kGL) {
@@ -161,6 +175,13 @@ std::unique_ptr<VideoDecoder> CreatePlat
           traits.media_log->Clone(), /*oop_video_decoder=*/{},
           /*in_video_decoder_process=*/false);
     }
+    case VideoDecoderType::kVda: {
+      return VdaVideoDecoder::Create(
+          traits.task_runner, traits.gpu_task_runner, traits.media_log->Clone(),
+          *traits.target_color_space, traits.gpu_preferences,
+          *traits.gpu_workarounds, traits.get_command_buffer_stub_cb,
+          VideoDecodeAccelerator::Config::OutputMode::kAllocate);
+    }
     default:
       return nullptr;
   }
@@ -196,6 +217,8 @@ GetPlatformSupportedVideoDecoderConfigs(
   base::UmaHistogramEnumeration("Media.VaapiLinux.SupportedVideoDecoder",
                                 decoder_implementation);
   switch (decoder_implementation) {
+    case VideoDecoderType::kVda:
+      return std::move(get_vda_configs).Run();
     case VideoDecoderType::kOutOfProcess:
     case VideoDecoderType::kVaapi:
     case VideoDecoderType::kV4L2:
--- /dev/null
+++ b/src/pi-util/BUILD.txt
@@ -0,0 +1,256 @@
+Build notes (cross compile from Ubuntu)
+=======================================
+
+Build from a patch
+------------------
+
+# Pick somewhere to put this
+cd ~
+mkdir chromium
+cd chromium
+# Get the build tools & put on path
+# You may want to add the path in .bashrc
+git clone https://chromium.googlesource.com/chromium/tools/depot_tools
+export PATH=$PATH:`pwd`/depot_tools
+# Get the main tree
+fetch chromium
+cd src
+# Checkout the version you want
+# * Fix version number
+git checkout 55.0.2883.99
+# Fix up any missing dependancies on the build m/c
+# * may well be unnecessary if you have built any other chrome
+./build/install-build-deps.sh
+./build/install-build-deps.sh --arm
+# Fetch & pull the other bits of the tree to sync.
+# As we are checking out a tag the --with_branch_heads is important
+gclient sync --with_branch_heads
+# Patch - should be completely clean if everything matchs
+# * Fix patch file to correct name / location
+cd ..
+patch -p1 < v55.0.2883.99.patch
+cd src
+# * Get a sysroot from somewhere and put it in build/linux/raspian_jessie_pi1-sysroot
+# * Example below is only if you have got an appropriate one lying around
+# * Otherwise follow sysroot instructions further down
+rsync -rl previous_location/raspian_jessie_pi1-sysroot build/linux/
+# Build output directories (out/armv6, out/armv7)
+# * This script currently assumes a sysroot of build/linux/raspian_jessie_pi1-sysroot
+#   so may need editing if you have put it elsewhere
+pi-util/gngen.py
+# Build chrome
+ninja -C out/armv6 chrome chrome_sandbox
+# Build armv7 ffmpeg
+ninja -C out/armv7 third_party/ffmpeg
+
+
+To run on a Pi
+--------------
+
+This requires a little installation.  The sandbox and ffmpeg shared libs
+need to be copied to the pi.  As neither is being tweaked much by me these
+steps should only be required if the underlying Chrome changes.  Otherwise
+you can just run out of the build directory (src/out/armv6)
+
+Assuming you can mount the build dir from the pi.
+
+# On the Pi NOT the build machine
+cd <path to build env>/src
+# Copy the ffmpeg libs
+pi-util/cplibs.sh
+# Copy the sandbox. BUILDTYPE tells the script where to get it from
+# This doesn't seem to be needed anymore with linux 4.9 and chrome 55
+BUILDTYPE=armv6 build/update-linux-sandbox.sh
+# Run chrome
+cd out/armv6
+./chrome
+
+
+Rebuilds
+--------
+
+In most cases a simple "ninja -C out/armv6 chrome" is all that is needed
+and the pi can run from out/armv6.
+
+To clean build "rm -rf out" and follow the build instructions from gngen.py
+
+
+Updating chromium from git
+--------------------------
+
+There is no script for this as the merges are prone to conflicts and it
+is much easier to sort them if you are doing stuff manually.
+
+If updating between major versions then mergeing tends to fail horribly
+so something along the lines of:
+
+# Look for where we are going
+git tag -l "118.*"
+TAG=118...
+
+# Remember where we are
+OLDTAG=`sed -nE 's/^src[^0-9]*([0-9.]+)"$/\1/p' pi-util/pipaths.py`
+OLDVER=`echo $OLDTAG | sed -nE 's/^([0-9]+).*$/\1/p'`
+echo OLDTAG=$OLDTAG OLDVER=$OLDVER
+
+NEWVER=`echo $TAG | sed -nE 's/^([0-9]+).*$/\1/p'`
+echo NEWTAG=$TAG NEWVER=$NEWVER
+
+# * Make sure there are no updates required and no untracked files
+pi-util/gitscan.py status
+# Set rename limit to huge as files are moved around frequently and getting
+# git to track them is much easier than trying to do it ourselves
+git config diff.renameLimit 1000000
+
+# Tag source & make a patch file - patch file is useful when files are moved
+# as then git goes all unhelpful
+pi-util/dodiff.py > ../v${OLDTAG}_stash.patch
+# As git stash will reset the branch switch to a temp branch 1st
+pi-util/gitscan.py checkout -b stash/${OLDVER}/base
+pi-util/gitscan.py --gitscan-no-src reset {BASE}
+pi-util/gitscan.py --gitscan-no-src stash -u
+pi-util/gitscan.py --gitscan-no-src checkout {BASE}
+
+# Need to do src separately as the stash will lose pi-utils
+git reset $OLDTAG
+git stash -u
+
+git checkout $TAG -b test/${NEWVER}/rpi_2
+
+# Clean out old objects
+rm -rf out
+# Beware that git clean might kill our sub-repos so so don't do it unless we
+# are sure it won't
+# git clean -dxf
+
+### Do the "get environment" stages of a new build
+./build/install-build-deps.sh
+./build/install-build-deps.sh --arm
+# Fetch & pull the other bits of the tree to sync.
+# As we are checking out a tag the --with_branch_heads is important
+gclient sync -D --with_branch_heads
+
+# Start rebuild
+git stash pop
+
+# Fix pipaths & make new branches (now so we don't forget later)
+sed "s/src_commit=.*/src_commit=\"$TAG\"/" pi-util/pipaths.py | tee t
+mv t pi-util/pipaths.py && git add pi-util/pipaths.py
+chmod 0755 pi-util/*.py pi-util/*.sh
+pi-util/gitscan.py --gitscan-no-src checkout -b test/${NEWVER}/rpi_2
+
+# If running with filemode false then readd pi-util with filemode true
+git config core.filemode true
+git add pi-util
+git config core.filemode false
+
+
+### Fix conflicts (there will be some)
+
+# If building a separated ffmpeg .so (we are not not currrently) then
+# fix chrome major version for ffmpeg .so in pi-util/cplibs.sh and third_party/ffmpeg/BUILD.gn
+
+git commit
+### run through all other dirs we care about doing the same
+### Probably need to fix exec perms on pi-util scripts
+pi-util/rootgen.sh
+pi-util/gngen.py
+### Fix up any new libpackage-dev that we need
+ninja ...
+### Fix up build disasters
+
+
+If updating within a major version mergeing seems to work reliably so my
+preferred method for achieving this goes:
+
+# Make sure everything is committed
+pi-util/gitscan.py status
+# Revert to base chromium checkout for old checkout
+pi-util/gitscan.py --gitscan-no-src checkout {BASE}
+# Merge new version into current base
+git fetch --all
+TAG=<new_tag>
+NEWVER=`echo $TAG | sed -nE 's/^([0-9]+).*$/\1/p'`
+
+git merge $TAG
+# Fix conflicts - DEPS always seems to conflict
+git checkout $TAG -- DEPS
+# Update pi-util/pipaths.py to contain the new tag
+# Either commit now or later
+sed "s/src_commit=.*/src_commit=\"$TAG\"/" pi-util/pipaths.py | tee t
+mv t pi-util/pipaths.py && git add pi-util/pipaths.py
+git commit --no-edit
+# Get the rest of the tree
+gclient sync --with_branch_heads
+# Checkout our tree and merge the new base into it
+pi-util/gitscan.py --gitscan-no-src checkout test/$NEWVER/rpi_2
+pi-util/gitscan.py --gitscan-no-src merge --no-edit {BASE}
+
+and we should be good to go.  At this point you can either clean build or
+not.  Chromes dependancy checks seem remarkably good so a simple build
+works nearly all the time.
+
+# Rebuild from clean
+rm -rf out
+# refetch root (optional)
+pi-util/rootgen.sh
+# Configure
+pi-util/gngen.py
+# Build release armv7 chrome (and any other targets you feel like)
+ninja -C out/armv7-rel chrome
+
+
+Sysroots (one time only)
+------------------------
+
+1st you will need to get the dev files for a bunch of libs on your pi (or
+if you can get the right files by magic on your cross-compile m/c then
+that is good too).  In src/pi-util there is a shell script
+pi-install-dev.sh which lists all the libs I think are needed along with a
+helpful apt-get install so all you should need to do is run it on an
+appropriate pi.
+
+Next the appropriate bits need to be copied to
+build/linux/<sysroot-name>-sysroot. We use raspian_stretch_pi1 as the
+sysroot name in these instructions and in the example script files so you
+might well find it easiest to use the same name too
+
+The script pi-util/syncroot.sh that will copy the needed bits of a root to
+the right place and then fix the full path symlinks to be relative.  It
+uses rsync to copy the files so the src can contain a machine name
+
+pi-util/syncroot.sh my-pi: raspian_stretch_pi1
+
+The "raspian_stretch_pi1" can be omitted and syncroot will choose the current
+default sysroot name.
+
+Beware that there are ~8 rsync statements so if the rsync is operating
+over ssh then you may need to type your password 8 times...  Note also
+that the script appends -sysroot to the given name so don't add that
+yourself!
+
+If the pi root is updated then this script can / should be rerun to update
+the sysroot.
+
+
+
+Other notes on the tree
+-----------------------
+
+The definitive list of expected repos is in pi-util/pipaths.py
+
+The script pi-util/gitscan.py will perform the same git op on all the
+repos that are in use in the current patch set.  It has substitutions
+of {PATH} and {BASE} for the path to the current repo and the chromium
+commit on which the current branch is based
+
+The current dev branch is test/57/mmal_2
+
+Status of optional neon by build file:
+skia/BUILD.gn:                     yes
+build/secondary/third_party/libjpeg_turbo/BUILD.gn: yes
+third_party/libwebp/BUILD.gn:      yes
+third_party/openmax_dl/dl/BUILD.gn unused
+third_party/libyuv/BUILD.gn:       yes
+third_party/libyuv/libyuv.gni:     yes
+third_party/pdfium/skia/BUILD.gn:  unused
--- /dev/null
+++ b/src/pi-util/README.txt
@@ -0,0 +1,118 @@
+Release notes
+=============
+
+This version should run with gpu-mem=64 with the default switches. Having
+said that this will only allow for 1 stream.  If you are playing >1 stream
+(even transiently) then you will need more (say gpu_mem=128) and you will
+need to set the --mmal-decoders option to the desired max number. The code
+should give up cleanly if it cannot allocate a h/w video decoder and give
+the stream to old-style ffmpeg decode, but as it stands in many cases it
+thinks it has allocated a decoder cleanly only to find that it fails when
+it tries to use it.
+
+Needs a current (buster 2019-06-07+) firmware/userland
+
+There are a few command-line switches - in general you shouldn't use
+them!
+
+
+Decode and resizer options
+--------------------------
+
+--mmal-decode-opaque     Set the decoder to use opaque frames between
+decoder and resizer.  This should be faster than i420 but doesn't work
+with old firmware.  This is the default with newer firmware (>=
+2016-11-01). (see --mmal-decode-i420)
+
+--mmal-decode-i420       Set the decoder to use I420 frames between
+decoder and resizer.  This generates an unnecessary conversion but works
+with all firmware.  This is the default with older firmware (<
+2016-11-01). (see --mmal-decode-opaque)
+
+--mmal-low-delay         Force "low-delay" mode on the decoder pipe.  This
+reduces the number of buffered ES frames before the decoder.  It isn't
+exactly low-delay but is definitely lower than otherwise.  May have a
+slight performance penalty and increase the risk of stuttering.  This mode
+will be automatically set by Chrome for some streams.
+
+--mmal-resize-isp        Use ISP resize rather than resizer.  Is noticably
+faster but requires --mmal-frame-copy or --mmal-zero-copy and newer
+firmware.  This is the default with newer firmware  (>= 2016-11-01) and
+enough gpu memory to support --mmal-frame-copy.
+
+--mmal-resize-resizer    Use resizer rather than ISP. Slower than ISP
+resize but supports older firmware and --mmal-slice-copy which may be
+needed if GPU memory is very limited (as will be the case on a Pi1 with a
+default setup).
+
+--mmal-resize-mode=NEVER|ALWAYS|SMALLER
+Sets resize behaviour.
+  NEVER    Output is the native size of the video
+  ALWAYS   Output allways attempts to match the size of the displayed picture
+           This is normally the fastest mode for SHM-RGB copy
+  SMALLER  Resize to smaller of native & display. This saves memory and is
+           the fastest for EGL output
+
+
+Copy-modes
+----------
+
+--mmal-copy-mode=<copy mode>
+
+This sets the output frame type & mmal->chrome copy mode. Current values
+for <copy mode> are:
+
+slice                   slowest - uses only a small amount of memory
+                        in the resizer
+
+<alloc>-<format>-<copy>
+  <alloc>
+    SHM      Frame allocated from shared memory
+    GPU      Frame allocated from gpu memory
+  <format>
+    YUV      3-plane I420
+    YC       2-plane I420 e.g. NV12
+    RGB      1-plane 4-byte RGBX
+  <copy>
+    COPY     Data copied on the ARM.  This should be slower than DMA but
+             sometimes give more performance at the expense of slightly
+	     higher ARM CPU usage
+    DMA      Data copied by firmware DMA to ARM buffers.
+    ZC       Data put directly into GPU buffer.  Fastest - only works
+             with EGL (needs vcsm-cma).
+
+Currently valid combinations are:
+
+SHM-YUV-DMA
+SHM-YC-DMA
+SHM-RGB-DMA
+SHM-RGB-COPY  Default for non-gpu operation
+GPU-RGB-DMA
+GPU-RGB-ZC
+GPU-YUV-COPY
+GPU-YUV-ZC    Default for EGL operation
+
+
+Misc options
+------------
+
+--enable-logging=stderr This is a standard option for chrome but worth
+noting as the mmal code will print out its interpretation of the command
+line options passed to it along with how much GPU memory it has detected
+and the firmware date.
+
+--pi-patch-version       Print out the versions of Chromium and Pi
+patches.  Chrome will then terminate
+
+--mmal-decoders=<n>      Set the number of mmal decoders we wil try to
+create simultainiously. Default=1. If this number is exceeded then decoder
+init will fail and chrome will fallback to ffmpeg decode.  There is no
+panalty for setting this to a large number if you wish to have "unlimited"
+decoders.  However if it is set too big and there isn't the gpu mem to
+satisfy the requirements of the decode it may fail cleanly and revert to
+software (ffmpeg) decode or init may appear to succeed and decode then
+fails in an undefined manner.
+
+--mmal-frame-buffers=<n> Set the number of gpu "frame" buffers.
+Change with care.
+
--- /dev/null
+++ b/src/pi-util/cpbuild.sh
@@ -0,0 +1,31 @@
+set -e
+if [ "$2" == "" ]; then
+  echo "mkzip <zipname> <out/dir>"
+  exit 1
+fi
+
+BASEDIR=`pwd`
+TMPBASE=$BASEDIR/out/tmp
+TMPDIRNAME=$1
+ZIPFILE=$1.zip
+OUTDIR=$BASEDIR/$2
+
+cd $OUTDIR
+D=$TMPBASE/$TMPDIRNAME
+rm -rf $D
+mkdir -p $D
+
+echo "=== Copying"
+cp -r * $D
+cd $D
+
+echo "=== Clean unwanted"
+find . -name obj -exec rm -rf {} +
+rm -rf gen clang_*
+rm -rf *.TOC *_deps *.zip core-* bin test_* toolchain.ninja third_party tools local_rustc_sysroot thinlto-cache
+cd $TMPBASE
+
+echo "=== Zipping"
+zip -r -q $ZIPFILE $TMPDIRNAME
+
+echo "=== Done: $TMPBASE/$ZIPFILE"
--- /dev/null
+++ b/src/pi-util/cplibs.sh
@@ -0,0 +1,19 @@
+set -e
+
+FFNAME=libffmpeg_chrome.so.66
+LIBROOT=/usr/lib/arm-linux-gnueabihf
+
+if [ ! -d $LIBROOT ]; then
+  echo Can\'t find $LIBROOT
+  echo Are you sure you are running this on a Pi?
+  exit 1
+fi
+
+echo Copying $FFNAME from armv6/7 to $LIBROOT/...
+
+cp out/armv7/$FFNAME /tmp
+sudo cp /tmp/$FFNAME $LIBROOT/neon/vfp
+cp out/armv6/$FFNAME /tmp
+sudo cp /tmp/$FFNAME $LIBROOT
+
+
--- /dev/null
+++ b/src/pi-util/defargs_arm64-bullseye.gn
@@ -0,0 +1,33 @@
+# Build arguments go here. Examples:
+#   is_component_build = true
+#   is_debug = false
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm64"
+target_os = "linux"
+
+# Enables screen sharing in hangouts
+enable_hangout_services_extension = true
+
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
+
+enable_widevine = true
+
+# Dawn seems to really want Vulkan - Chrome doesn't like our Vulkan
+# this causes a hiccup about a min after startup.
+# Disabling Dawn seems to create no penalty but this probably won't
+# be true indefinitely
+use_dawn = false
+skia_use_dawn = false
+
+# We don't have the required GL extensions to enable GL passthrough so must
+# enable the validating decode otherwise we get a fatal GPU error
+enable_validating_command_decoder = true
+
+disable_fieldtrial_testing_config = true
+enable_nacl = false
+blink_symbol_level = 0
+symbol_level = 1
+is_official_build = true
+is_component_ffmpeg = true
+
--- /dev/null
+++ b/src/pi-util/defargs_armv7-bullseye.gn
@@ -0,0 +1,41 @@
+# Build arguments go here. Examples:
+#   is_component_build = true
+#   is_debug = false
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm"
+target_os = "linux"
+
+arm_float_abi = "hard"
+arm_use_neon = true
+# We have lib issues if we enable thumb
+arm_use_thumb = false
+arm_optionally_use_neon = false
+arm_version = 7
+arm_arch = "armv7-a"
+
+enable_widevine = true
+
+# Dawn seems to really want Vulkan - Chrome doesn't like our Vulkan
+# this causes a hiccup about a min after startup.
+# Disabling Dawn seems to create no penalty but this probably won't
+# be true indefinitely
+use_dawn = false
+skia_use_dawn = false
+
+# Enables screen sharing in hangouts
+enable_hangout_services_extension = true
+
+# We don't have the required GL extensions to enable GL passthrough so must
+# enable the validating decode otherwise we get a fatal GPU error
+enable_validating_command_decoder = true
+
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
+
+disable_fieldtrial_testing_config = true
+enable_nacl = false
+blink_symbol_level = 0
+symbol_level = 1
+is_official_build = true
+is_component_ffmpeg = true
+
--- /dev/null
+++ b/src/pi-util/dodiff.py
@@ -0,0 +1,35 @@
+#!/usr/bin/env python3
+
+import os, sys, string, subprocess
+
+# Local
+import gitscan, pipaths
+
+def doscan(outfile = sys.stdout):
+    revdict = gitscan.revdict()
+
+    cpath = gitscan.basepath()
+
+    for p in pipaths.pipaths:
+        os.chdir(os.path.join(cpath, p))
+        diff = subprocess.check_output(["git", "diff", "--ignore-submodules", revdict[p]], text=True)
+
+        header = False
+        lines = diff.split("\n")
+        # Remove terminal blank line
+        if lines[-1] == "":
+            lines.pop()
+        for line in lines:
+            if line.startswith("diff --git "):
+                header = True
+            if header:
+                line = line.replace(" a/", " a/" + p + "/")
+                line = line.replace(" b/", " b/" + p + "/")
+            if line.startswith("+++ "):
+                header = False
+            print(line, file=outfile)
+
+
+if __name__ == '__main__':
+    doscan()
+
--- /dev/null
+++ b/src/pi-util/gitscan.py
@@ -0,0 +1,69 @@
+#!/usr/bin/env python3
+
+import os, string, subprocess, sys
+
+# Local
+import pipaths
+
+def revdict():
+    revdict = {'src':pipaths.src_commit}
+    stuff = subprocess.check_output(["gclient", "revinfo"], text=True)
+    for line in stuff.split("\n"):
+        pathn = line.find(":")
+        commitn = line.rfind("@")
+        if pathn != -1 and commitn != -1 :
+             revdict[line[:pathn]] = line[commitn+1:]
+    return revdict
+
+def basepath():
+    cpath = os.getcwd()
+    if not cpath.endswith("/src"):
+        raise "CWD doesn't end with /src"
+
+    return cpath[:-4]
+
+def gitscan(args, nosrc = False, quiet=False):
+    rv = 0
+
+    oldcwd = os.getcwd()
+    rdict = revdict()
+    cpath = basepath()
+
+    for p in pipaths.pipaths:
+        if nosrc and p == "src":
+            continue
+
+        os.chdir(os.path.join(cpath, p))
+
+        gitargs = [a.replace("{PATH}", p).replace("{BASE}", rdict[p]) for a in args]
+        gitargs[0:0] = ["git"]
+
+        if not quiet:
+            print(">>>", p)
+
+        rv = subprocess.call(gitargs)
+        if rv != 0:
+            if not quiet:
+                print("Git returned non-zero error code", rv, "\ncwd =", os.getcwd(), "\ncmd =", gitargs)
+            break
+
+    os.chdir(oldcwd)
+    return rv
+
+
+if __name__ == '__main__':
+
+    if len(sys.argv) < 2:
+        print("Usage: gitscan [--gitscan-no-src] <git cmd>")
+        print("  substitutes {PATH} and {BASE}")
+        exit(0)
+
+    nosrc = False
+
+    if sys.argv[1] == "--gitscan-no-src":
+        nosrc = True
+        del sys.argv[1]
+
+    gitscan(sys.argv[1:], nosrc)
+
+
--- /dev/null
+++ b/src/pi-util/gngen.py
@@ -0,0 +1,71 @@
+#!/usr/bin/env python3
+
+import os, ast, fileinput, subprocess, sys
+
+def docopy(name, vars, is_debug=False, is_ozone=False):
+    dir_suffix = ""
+    deb_str = "false"
+
+    if is_ozone:
+        ozone_str = "true"
+        dir_suffix = dir_suffix + "-ozone"
+    else:
+        ozone_str = "false"
+
+    if is_debug:
+        deb_str = "true"
+        dir_suffix = dir_suffix + "-deb"
+    else:
+        deb_str = "false"
+        dir_suffix = dir_suffix + "-rel"
+
+
+    dest_dir = os.path.join("out", name + dir_suffix)
+    src_file = os.path.join("pi-util", "defargs_" + name + ".gn")
+
+    # Ignore any errors making dir (in particular it already exists)
+    try:
+        os.makedirs(dest_dir)
+    except:
+        pass
+
+    dargs = open(os.path.join(dest_dir, "args.gn"), "wt")
+    dargs.write('# -- copied from: ' + src_file + '\n')
+
+    for line in fileinput.input(src_file):
+        dargs.write(line)
+
+    dargs.write('# -- created by ' + sys.argv[0] + '\n')
+    dargs.write('is_debug = ' + deb_str + '\n')
+    dargs.write('use_ozone = ' + ozone_str + '\n')
+    if is_ozone:
+        dargs.write('ozone_platform_x11 = true\n')
+        dargs.write('use_v4l2_codec = true\n')
+        dargs.write('use_v4l2_codec_rpi = true\n')
+
+    dargs.write('target_sysroot = "' + vars["target_sysroot"] + '"\n')
+    dargs.write('google_api_key = "' + vars["google_api_key"] + '"\n')
+    dargs.write('google_default_client_id = "' + vars["google_default_client_id"] + '"\n')
+    dargs.write('google_default_client_secret = "' + vars["google_default_client_secret"] + '"\n')
+
+    dargs.close()
+
+    subprocess.check_call(["gn", "gen", dest_dir])
+
+
+if __name__ == '__main__':
+    gyp_vars = {}
+    gypi = os.path.join(os.environ["HOME"], ".gyp", "include.gypi")
+    if os.path.isfile(gypi):
+        print("Importing from:", gypi)
+        gyps = open(gypi).read(-1)
+        gyp_vars = ast.literal_eval(gyps)["variables"]
+
+    gyp_vars["target_sysroot"] = os.path.abspath("build/linux/pios_bullseye_armhf-sysroot")
+
+    docopy("armv7-bullseye", gyp_vars, is_ozone=True)
+
+    gyp_vars["target_sysroot"] = os.path.abspath("build/linux/pios_bullseye_arm64-sysroot")
+
+    docopy("arm64-bullseye", gyp_vars, is_ozone=True)
+
--- /dev/null
+++ b/src/pi-util/makeall.sh
@@ -0,0 +1,49 @@
+set -e
+
+DISTRO=bullseye
+
+GET_BUILD_DEPS=
+if [ "$1" == "--build-deps" ]; then
+  GET_BUILD_DEPS=1
+  shift
+fi
+
+if [ "$1" == "" ]; then
+  echo "Usage: $0 [--build-deps] <git tag>"
+  exit 1
+fi
+
+echo === Check all committed
+pi-util/gitscan.py diff --name-status --exit-code
+echo === Reset third party libraries
+pi-util/gitscan.py --gitscan-no-src checkout {BASE}
+TAG=$1
+echo === Fetch chrome
+pi-util/gitscan.py fetch -t --all
+echo === Checkout chrome $TAG
+git checkout $TAG
+if [ ! $GET_BUILD_DEPS ]; then
+  echo === Skip system build dependancies
+else
+  echo === Get system build dependancies
+  build/install-build-deps.sh --arm
+fi
+echo === Sync third party libraries
+gclient sync -D --with_branch_heads
+# Shouldn't need this but the x bit often gets accidentally lost
+# due to core.filemode options
+chmod +x pi-util/*.sh pi-util/*.py
+echo === Checkout third party libraries
+pi-util/gitscan.py --gitscan-no-src checkout $TAG --
+echo === Get pi sysroots
+rm -rf out
+pi-util/rootgen.sh
+echo === Setup gn
+pi-util/gngen.py
+echo === Start build
+ninja -C out/armv7-${DISTRO}-ozone-rel chrome
+ninja -C out/arm64-${DISTRO}-ozone-rel chrome
+ninja -C out/armv6-${DISTRO}-ozone-rel chrome
+
+
+
--- /dev/null
+++ b/src/pi-util/patch2nd.awk
@@ -0,0 +1,3 @@
+/^\-\-\-/  { next }
+/^\+\+\+/ { $1="---"; print; $1="+++"; }
+{ print }
--- /dev/null
+++ b/src/pi-util/patchmake.sh
@@ -0,0 +1,50 @@
+set -e
+
+GET_BUILD_DEPS=
+if [ "$1" == "--build-deps" ]; then
+  GET_BUILD_DEPS=1
+  shift
+fi
+
+if [ "$1" == "" ]; then
+  echo "Usage: $0 [--build-deps] <patch file>"
+  exit 1
+fi
+if [ ! -e "$1" ]; then
+  echo "Didn't find patchfile $1"
+  exit 1
+fi
+
+PATCHFILE=$1
+TAG=${PATCHFILE##*/}
+TAG=${TAG:1}
+TAG=${TAG%%_*}
+
+echo "Version $TAG extracted from patchfile name"
+
+echo === Checkout chrome $TAG
+git checkout $TAG
+if [ ! $GET_BUILD_DEPS ]; then
+  echo === Skip system build dependancies
+else
+  echo === Get system build dependancies
+  build/install-build-deps.sh --unsupported --arm
+fi
+echo === Sync third party libraries
+gclient sync -D --with_branch_heads
+echo === Patch
+patch -p2 < $PATCHFILE
+# Shouldn't need this but the x bit often gets accidentally lost
+# due to core.filemode options
+chmod +x pi-util/*.sh pi-util/*.py
+echo === Get pi sysroots
+rm -rf out
+pi-util/rootgen.sh
+echo === Setup gn
+pi-util/gngen.py
+echo === Start build
+ninja -C out/armv7-bullseye-ozone-rel chrome
+ninja -C out/arm64-bullseye-ozone-rel chrome
+
+
+
--- /dev/null
+++ b/src/pi-util/pi-install-dev.sh
@@ -0,0 +1,53 @@
+# Install set to build appropriate root on a clean pi
+
+APT=aptitude
+#APT=apt-get
+
+sudo $APT install \
+comerr-dev \
+libasound2-dev \
+libatk1.0-dev \
+libatk-bridge2.0-dev \
+libcap-dev \
+libcups2-dev \
+libexif-dev \
+libffi-dev \
+libgbm-dev \
+libgconf2-dev \
+libgl1-mesa-dev \
+libgles-dev \
+libgtk-3-dev \
+libjpeg-dev \
+libkrb5-dev \
+libnspr4-dev \
+libnss3-dev \
+libpam0g-dev \
+libpango1.0-dev \
+libpci-dev \
+libpcre3-dev \
+libpipewire-0.2-dev \
+libssl-dev \
+libudev-dev \
+libx11-xcb-dev \
+libxcb1-dev \
+libxcb-dri3-dev \
+libxcb-shm0-dev \
+libxcb-image0-dev \
+libxss-dev \
+libxt-dev \
+libxtst-dev \
+mesa-common-dev \
+python-xcbgen \
+uuid-dev \
+xcb-proto
+
+echo Also need python-xcbgen on host
+
+# Pulse (hopefully) disabled
+# libpulse-dev \
+
+# Obviously replace paths appropriately below
+# Now run pi-util/syncroot.sh on the compile m/c to grab the appropriate
+# bits of the root and fix up the paths.
+# e.g. ON COMPILE M/C in src dir:
+# pi-util/syncroot.sh my-pi: raspian_jessie_pi1
--- /dev/null
+++ b/src/pi-util/pipaths.py
@@ -0,0 +1,7 @@
+pipaths=[
+    "src",
+    "src/third_party/libyuv",
+    "src/third_party/skia"]
+
+# Our base tag or commit no
+src_commit="124.0.6367.73"
--- /dev/null
+++ b/src/pi-util/pipewire_utils_h.patch
@@ -0,0 +1,11 @@
+--- a/build/linux/raspian_stretch_pi1-sysroot/usr/include/pipewire/utils.h
++++ b/build/linux/raspian_stretch_pi1-sysroot/usr/include/pipewire/utils.h
+@@ -52,7 +52,7 @@ static inline struct spa_pod *
+ pw_spa_pod_copy(const struct spa_pod *pod)
+ {
+ 	size_t size;
+-	struct spa_pod *c;
++	void *c;
+ 
+ 	if (pod == NULL)
+ 		return NULL;
--- /dev/null
+++ b/src/pi-util/rebase_liblinks.py
@@ -0,0 +1,37 @@
+#!/usr/bin/env python
+
+import os, sys
+from stat import *
+
+def walktree(top, callback, n, prefix):
+    '''recursively descend the directory tree rooted at top,
+       calling the callback function for each regular file'''
+
+    for f in os.listdir(top):
+        pathname = os.path.join(top, f)
+        mode = os.lstat(pathname).st_mode
+        if S_ISDIR(mode):
+            # It's a directory, recurse into it
+            walktree(pathname, callback, n+1, prefix)
+        elif S_ISLNK(mode):
+            # It's a file, call the callback function
+            callback(pathname, os.readlink(pathname), n, prefix)
+
+def visitfile(file, linkname, n, prefix):
+    if (linkname.startswith(prefix + 'lib/')):
+        newlink = "../" * n + linkname[len(prefix):]
+        print 'relinking', file, "->", newlink
+        os.remove(file)
+        os.symlink(newlink, file)
+
+if __name__ == '__main__':
+    argc = len(sys.argv)
+    if argc == 2:
+        walktree(sys.argv[1], visitfile, 0, "/")
+    elif argc == 3:
+        walktree(sys.argv[1], visitfile, 0, sys.argv[2])
+    else:
+        print "rebase_liblinks.py <local root> [<old sysroot>]"
+
+
+
--- /dev/null
+++ b/src/pi-util/rootgen.sh
@@ -0,0 +1,73 @@
+#!/bin/bash -e
+
+SRC_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && cd .. && pwd )"
+SCRIPT_DIR=$SRC_DIR/build/linux/sysroot_scripts
+BUILD_DIR=$SRC_DIR/out/sysroot-build/bullseye
+
+NOGEN=
+CLEAN=
+WANTXX=
+WANT32=
+WANT64=
+while [ "$1" != "" ] ; do
+  case $1 in
+    --nogen)
+      NOGEN=1
+      ;;
+    --clean)
+      CLEAN=1
+      ;;
+    --32)
+      WANT32=1
+      WANTXX=1
+      ;;
+    --64)
+      WANT64=1
+      WANTXX=1
+      ;;
+    *)
+      echo "Usage: $0 [--nogen][--clean][--32][--64]"
+      echo "  --nogen    Do not do sysroot generation"
+      echo "  --clean    Wipe existing sysroot caches"
+      echo "  --32       Only build 32-bit sysroot"
+      echo "  --64       Only build 64-bit sysroot"
+      exit 1
+      ;;
+  esac
+  shift
+done
+
+if [ ! $WANTXX ]; then
+  WANT32=1
+  WANT64=1
+fi
+
+if [ $CLEAN ]; then
+  rm -rf $SRC_DIR/build/linux/pios_*-sysroot
+  rm -f $SCRIPT_DIR/pios_keyring.gpg
+  rm -f $SCRIPT_DIR/generated_package_lists/pios-*
+  rm -rf $SRC_DIR/out/sysroot-build
+fi
+
+if [ ! $NOGEN ]; then
+  mkdir -p $BUILD_DIR
+  cd $SCRIPT_DIR
+  if [ ! -e pios_keyring.gpg ]; then
+    ./generate_keyring.sh --pios
+  fi
+  if [ $WANT32 ]; then
+    cd $SCRIPT_DIR
+    ./sysroot_creator.py --pios build armhf |& tee $BUILD_DIR/build-armhf.log
+    mkdir -pv ../pios_bullseye_armhf-sysroot
+    cd ../pios_bullseye_armhf-sysroot
+    bsdtar xf $BUILD_DIR/debian_pios-bullseye_armhf_sysroot.tar.xz
+  fi
+  if [ $WANT64 ]; then
+    cd $SCRIPT_DIR
+    ./sysroot_creator.py --pios build arm64 |& tee $BUILD_DIR/build-arm64.log
+    mkdir -pv ../pios_bullseye_arm64-sysroot
+    cd ../pios_bullseye_arm64-sysroot
+    bsdtar xf $BUILD_DIR/debian_pios-bullseye_arm64_sysroot.tar.xz
+  fi
+fi
+
--- /dev/null
+++ b/src/pi-util/settag.py
@@ -0,0 +1,63 @@
+#!/usr/bin/env python3
+
+import sys, os, subprocess
+
+# Local
+import pipaths
+import gitscan
+import dodiff
+import argparse
+
+def set_version(verstr):
+    pathname = "components/version_info/pi_patch_version_values.h"
+
+    with open(pathname, "wt") as f:
+        f.write("// Pi patch version - generated by pi-util/settag.py\n")
+        f.write('#define PI_PATCH_VERSION_STRING "' + verstr + '"\n')
+
+    subprocess.check_call(["git", "add", pathname])
+    subprocess.check_call(["git", "commit", "-m", "Update pi patch version to " + verstr])
+
+
+def set_tag(verstr):
+    newtag = "pi/" + pipaths.src_commit + "/" + verstr
+    print("Setting tag: " + newtag)
+    if gitscan.gitscan(["tag", newtag], quiet=True) != 0:
+        print("Tagging failed")
+        sys.exit(1)
+
+def set_tag_and_version(verstr):
+    set_version(verstr)
+    set_tag(verstr)
+
+if __name__ == '__main__':
+    argp = argparse.ArgumentParser(
+        description="Sets version info in pi_patch_version_values & tags source tree with it")
+    argp.add_argument("-p", action='store_true', help="Generate patch file")
+    argp.add_argument("-f", action='store_true', help="Overwrite existing patch file (only relevent if -p)")
+    argp.add_argument("-n", action='store_true', help="Do not tag")
+    argp.add_argument("verstr", help="Pi patch version string")
+    args = argp.parse_args()
+
+    patchpath = os.path.join("..", "v" + pipaths.src_commit + "_" + args.verstr + ".patch")
+
+    if args.p and not args.f and os.path.exists(patchpath):
+        print("Patchfile", patchpath, "already exists")
+        sys.exit(1)
+
+    if not args.n:
+        print("-- Checking all committed")
+        if gitscan.gitscan(["diff", "--ignore-submodules", "--name-status", "--exit-code"], quiet=True) != 0:
+            print("Status check failed - commit everything and try again")
+            sys.exit(1)
+
+        print("-- Generating & committing pi_patch_version_values.h")
+        set_version(args.verstr)
+        print("-- Generating tags")
+        set_tag(args.verstr)
+
+    if args.p:
+        print("-- Generating patch file: ", patchpath)
+        with open(patchpath, "wt") as f:
+            dodiff.doscan(f)
+
--- /dev/null
+++ b/src/pi-util/syncroot.sh
@@ -0,0 +1,70 @@
+set -e
+
+NEEDSVC=1
+TYPE=arm
+API=arm-linux-gnueabihf
+SYSROOT_DEFAULT=pios_buster_arm
+
+if [ "$1" == "--arm64" ]; then
+  shift
+  TYPE=arm64
+  NEEDSVC=
+  API=aarch64-linux-gnu
+  SYSROOT_DEFAULT=pios_buster_arm64
+fi
+
+if [ "$1" == "" ]; then
+  echo Usage: $0 [--arm64] \<src_dir\> [\<rootname\>]
+  echo src_dir is a source for rsync so may contain m/c name.
+  echo rootname will be set to \"pios_buster_arm\" if missing
+  echo e.g.: pi-util/syncroot.sh my-pi:
+  exit 1
+fi
+
+SYSROOT_NAME=$2
+if [ "$SYSROOT_NAME" == "" ]; then
+  SYSROOT_NAME=$SYSROOT_DEFAULT
+fi
+
+DST_ROOT=`gclient root`
+DST=$DST_ROOT/src/build/linux/$SYSROOT_NAME-sysroot
+SRC=$1
+
+if [ ! -d $DST_ROOT/src/build/linux ]; then
+  echo We don\'t appear to be in a Chrome build tree
+  exit 1
+fi
+
+echo Copying root for $TYPE
+echo Sync src:  $SRC
+echo Sync dest: $DST
+
+mkdir -p $DST/lib
+mkdir -p $DST/opt/vc/include
+mkdir -p $DST/usr/lib/pkgconfig
+mkdir -p $DST/usr/bin
+mkdir -p $DST/usr/share
+
+rsync -rl $SRC/lib $DST
+if [ $NEEDSVC ]; then
+  #### MUST NOT include /opt/vc/include/*GL*
+  # Creates conflicts with GL includes inside Chrome
+  rsync -rl $SRC/opt/vc/lib $DST/opt/vc
+  rsync -rl $SRC/opt/vc/include/interface $DST/opt/vc/include
+fi
+rsync -rl --exclude cups/backend $SRC/usr/lib $DST/usr
+rsync -rl $SRC/usr/include $DST/usr
+rsync -rl $SRC/usr/share/pkgconfig $DST/usr/share
+rsync -rl $SRC/usr/share/xcb $DST/usr/share
+rsync -rl $SRC/usr/bin/cups-config $DST/usr/bin
+
+# Fix up pipewire issue
+if [ -e $DST/usr/include/pipewire/utils.h ]; then
+  sed 's/struct spa_pod \*c/void \* c/' < $DST/usr/include/pipewire/utils.h > u.h
+  mv u.h $DST/usr/include/pipewire/utils.h
+fi
+
+cd $DST/usr/lib/pkgconfig
+ln -sf ../$API/pkgconfig/* .
+cd ../../../../../..
+pi-util/rebase_liblinks.py $DST
--- a/src/sandbox/policy/linux/bpf_gpu_policy_linux.cc
+++ b/src/sandbox/policy/linux/bpf_gpu_policy_linux.cc
@@ -85,6 +85,27 @@ ResultExpr GpuProcessPolicy::EvaluateSys
     case __NR_mmap:
       return Allow();
 #endif
+#if defined(USE_X11) || 1
+    // Wanted for MESA to fire up happily
+    // *** Should almost certainly arrange for the offending setup
+    //     to happen before sandbox is applied but I can't work out
+    //     what is needed
+    // Alternatively --in-process-gpu fixes the issue
+#ifdef __NR_readlink
+    case __NR_readlink:  // 85
+#else
+    case __NR_readlinkat:
+#endif
+#ifdef __NR_stat64
+    case __NR_stat64:    // 195
+#endif
+    case __NR_openat:    // 322 --- This one is clearly bad!
+    // V4L2 requires open/close - not sure how this works in chromeos without the holes
+#ifdef __NR_open
+    case __NR_open:
+#endif
+    case __NR_close:
+#endif
     // We also hit this on the linux_chromeos bot but don't yet know what
     // weird flags were involved.
     case __NR_mprotect:
--- a/src/third_party/ipcz/src/ipcz/node_messages_generator.h
+++ b/src/third_party/ipcz/src/ipcz/node_messages_generator.h
@@ -7,6 +7,9 @@
 // This file defines the internal messages which can be sent on a NodeLink
 // between two ipcz nodes.
 
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wunaligned-access"
+
 IPCZ_MSG_BEGIN_INTERFACE(Node)
 
 // Initial greeting sent by a broker node when a ConnectNode() is issued without
@@ -627,3 +630,7 @@ IPCZ_MSG_BEGIN(AcceptRelayedMessage, IPC
 IPCZ_MSG_END()
 
 IPCZ_MSG_END_INTERFACE()
+
+#pragma GCC diagnostic pop
+
+
--- a/src/third_party/libdrm/BUILD.gn
+++ b/src/third_party/libdrm/BUILD.gn
@@ -72,6 +72,7 @@ static_library("libdrm") {
     # glibc-2.24.  This causes a build error when using the Debian
     # Stretch sysroot.
     "-Wno-deprecated-declarations",
+    "-DMAJOR_IN_SYSMACROS=1",
   ]
 
   public_configs = [ ":libdrm_config" ]
--- a/src/third_party/widevine/cdm/widevine.gni
+++ b/src/third_party/widevine/cdm/widevine.gni
@@ -27,7 +27,7 @@ if (is_chromeos && !is_chromeos_device)
 library_widevine_cdm_available =
     (is_chromeos &&
      (target_cpu == "x64" || target_cpu == "arm" || target_cpu == "arm64")) ||
-    (target_os == "linux" && target_cpu == "x64") ||
+    (target_os == "linux" && (target_cpu == "x64" || target_cpu == "arm")) ||
     (target_os == "mac" && (target_cpu == "x64" || target_cpu == "arm64")) ||
     (target_os == "win" &&
      (target_cpu == "x86" || target_cpu == "x64" || target_cpu == "arm64"))
--- a/src/ui/gl/init/gl_factory.cc
+++ b/src/ui/gl/init/gl_factory.cc
@@ -103,6 +103,15 @@ GLImplementationParts GetRequestedGLImpl
   std::optional<GLImplementationParts> impl_from_cmdline =
       GetRequestedGLImplementationFromCommandLine(cmd, fallback_to_software_gl);
 
+  // RPI: We always want EGL as our preferred render
+  // Easiest to simply add here - angle + GLES +/- EGL crashes
+  // so add here after the angle add.
+  //
+  // BEWARE: falling back from EGL to anything else with --in-process-gpu
+  // set produces a segfault when we exit so ideally we would only do this
+  // on Pi4/(F)KMS?
+  allowed_impls.insert(allowed_impls.begin(), GLImplementationParts(kGLImplementationEGLGLES2));
+
   // The default implementation is always the first one in list.
   if (!impl_from_cmdline)
     return allowed_impls[0];
--- a/src/ui/ozone/platform/wayland/host/wayland_connection.h
+++ b/src/ui/ozone/platform/wayland/host/wayland_connection.h
@@ -360,8 +360,9 @@ class WaylandConnection {
   void DumpState(std::ostream& out) const;
 
   bool UseImplicitSyncInterop() const {
-    return !linux_explicit_synchronization_v1() &&
-           WaylandBufferManagerHost::SupportsImplicitSyncInterop();
+    return false; // *** Broken, at least on Pi
+//    return !linux_explicit_synchronization_v1() &&
+//           WaylandBufferManagerHost::SupportsImplicitSyncInterop();
   }
 
  private:
--- a/src/third_party/libyuv/BUILD.gn
+++ b/src/third_party/libyuv/BUILD.gn
@@ -188,7 +188,6 @@ static_library("libyuv_internal") {
     configs += [ "//build/config/compiler:optimize_max" ]
   }
 
-  # To enable AVX2 or other cpu optimization, pass flag here
   if (!is_win) {
     cflags = [
       # "-mpopcnt",
@@ -197,6 +196,11 @@ static_library("libyuv_internal") {
       "-ffp-contract=fast",  # Enable fma vectorization for NEON.
     ]
   }
+
+  if (current_cpu == "arm" && arm_version < 7) {
+    # This emables the neon test even if the current compile doesn't support it
+    defines += [ "LIBYUV_NEON" ]
+  }
 }
 
 if (libyuv_use_neon) {
@@ -229,6 +233,11 @@ if (libyuv_use_neon) {
 
     if (current_cpu != "arm64") {
       configs -= [ "//build/config/compiler:compiler_arm_fpu" ]
+      if (arm_version < 7) {
+        configs += [
+          "//build/config/compiler:force_march_armv7",
+        ]
+      }
       cflags = [ "-mfpu=neon" ]
     }
   }
--- a/src/third_party/libyuv/source/cpu_id.cc
+++ b/src/third_party/libyuv/source/cpu_id.cc
@@ -132,6 +132,18 @@ static int GetXCR0() {
 #pragma optimize("g", on)
 #endif
 
+#ifdef __ARMEL__
+// This is (a) simpler and (b) works in sandbox vs the /proc/cpuinfo method
+#include <sys/auxv.h>
+
+int ArmCpuCaps(const char* cpuinfo_name) {
+  const unsigned long auxval = getauxval(AT_HWCAP);
+
+  // Documentation suggests that getauxval(AT_HWCAP) should return a pointer
+  // to a bit array, but evidence suggests it returns a simple bit field
+  return ((auxval & HWCAP_ARM_NEON) != 0 ? kCpuHasNEON : 0);
+}
+#else
 // Based on libvpx arm_cpudetect.c
 // For Arm, but public to allow testing on any CPU
 LIBYUV_API SAFEBUFFERS int ArmCpuCaps(const char* cpuinfo_name) {
@@ -161,6 +173,7 @@ LIBYUV_API SAFEBUFFERS int ArmCpuCaps(co
   fclose(f);
   return 0;
 }
+#endif
 
 LIBYUV_API SAFEBUFFERS int RiscvCpuCaps(const char* cpuinfo_name) {
   char cpuinfo_line[512];
--- a/src/third_party/skia/src/core/SkBitmapProcState.cpp
+++ b/src/third_party/skia/src/core/SkBitmapProcState.cpp
@@ -24,6 +24,7 @@
 class SkImage;
 class SkImage_Base;
 
+#if !defined(SK_ARM_HAS_NEON) || defined(__ARM_64BIT_STATE)
 // One-stop-shop shader for,
 //   - nearest-neighbor sampling (_nofilter_),
 //   - clamp tiling in X and Y both (Clamp_),
@@ -79,6 +80,199 @@ static void Clamp_S32_opaque_D32_nofilte
         }
     }
 }
+#endif
+
+// We define two variants of this: one for 32-bit ARM NEON, and one generic C:
+
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+static inline void Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core_neon(SkPMColor* __restrict__ &dst, const SkPMColor* __restrict__ src, int core, SkFractionalInt fx, const SkFractionalInt dx)
+{
+    const SkPMColor*p = src + (int32_t)(fx >> 32);
+    uint32_t accum = (uint32_t) fx;
+    const SkPMColor *p2;
+    __asm__ volatile (
+            "cmp     %[core], #0           \n\t"
+            "it      ne                    \n\t"
+            "tstne   %[dst], #0xc          \n\t"
+            "beq     2f                    \n\t"
+            "1:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[inc1]         \n\t"
+            "addcs   %[p], %[inc2]         \n\t"
+            "vstm    %[dst]!, {s0}         \n\t"
+            "subs    %[core], #1           \n\t"
+            "it      ne                    \n\t"
+            "tstne   %[dst], #0xc          \n\t"
+            "bne     1b                    \n\t"
+            "2:                            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "subs    %[core], #4           \n\t"
+            "bcc     4f                    \n\t"
+            "3:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[p2], %[inc1]  \n\t"
+            "addcs   %[p], %[p2], %[inc2]  \n\t"
+            "vldr    s1, [%[p2]]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vldr    s2, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[p2], %[inc1]  \n\t"
+            "addcs   %[p], %[p2], %[inc2]  \n\t"
+            "vldr    s3, [%[p2]]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vst1.32 {q0}, [%[dst] :128]!  \n\t"
+            "subs    %[core], #4           \n\t"
+            "bcs     3b                    \n\t"
+            "4:                            \n\t"
+            "adds    %[core], #4           \n\t"
+            "beq     6f                    \n\t"
+            "5:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "mov     %[p], %[p2]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vstm    %[dst]!, {s0}         \n\t"
+            "subs    %[core], #1           \n\t"
+            "bne     5b                    \n\t"
+            "6:                            \n\t"
+    : // Outputs
+            [accum]"+r"(accum),
+             [core]"+r"(core),
+              [dst]"+r"(dst),
+                [p]"+r"(p),
+               [p2]"=&r"(p2)
+    : // Inputs
+              [dx]"r"((int32_t) dx),
+            [inc1]"r"((int32_t)(dx >> 32) * 4),
+            [inc2]"r"(((int32_t)(dx >> 32) + 1) * 4)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+#endif
+
+#if 0
+static inline void Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core(SkPMColor* __restrict__ &dst, const SkPMColor* __restrict__ src, int core, SkFractionalInt fx, const SkFractionalInt dx)
+{
+    const SkPMColor*p = src + (int32_t)(fx >> 32);
+    uint32_t accum = (uint32_t) fx;
+    for (; core > 0; --core) {
+        *dst++ = *p;
+        uint32_t prev_accum = accum;
+        accum += (int32_t) dx;
+        if (accum < prev_accum) /* i.e. carry set */
+            p += (int32_t)(dx >> 32) + 1;
+        else
+            p += (int32_t)(dx >> 32);
+    }
+}
+#endif
+
+#define Clamp_S32_opaque_D32_nofilter_DX_shaderproc_template(SUFFIX)                               \
+static void Clamp_S32_opaque_D32_nofilter_DX_shaderproc(const void* sIn, int x, int y,             \
+                                                        SkPMColor* SK_RESTRICT dst,  int count) {  \
+    const SkBitmapProcState& s = *static_cast<const SkBitmapProcState*>(sIn);                      \
+    SkASSERT(s.fAlphaScale == 256);                                                                \
+                                                                                                   \
+    const unsigned maxX = s.fPixmap.width() - 1;                                                   \
+    SkFractionalInt fx;                                                                            \
+    int dstY;                                                                                      \
+    {                                                                                              \
+        const SkBitmapProcStateAutoMapper mapper(s, x, y);                                         \
+        const unsigned maxY = s.fPixmap.height() - 1;                                              \
+        dstY = SkTPin(mapper.intY(), 0, (int)maxY);                                                    \
+        fx = mapper.fractionalIntX();                                                              \
+    }                                                                                              \
+                                                                                                   \
+    const SkPMColor* SK_RESTRICT src = s.fPixmap.addr32(0, dstY);                                  \
+    const SkFractionalInt dx = s.fInvSxFractionalInt;                                              \
+                                                                                                   \
+    int core;                                                                                      \
+                                                                                                   \
+    /* The unscaled case is easily common enough to be worth special-casing.                       \
+     * The system memcpy() is typically already heavily optimized, so just use that.               \
+     */                                                                                            \
+    if (dx == 0x100000000ll) {                                                                     \
+        int32_t fx_integer = fx >> 32;                                                             \
+        if (fx_integer < 0) {                                                                      \
+            int left = std::min(-fx_integer, count);                                                \
+            fx_integer += left;                                                                    \
+            count -= left;                                                                         \
+            for (; left > 0; --left)                                                               \
+                *dst++ = src[0];                                                                   \
+        }                                                                                          \
+        if (fx_integer < (int)maxX) {                                                              \
+            core = std::min((int)maxX + 1 - fx_integer, count);                                     \
+            memcpy(dst, src + fx_integer, core * sizeof (uint32_t));                               \
+            dst += core;                                                                           \
+            count -= core;                                                                         \
+        }                                                                                          \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[maxX];                                                                    \
+        }                                                                                          \
+    }                                                                                              \
+                                                                                                   \
+    /* Handle other non-reflected scale factors. */                                                \
+    else if (dx >= 0) {                                                                            \
+        for (; fx < 0 && count > 0; --count) {                                                     \
+            *dst++ = src[0];                                                                       \
+            fx += dx;                                                                              \
+        }                                                                                          \
+        if ((int32_t)(fx >> 32) > (int)maxX)                                                       \
+            core = 0;                                                                              \
+        else if ((int32_t)((fx + (count - 1) * dx) >> 32) <= (int)maxX)                            \
+            core = count;                                                                          \
+        else                                                                                       \
+            core = (int32_t)(((((SkFractionalInt) maxX) << 32) + 0xffffffff - fx) / dx) + 1;       \
+        Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core##SUFFIX(dst, src, core, fx, dx);          \
+        count -= core;                                                                             \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[maxX];                                                                    \
+        }                                                                                          \
+    }                                                                                              \
+                                                                                                   \
+    /* It's not clear if reflection is used, but it's a relatively                                 \
+     * simple variation on the non-reflected case. */                                              \
+    else                                                                                           \
+    {                                                                                              \
+        for (; (int32_t)(fx >> 32) > (int)maxX && count > 0; --count) {                            \
+            *dst++ = src[maxX];                                                                    \
+            fx += dx;                                                                              \
+        }                                                                                          \
+        if (fx < 0)                                                                                \
+            core = 0;                                                                              \
+        else if (fx + (count - 1) * dx >= 0)                                                       \
+            core = count;                                                                          \
+        else                                                                                       \
+            core = (int32_t)(fx / -dx) + 1;                                                        \
+        Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core##SUFFIX(dst, src, core, fx, dx);          \
+        count -= core;                                                                             \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[0];                                                                       \
+        }                                                                                          \
+    }                                                                                              \
+}
+
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+Clamp_S32_opaque_D32_nofilter_DX_shaderproc_template(_neon)
+#endif
+
 
 static void S32_alpha_D32_nofilter_DX(const SkBitmapProcState& s,
                                       const uint32_t* xy, int count, SkPMColor* colors) {
@@ -255,7 +449,11 @@ bool SkBitmapProcState::chooseProcs() {
     fMatrixProc = this->chooseMatrixProc(translate_only);
     SkASSERT(fMatrixProc);
 
-    fSampleProc32 = fBilerp ? SkOpts::S32_alpha_D32_filter_DX : S32_alpha_D32_nofilter_DX;
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+    fSampleProc32 = fBilerp ? (fAlphaScale == 256 ? SkOpts::S32_opaque_D32_filter_DX : SkOpts::S32_alpha_D32_filter_DX) : S32_alpha_D32_nofilter_DX  ;
+#else
+    fSampleProc32 = fBilerp ? SkOpts::S32_alpha_D32_filter_DX   : S32_alpha_D32_nofilter_DX  ;
+#endif
     SkASSERT(fSampleProc32);
 
     // our special-case shaderprocs
--- a/src/third_party/skia/src/core/SkBitmapProcState.h
+++ b/src/third_party/skia/src/core/SkBitmapProcState.h
@@ -216,7 +216,10 @@ namespace SkOpts {
     // SkBitmapProcState optimized Shader, Sample, or Matrix procs.
     extern void (*S32_alpha_D32_filter_DX)(const SkBitmapProcState&,
                                            const uint32_t* xy, int count, SkPMColor*);
-
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+    extern void (*S32_opaque_D32_filter_DX)(const SkBitmapProcState&,
+                                           const uint32_t* xy, int count, SkPMColor*);
+#endif
     void Init_BitmapProcState();
 }  // namespace SkOpts
 
--- a/src/third_party/skia/src/core/SkBitmapProcState_matrixProcs.cpp
+++ b/src/third_party/skia/src/core/SkBitmapProcState_matrixProcs.cpp
@@ -272,6 +272,530 @@ static unsigned clamp(SkFixed fx, int ma
     return SkTPin(fx >> 16, 0, max);
 }
 
+// Clamp/Clamp and Repeat/Repeat have NEON or portable implementations.
+#if defined(SK_ARM_HAS_NEON)
+    #include <arm_neon.h>
+
+    // TODO: this is a fine drop-in for decal_nofilter_scale() generally.
+    static void decal_nofilter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count) {
+        if (count >= 8) {
+            // SkFixed is 16.16 fixed point
+            SkFixed dx8 = dx * 8;
+            int32x4_t vdx8 = vdupq_n_s32(dx8);
+
+            // setup lbase and hbase
+            int32x4_t lbase, hbase;
+            lbase = vdupq_n_s32(fx);
+            lbase = vsetq_lane_s32(fx + dx, lbase, 1);
+            lbase = vsetq_lane_s32(fx + dx + dx, lbase, 2);
+            lbase = vsetq_lane_s32(fx + dx + dx + dx, lbase, 3);
+            hbase = lbase + vdupq_n_s32(4 * dx);
+
+            do {
+                // store the upper 16 bits
+                vst1q_u32(dst, vreinterpretq_u32_s16(
+                    vuzpq_s16(vreinterpretq_s16_s32(lbase), vreinterpretq_s16_s32(hbase)).val[1]
+                ));
+
+                // on to the next group of 8
+                lbase += vdx8;
+                hbase += vdx8;
+                dst += 4; // we did 8 elements but the result is twice smaller
+                count -= 8;
+                fx += dx8;
+            } while (count >= 8);
+        }
+
+        uint16_t* xx = (uint16_t*)dst;
+        for (int i = count; i > 0; --i) {
+            *xx++ = SkToU16(fx >> 16); fx += dx;
+        }
+    }
+
+    static void decal_filter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count) {
+#ifndef __ARM_64BIT_STATE
+        SkASSERT(((fx + (count-1) * dx) >> (16 + 14)) == 0);
+        fx = (fx << 2) + 1;
+        dx <<= 2;
+        while (((uintptr_t) dst & 0xf) && --count >= 0) {
+            *dst++ = (fx & 0xffffc001) + (fx >> 18);
+            fx += dx;
+        }
+        if ((count -= 4) >= 0) {
+            uint32_t tmp;
+            __asm__ (
+                    "adr         %[tmp], 1f                  \n\t"
+                    "vmvn.i32    q10, #0x3fff                \n\t"
+                    "vld1.32     {q11}, [%[tmp]]             \n\t"
+                    "vdup.32     q8, %[fx]                   \n\t"
+                    "vdup.32     q9, %[dx]                   \n\t"
+                    "vsra.u32    q10, #31                    \n\t"
+                    "vmla.u32    q8, q9, q11                 \n\t"
+                    "vshl.u32    q9, #2                      \n\t"
+                    "b           2f                          \n\t"
+                    "1:                                      \n\t"
+                    ".long       0                           \n\t"
+                    ".long       1                           \n\t"
+                    ".long       2                           \n\t"
+                    ".long       3                           \n\t"
+                    "2:                                      \n\t"
+                    "vand        q11, q8, q10                \n\t"
+                    "vshr.u32    q12, q8, #18                \n\t"
+                    "vadd.i32    q11, q12                    \n\t"
+                    "vadd.i32    q8, q9                      \n\t"
+                    "subs        %[count], #4                \n\t"
+                    "vst1.32     {q11}, [%[dst]:128]!        \n\t"
+                    "bpl         2b                          \n\t"
+                    "vmov.32     %[fx], d16[0]               \n\t"
+            : // Outputs
+                    [count]"+l"(count),
+                      [dst]"+r"(dst),
+                       [fx]"+r"(fx),
+                      [tmp]"=&r"(tmp)
+            : // Inputs
+                    [dx]"r"(dx)
+            : // Clobbers
+                    "cc", "memory"
+            );
+        }
+        if ((count += 4-1) >= 0) {
+            do {
+                *dst++ = (fx & 0xffffc001) + (fx >> 18);
+                fx += dx;
+            } while (--count >= 0);
+        }
+#else // !defined(__ARM_64BIT_STATE)
+        if (count >= 8) {
+            SkFixed dx8 = dx * 8;
+            int32x4_t vdx8 = vdupq_n_s32(dx8);
+
+            int32x4_t wide_fx, wide_fx2;
+            wide_fx = vdupq_n_s32(fx);
+            wide_fx = vsetq_lane_s32(fx + dx, wide_fx, 1);
+            wide_fx = vsetq_lane_s32(fx + dx + dx, wide_fx, 2);
+            wide_fx = vsetq_lane_s32(fx + dx + dx + dx, wide_fx, 3);
+
+            wide_fx2 = vaddq_s32(wide_fx, vdupq_n_s32(4 * dx));
+
+            while (count >= 8) {
+                int32x4_t wide_out;
+                int32x4_t wide_out2;
+
+                wide_out = vshlq_n_s32(vshrq_n_s32(wide_fx, 12), 14);
+                wide_out = wide_out | (vshrq_n_s32(wide_fx,16) + vdupq_n_s32(1));
+
+                wide_out2 = vshlq_n_s32(vshrq_n_s32(wide_fx2, 12), 14);
+                wide_out2 = wide_out2 | (vshrq_n_s32(wide_fx2,16) + vdupq_n_s32(1));
+
+                vst1q_u32(dst, vreinterpretq_u32_s32(wide_out));
+                vst1q_u32(dst+4, vreinterpretq_u32_s32(wide_out2));
+
+                dst += 8;
+                fx += dx8;
+                wide_fx += vdx8;
+                wide_fx2 += vdx8;
+                count -= 8;
+            }
+        }
+
+        if (count & 1)
+        {
+            SkASSERT((fx >> (16 + 14)) == 0);
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+        }
+        while ((count -= 2) >= 0)
+        {
+            SkASSERT((fx >> (16 + 14)) == 0);
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+        }
+#endif
+    }
+
+    static inline int16x8_t clamp8(int32x4_t low, int32x4_t high, unsigned max) {
+        int16x8_t res;
+
+        // get the hi 16s of all those 32s
+        res = vuzpq_s16(vreinterpretq_s16_s32(low), vreinterpretq_s16_s32(high)).val[1];
+
+        // clamp
+        res = vmaxq_s16(res, vdupq_n_s16(0));
+        res = vminq_s16(res, vdupq_n_s16(max));
+
+        return res;
+    }
+
+    static inline int32x4_t clamp4(int32x4_t f, unsigned max) {
+        int32x4_t res;
+
+        // get the hi 16s of all those 32s
+        res = vshrq_n_s32(f, 16);
+
+        // clamp
+        res = vmaxq_s32(res, vdupq_n_s32(0));
+        res = vminq_s32(res, vdupq_n_s32(max));
+
+        return res;
+    }
+
+    static inline int32x4_t extract_low_bits_clamp4(int32x4_t fx, unsigned) {
+        int32x4_t ret;
+
+        ret = vshrq_n_s32(fx, 12);
+
+        /* We don't need the mask below because the caller will
+         * overwrite the non-masked bits
+         */
+        //ret = vandq_s32(ret, vdupq_n_s32(0xF));
+
+        return ret;
+    }
+
+    static inline int16x8_t repeat8(int32x4_t low, int32x4_t high, unsigned max) {
+        uint16x8_t res;
+        uint32x4_t tmpl, tmph;
+
+        // get the lower 16 bits
+        res = vuzpq_u16(vreinterpretq_u16_s32(low), vreinterpretq_u16_s32(high)).val[0];
+
+        // bare multiplication, not SkFixedMul
+        tmpl = vmull_u16(vget_low_u16(res), vdup_n_u16(max+1));
+        tmph = vmull_u16(vget_high_u16(res), vdup_n_u16(max+1));
+
+        // extraction of the 16 upper bits
+        res = vuzpq_u16(vreinterpretq_u16_u32(tmpl), vreinterpretq_u16_u32(tmph)).val[1];
+
+        return vreinterpretq_s16_u16(res);
+    }
+
+    static inline int32x4_t repeat4(int32x4_t f, unsigned max) {
+        uint16x4_t res;
+        uint32x4_t tmp;
+
+        // get the lower 16 bits
+        res = vmovn_u32(vreinterpretq_u32_s32(f));
+
+        // bare multiplication, not SkFixedMul
+        tmp = vmull_u16(res, vdup_n_u16(max+1));
+
+        // extraction of the 16 upper bits
+        tmp = vshrq_n_u32(tmp, 16);
+
+        return vreinterpretq_s32_u32(tmp);
+    }
+
+    static inline int32x4_t extract_low_bits_repeat_mirror4(int32x4_t fx, unsigned max) {
+        uint16x4_t res;
+        uint32x4_t tmp;
+        int32x4_t ret;
+
+        // get the lower 16 bits
+        res = vmovn_u32(vreinterpretq_u32_s32(fx));
+
+        // bare multiplication, not SkFixedMul
+        tmp = vmull_u16(res, vdup_n_u16(max + 1));
+
+        // shift and mask
+        ret = vshrq_n_s32(vreinterpretq_s32_u32(tmp), 12);
+
+        /* We don't need the mask below because the caller will
+         * overwrite the non-masked bits
+         */
+        //ret = vandq_s32(ret, vdupq_n_s32(0xF));
+
+        return ret;
+    }
+
+    template <unsigned   (*tile)(SkFixed, int),
+              int16x8_t (*tile8)(int32x4_t, int32x4_t, unsigned),
+             bool tryDecal>
+    static void nofilter_scale_neon(const SkBitmapProcState& s,
+                                    uint32_t xy[], int count, int x, int y) {
+
+        // we store y, x, x, x, x, x
+        const unsigned maxX = s.fPixmap.width() - 1;
+        SkFractionalInt fx;
+        {
+            const SkBitmapProcStateAutoMapper mapper(s, x, y);
+            const unsigned maxY = s.fPixmap.height() - 1;
+            *xy++ = tile(mapper.fixedY(), maxY);
+            fx = mapper.fractionalIntX();
+        }
+
+        if (0 == maxX) {
+            // all of the following X values must be 0
+            memset(xy, 0, count * sizeof(uint16_t));
+            return;
+        }
+
+        const SkFractionalInt dx = s.fInvSxFractionalInt;
+
+        // test if we don't need to apply the tile proc
+        const SkFixed fixedFx = SkFractionalIntToFixed(fx);
+        const SkFixed fixedDx = SkFractionalIntToFixed(dx);
+        if (tryDecal && can_truncate_to_fixed_for_decal(fixedFx, fixedDx, count, maxX)) {
+            decal_nofilter_scale_neon(xy, fixedFx, fixedDx, count);
+            return;
+        }
+
+        if (count >= 8) {
+            SkFractionalInt dx2 = dx+dx;
+            SkFractionalInt dx4 = dx2+dx2;
+            SkFractionalInt dx8 = dx4+dx4;
+
+            // now build fx/fx+dx/fx+2dx/fx+3dx
+            SkFractionalInt fx1, fx2, fx3;
+            int32x4_t lbase, hbase;
+            int16_t *dst16 = (int16_t *)xy;
+
+            fx1 = fx+dx;
+            fx2 = fx1+dx;
+            fx3 = fx2+dx;
+
+            lbase = vdupq_n_s32(SkFractionalIntToFixed(fx));
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx1), lbase, 1);
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx2), lbase, 2);
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx3), lbase, 3);
+            hbase = vaddq_s32(lbase, vdupq_n_s32(SkFractionalIntToFixed(dx4)));
+
+            // store & bump
+            while (count >= 8) {
+
+                int16x8_t fx8;
+
+                fx8 = tile8(lbase, hbase, maxX);
+
+                vst1q_s16(dst16, fx8);
+
+                // but preserving base & on to the next
+                lbase = vaddq_s32 (lbase, vdupq_n_s32(SkFractionalIntToFixed(dx8)));
+                hbase = vaddq_s32 (hbase, vdupq_n_s32(SkFractionalIntToFixed(dx8)));
+                dst16 += 8;
+                count -= 8;
+                fx += dx8;
+            }
+            xy = (uint32_t *) dst16;
+        }
+
+        uint16_t* xx = (uint16_t*)xy;
+        for (int i = count; i > 0; --i) {
+            *xx++ = tile(SkFractionalIntToFixed(fx), maxX);
+            fx += dx;
+        }
+    }
+
+    template <unsigned              (*tile )(SkFixed, int),
+              int32x4_t             (*tile4)(int32x4_t, unsigned),
+              unsigned  (*extract_low_bits )(SkFixed, int),
+              int32x4_t (*extract_low_bits4)(int32x4_t, unsigned),
+              bool tryDecal>
+    static void filter_scale_neon(const SkBitmapProcState& s,
+                                  unsigned int * xy, int count, int x, int y) {
+
+        auto pack = [&](SkFixed f, unsigned max, SkFixed one) {
+            unsigned i = tile(f, max);
+            i = (i << 4) | extract_low_bits(f, max);
+            return (i << 14) | (tile((f + one), max));
+        };
+
+        auto pack4 = [&](int32x4_t f, unsigned max, SkFixed one) {
+            int32x4_t ret, res;
+
+            res = tile4(f, max);
+
+            ret = extract_low_bits4(f, max);
+            ret = vsliq_n_s32(ret, res, 4);
+
+            res = tile4(f + vdupq_n_s32(one), max);
+            ret = vorrq_s32(vshlq_n_s32(ret, 14), res);
+
+            return ret;
+        };
+
+        const unsigned maxX = s.fPixmap.width() - 1;
+        const SkFixed one = s.fFilterOneX;
+        const SkFractionalInt dx = s.fInvSxFractionalInt;
+        SkFractionalInt fx;
+
+        {
+            const SkBitmapProcStateAutoMapper mapper(s, x, y);
+            const SkFixed fy = mapper.fixedY();
+            const unsigned maxY = s.fPixmap.height() - 1;
+            // compute our two Y values up front
+            *xy++ = pack(fy, maxY, s.fFilterOneY);
+            // now initialize fx
+            fx = mapper.fractionalIntX();
+        }
+
+        // test if we don't need to apply the tile proc
+        const SkFixed fixedFx = SkFractionalIntToFixed(fx);
+        const SkFixed fixedDx = SkFractionalIntToFixed(dx);
+        if (tryDecal && can_truncate_to_fixed_for_decal(fixedFx, fixedDx, count, maxX)) {
+            decal_filter_scale_neon(xy, fixedFx, fixedDx, count);
+            return;
+        }
+
+#ifndef __ARM_64BIT_STATE
+        if (tile == clamp && one == SK_Fixed1) {
+            SkASSERT(maxX < (1<<14)-1);
+            if (dx >= 0) {
+                --count;
+                while (count >= 0 && fx < 0) {
+                    *xy++ = 0;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 0 && ((uintptr_t) xy & 0xf) && fx < ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                if ((count -= 8-1) >= 0 && fx + 7*dx < ((SkFractionalInt) maxX << 32)) {
+                    SkFractionalInt rem = (((SkFractionalInt) maxX << 32) - 7*dx - fx - 1) / 8;
+                    int32_t rem_hi = rem >> 32;
+                    uint32_t rem_lo = (uint32_t) rem;
+                    int32_t fx_hi = fx >> 32;
+                    uint32_t fx_lo = (uint32_t) fx;
+                    __asm__ (
+                            "vmov        d16, %[fx_lo], %[fx_hi]     \n\t"
+                            "vmov        d24, %[dx_lo], %[dx_hi]     \n\t"
+                            "vadd.i64    d17, d16, d24               \n\t"
+                            "vmov        d25, %[dx_lo], %[dx_hi]     \n\t"
+                            "vmvn.i32    q13, #0x3fff                \n\t"
+                            "vadd.i64    d18, d17, d24               \n\t"
+                            "vmov.i32    q14, #1                     \n\t"
+                            "vadd.i64    d19, d18, d24               \n\t"
+                            "vshl.i64    q12, #2                     \n\t"
+                            "b           2f                          \n\t"
+                            "1:                                      \n\t"
+                            "vadd.i64    q8, q10, q12                \n\t"
+                            "vadd.i64    q9, q11, q12                \n\t"
+                            "2:                                      \n\t"
+                            "vadd.i64    q10, q8, q12                \n\t"
+                            "vadd.i64    q11, q9, q12                \n\t"
+                            "vshrn.i64   d16, q8, #14                \n\t"
+                            "vshrn.i64   d17, q9, #14                \n\t"
+                            "vand        q8, q13                     \n\t"
+                            "vorr        q8, q14                     \n\t"
+                            "vshrn.i64   d18, q10, #14               \n\t"
+                            "vshrn.i64   d19, q11, #14               \n\t"
+                            "vand        q9, q13                     \n\t"
+                            "subs        %[rem_lo], %[dx_lo]         \n\t"
+                            "vorr        q9, q14                     \n\t"
+                            "sbcs        %[rem_hi], %[dx_hi]         \n\t"
+                            "vsra.u32    q8, #18                     \n\t"
+                            "subs        %[count], #8                \n\t"
+                            "vsra.u32    q9, #18                     \n\t"
+                            "it          pl                          \n\t"
+                            "teqpl       %[rem_hi], #0               \n\t"
+                            "vst1.32     {q8-q9}, [%[dst]:128]!      \n\t"
+                            "bpl         1b                          \n\t"
+                            "vadd.i64    d16, d20, d24               \n\t"
+                            "vmov        %[fx_lo], %[fx_hi], d16     \n\t"
+                    : // Outputs
+                             [count]"+l"(count),
+                               [dst]"+r"(xy),
+                            [rem_hi]"+l"(rem_hi),
+                            [rem_lo]"+l"(rem_lo),
+                             [fx_hi]"+r"(fx_hi),
+                             [fx_lo]"+r"(fx_lo)
+                    : // Inputs
+                            [dx_hi]"l"((int32_t) (dx >> 32)),
+                            [dx_lo]"l"((uint32_t) dx)
+                    : // Clobbers
+                            "cc", "memory"
+                    );
+                    fx = ((SkFractionalInt) fx_hi << 32) | fx_lo;
+                }
+                count += 8-1;
+                while (count >= 0 && fx < ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 0) {
+                    *xy++ = (maxX << 18) + maxX;
+                    --count;
+                }
+            } else {
+                // Reflection case. Don't bother to optimize this as much -
+                // not even sure if it's used!
+                while (count >= 1 && fx >= ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = (maxX << 18) + maxX;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 1 && fx >= 0) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 1) {
+                    *xy++ = 0;
+                    --count;
+                }
+            }
+        }
+        else
+        {
+        // Drop back to old code for repeat or other values of 'one'
+#endif
+        if (count >= 4) {
+            int32x4_t wide_fx;
+
+            wide_fx = vdupq_n_s32(SkFractionalIntToFixed(fx));
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx), wide_fx, 1);
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx+dx), wide_fx, 2);
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx+dx+dx), wide_fx, 3);
+
+            while (count >= 4) {
+                int32x4_t res;
+
+                res = pack4(wide_fx, maxX, one);
+
+                vst1q_u32(xy, vreinterpretq_u32_s32(res));
+
+                wide_fx += vdupq_n_s32(SkFractionalIntToFixed(dx+dx+dx+dx));
+                fx += dx+dx+dx+dx;
+                xy += 4;
+                count -= 4;
+            }
+        }
+
+        while (--count >= 0) {
+            *xy++ = pack(SkFractionalIntToFixed(fx), maxX, one);
+            fx += dx;
+        }
+#ifndef __ARM_64BIT_STATE
+        }
+#endif
+    }
+
+    static const SkBitmapProcState::MatrixProc ClampX_ClampY_Procs[] = {
+        nofilter_scale_neon<clamp, clamp8, true>,
+        filter_scale_neon<clamp,
+                          clamp4,
+                          extract_low_bits_clamp_clamp,
+                          extract_low_bits_clamp4,
+                          true>,
+        nofilter_affine<clamp, clamp>,       filter_affine<clamp, clamp, extract_low_bits_clamp_clamp>,
+    };
+
+    static const SkBitmapProcState::MatrixProc RepeatX_RepeatY_Procs[] = {
+        nofilter_scale_neon<repeat, repeat8, false>,
+        filter_scale_neon<repeat,
+                          repeat4,
+                          extract_low_bits_general,
+                          extract_low_bits_repeat_mirror4,
+                          false>,
+        nofilter_affine<repeat, repeat>,        filter_affine<repeat, repeat, extract_low_bits_general>
+    };
+#else
+
 static const SkBitmapProcState::MatrixProc ClampX_ClampY_Procs[] = {
     nofilter_scale <clamp, clamp, true>, filter_scale <clamp, clamp, extract_low_bits_clamp_clamp, true>,
     nofilter_affine<clamp, clamp>,       filter_affine<clamp, clamp, extract_low_bits_clamp_clamp>,
@@ -280,6 +804,9 @@ static const SkBitmapProcState::MatrixPr
     nofilter_scale <repeat, repeat, false>, filter_scale <repeat, repeat, extract_low_bits_general, false>,
     nofilter_affine<repeat, repeat>,        filter_affine<repeat, repeat, extract_low_bits_general>
 };
+
+#endif
+
 static const SkBitmapProcState::MatrixProc MirrorX_MirrorY_Procs[] = {
     nofilter_scale <mirror, mirror,  false>, filter_scale <mirror, mirror, extract_low_bits_general, false>,
     nofilter_affine<mirror, mirror>,         filter_affine<mirror, mirror, extract_low_bits_general>,
--- a/src/third_party/skia/src/core/SkBitmapProcState_opts.cpp
+++ b/src/third_party/skia/src/core/SkBitmapProcState_opts.cpp
@@ -19,6 +19,9 @@
 
 namespace SkOpts {
     DEFINE_DEFAULT(S32_alpha_D32_filter_DX);
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+    DEFINE_DEFAULT(S32_opaque_D32_filter_DX);
+#endif
 
     void Init_BitmapProcState_ssse3();
 
--- a/src/third_party/skia/src/opts/SkBitmapProcState_opts.h
+++ b/src/third_party/skia/src/opts/SkBitmapProcState_opts.h
@@ -256,6 +256,256 @@ static void decode_packed_coordinates_an
         }
     }
 
+#elif defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+#define S32_ALPHA_D32_FILTER_DX_1PIX_NEON(opt)               \
+            "ldr         %[x], [%[xy]], #4           \n\t"   \
+            "uxth        %[tmp2], %[x], ror #16      \n\t"   \
+            "lsl         %[tmp3], %[x], #2           \n\t"   \
+            "bic         %[tmp2], #3                 \n\t"   \
+            "uxth        %[tmp3], %[tmp3]            \n\t"   \
+            "add         %[tmp0], %[row0], %[tmp2]   \n\t"   \
+            "add         %[tmp1], %[row0], %[tmp3]   \n\t"   \
+            "add         %[tmp2], %[row1], %[tmp2]   \n\t"   \
+            "add         %[tmp3], %[row1], %[tmp3]   \n\t"   \
+            "lsr         %[x], #14                   \n\t"   \
+            "vldr        s0, [%[tmp0]]               \n\t"   \
+            "and         %[x], #0xf                  \n\t"   \
+            "vldr        s1, [%[tmp1]]               \n\t"   \
+            "vldr        s2, [%[tmp2]]               \n\t"   \
+            "vldr        s3, [%[tmp3]]               \n\t"   \
+            "vdup.16     d2, %[x]                    \n\t"   \
+            "vsub.i16    d3, d23, d2                 \n\t"   \
+            "vmull.u8    q2, d0, d31                 \n\t"   \
+            "vmlal.u8    q2, d1, d30                 \n\t"   \
+            "vmul.u16    d0, d4, d3                  \n\t"   \
+            "vmla.u16    d0, d5, d2                  \n\t"   \
+            "vshr.u16    d0, #8                      \n\t"   \
+            "vmul.u16    d0, d10                     \n\t"   \
+            opt"                                     \n\t"   \
+            "vshrn.u16   d0, q0, #8                  \n\t"   \
+            "vst1.32     {d0[0]}, [%[dst]:32]!       \n\t"   \
+
+void S32_alpha_D32_filter_DX(const SkBitmapProcState& s,
+                             const uint32_t* SK_RESTRICT xy,
+                             int count, SkPMColor* SK_RESTRICT colors) {
+    SkASSERT(count > 0 && colors != nullptr);
+    SkASSERT(4 == s.fPixmap.info().bytesPerPixel());
+    SkASSERT(s.fAlphaScale <= 256);
+
+    int y0, y1, wy;
+    decode_packed_coordinates_and_weight(*xy++, &y0, &y1, &wy);
+
+    auto row0 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y0 * s.fPixmap.rowBytes() ),
+         row1 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y1 * s.fPixmap.rowBytes() );
+
+    uint32_t tmp0, tmp1, tmp2, tmp3, x;
+    __asm__ volatile (
+            "vpush       {q4-q5}                     \n\t"
+            "vmov.i16    d22, #0xf                   \n\t"
+            "vmov.i16    d23, #0x10                  \n\t"
+            "vmov.i32    q12, #0x3fff                \n\t"
+            "vdup.32     q13, %[row0]                \n\t"
+            "vdup.32     q14, %[row1]                \n\t"
+            "vdup.i8     d30, %[subY]                \n\t"
+            "vmov.i8     d31, #16                    \n\t"
+            "vdup.16     q5, %[alpha]                \n\t"
+            "vshl.i32    q12, #2                     \n\t"
+            "tst         %[dst], #0xc                \n\t"
+            "vsub.i8     d31, d30                    \n\t"
+            "beq         2f                          \n\t"
+
+            "1:                                      \n\t"
+            S32_ALPHA_D32_FILTER_DX_1PIX_NEON(
+            "add         %[tmp0], %[dst], #4         \n\t"
+            "subs        %[len], #1                  \n\t"
+            "it          ne                          \n\t"
+            "tstne       %[tmp0], #0xc"
+            )
+            "bne         1b                          \n\t"
+
+            "2:"
+            "subs        %[len], #4                  \n\t"
+            "bmi         13f                         \n\t"
+
+            "vld1.32     {q8}, [%[xy]]!              \n\t"
+            "vshr.u32    q9, q8, #16                 \n\t"
+            "vand        q9, q12                     \n\t"
+            "vadd.i32    q1, q13, q9                 \n\t"
+            "vshl.i32    q0, q8, #2                  \n\t"
+            "vand        q0, q12                     \n\t"
+            "vadd.i32    q2, q13, q0                 \n\t"
+            "vmov        %[tmp0], s4                 \n\t"
+            "vmov        %[tmp1], s5                 \n\t"
+            "vadd.i32    q3, q14, q9                 \n\t"
+            "vmov        %[tmp2], %[tmp3], d3        \n\t"
+
+            "11:                                     \n\t"
+            "vadd.i32    q4, q14, q0                 \n\t"
+            "vldr        s4, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s8                 \n\t"
+            "vldr        s5, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s9                 \n\t"
+            "vldr        s6, [%[tmp2]]               \n\t"
+            "vmov        %[tmp2], s10                \n\t"
+            "vldr        s7, [%[tmp3]]               \n\t"
+            "vmov        %[tmp3], s11                \n\t"
+            "vldr        s8, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s12                \n\t"
+            "vldr        s9, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s13                \n\t"
+            "vldr        s10, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s14                \n\t"
+            "vldr        s11, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s15                \n\t"
+            "vldr        s12, [%[tmp0]]              \n\t"
+            "vmov        %[tmp0], s16                \n\t"
+            "vldr        s13, [%[tmp1]]              \n\t"
+            "vmov        %[tmp1], s17                \n\t"
+            "vldr        s14, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s18                \n\t"
+            "vldr        s15, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s19                \n\t"
+            "vldr        s16, [%[tmp0]]              \n\t"
+            "vshrn.i32   d1, q8, #14                 \n\t"
+            "vldr        s17, [%[tmp1]]              \n\t"
+            "vand        d1, d22                     \n\t"
+            "vldr        s18, [%[tmp2]]              \n\t"
+            "vsub.i16    d0, d23, d1                 \n\t"
+            "vldr        s19, [%[tmp3]]              \n\t"
+            "vmull.u8    q10, d2, d31                \n\t"
+            "vmlal.u8    q10, d6, d30                \n\t"
+            "vmull.u8    q1, d3, d31                 \n\t"
+            "vmlal.u8    q1, d7, d30                 \n\t"
+            "vmull.u8    q3, d4, d31                 \n\t"
+            "subs        %[len], #4                  \n\t"
+            "vmlal.u8    q3, d8, d30                 \n\t"
+            "bmi         12f                         \n\t"
+
+            "  vld1.32     {q8}, [%[xy]]!            \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "  vshr.u32    d18, d16, #16             \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "  vshr.u32    d19, d17, #16             \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "  vand        d18, d24                  \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "  vand        d19, d25                  \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "  vadd.i32    d2, d26, d18              \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "  vadd.i32    d3, d27, d19              \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "  vshl.i32    d0, d16, #2               \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "  vshl.i32    d1, d17, #2               \n\t"
+            "  vand        q0, q12                   \n\t"
+            "  vadd.i32    q2, q13, q0               \n\t"
+            "vshr.u16    q4, #8                      \n\t"
+            "vshr.u16    q10, #8                     \n\t"
+            "vmul.u16    q4, q5                      \n\t"
+            "vmul.u16    q10, q5                     \n\t"
+            "  vmov        %[tmp0], %[tmp1], d2      \n\t"
+            "  vadd.i32    q3, q14, q9               \n\t"
+            "  vmov        %[tmp2], %[tmp3], d3      \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+            "b           11b                         \n\t"
+
+            "12:                                     \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "vshr.u16    q4, #8                      \n\t"
+            "vshr.u16    q10, #8                     \n\t"
+            "vmul.u16    q4, q5                      \n\t"
+            "vmul.u16    q10, q5                     \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+
+            "13:                                     \n\t"
+            "adds        %[len], #4-1                \n\t"
+            "bmi         22f                         \n\t"
+
+            "21:                                     \n\t"
+            S32_ALPHA_D32_FILTER_DX_1PIX_NEON("subs %[len], #1")
+            "bpl         21b                         \n\t"
+
+            "22:                                     \n\t"
+            "vpop        {q4-q5}                     \n\t"
+    : // Outputs
+             [dst]"+r"(colors),
+              [xy]"+r"(xy),
+             [len]"+r"(count),
+            [tmp0]"=&r"(tmp0),
+            [tmp1]"=&r"(tmp1),
+            [tmp2]"=&r"(tmp2),
+            [tmp3]"=&r"(tmp3),
+               [x]"=&r"(x)
+    : // Inputs
+            [alpha]"r"(s.fAlphaScale),
+             [row0]"r"(row0),
+             [row1]"r"(row1),
+             [subY]"r"(wy)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+#if 0
+        // Copied from just below
+        static void filter_and_scale_by_alpha(unsigned x, unsigned y,
+                                              SkPMColor a00, SkPMColor a01,
+                                              SkPMColor a10, SkPMColor a11,
+                                              SkPMColor *dst,
+                                              uint16_t scale) {
+            uint8x8_t vy, vconst16_8, v16_y, vres;
+            uint16x4_t vx, vconst16_16, v16_x, tmp, vscale;
+            uint32x2_t va0, va1;
+            uint16x8_t tmp1, tmp2;
+
+            vy = vdup_n_u8(y);                // duplicate y into vy
+            vconst16_8 = vmov_n_u8(16);       // set up constant in vconst16_8
+            v16_y = vsub_u8(vconst16_8, vy);  // v16_y = 16-y
+
+            va0 = vdup_n_u32(a00);            // duplicate a00
+            va1 = vdup_n_u32(a10);            // duplicate a10
+            va0 = vset_lane_u32(a01, va0, 1); // set top to a01
+            va1 = vset_lane_u32(a11, va1, 1); // set top to a11
+
+            tmp1 = vmull_u8(vreinterpret_u8_u32(va0), v16_y); // tmp1 = [a01|a00] * (16-y)
+            tmp2 = vmull_u8(vreinterpret_u8_u32(va1), vy);    // tmp2 = [a11|a10] * y
+
+            vx = vdup_n_u16(x);                // duplicate x into vx
+            vconst16_16 = vmov_n_u16(16);      // set up constant in vconst16_16
+            v16_x = vsub_u16(vconst16_16, vx); // v16_x = 16-x
+
+            tmp = vmul_u16(vget_high_u16(tmp1), vx);        // tmp  = a01 * x
+            tmp = vmla_u16(tmp, vget_high_u16(tmp2), vx);   // tmp += a11 * x
+            tmp = vmla_u16(tmp, vget_low_u16(tmp1), v16_x); // tmp += a00 * (16-x)
+            tmp = vmla_u16(tmp, vget_low_u16(tmp2), v16_x); // tmp += a10 * (16-x)
+
+            if (scale < 256) {
+                vscale = vdup_n_u16(scale);        // duplicate scale
+                tmp = vshr_n_u16(tmp, 8);          // shift down result by 8
+                tmp = vmul_u16(tmp, vscale);       // multiply result by scale
+            }
+
+            vres = vshrn_n_u16(vcombine_u16(tmp, vcreate_u16(0)), 8); // shift down result by 8
+            vst1_lane_u32(dst, vreinterpret_u32_u8(vres), 0);         // store result
+        }
+#endif
+
 #else
 
     // The NEON code only actually differs from the portable code in the
@@ -368,6 +618,202 @@ static void decode_packed_coordinates_an
 
 #endif
 
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+#define S32_OPAQUE_D32_FILTER_DX_1PIX_NEON(opt)              \
+            "ldr         %[x], [%[xy]], #4           \n\t"   \
+            "uxth        %[tmp2], %[x], ror #16      \n\t"   \
+            "lsl         %[tmp3], %[x], #2           \n\t"   \
+            "bic         %[tmp2], #3                 \n\t"   \
+            "uxth        %[tmp3], %[tmp3]            \n\t"   \
+            "add         %[tmp0], %[row0], %[tmp2]   \n\t"   \
+            "add         %[tmp1], %[row0], %[tmp3]   \n\t"   \
+            "add         %[tmp2], %[row1], %[tmp2]   \n\t"   \
+            "add         %[tmp3], %[row1], %[tmp3]   \n\t"   \
+            "lsr         %[x], #14                   \n\t"   \
+            "vldr        s0, [%[tmp0]]               \n\t"   \
+            "and         %[x], #0xf                  \n\t"   \
+            "vldr        s1, [%[tmp1]]               \n\t"   \
+            "vldr        s2, [%[tmp2]]               \n\t"   \
+            "vldr        s3, [%[tmp3]]               \n\t"   \
+            "vdup.16     d2, %[x]                    \n\t"   \
+            "vsub.i16    d3, d23, d2                 \n\t"   \
+            "vmull.u8    q2, d0, d31                 \n\t"   \
+            "vmlal.u8    q2, d1, d30                 \n\t"   \
+            "vmul.u16    d0, d4, d3                  \n\t"   \
+            "vmla.u16    d0, d5, d2                  \n\t"   \
+            opt"                                     \n\t"   \
+            "vshrn.u16   d0, q0, #8                  \n\t"   \
+            "vst1.32     {d0[0]}, [%[dst]:32]!       \n\t"   \
+
+void S32_opaque_D32_filter_DX(const SkBitmapProcState& s,
+                              const uint32_t* SK_RESTRICT xy,
+                              int count, SkPMColor* SK_RESTRICT colors) {
+    SkASSERT(count > 0 && colors != nullptr);
+    SkASSERT(4 == s.fPixmap.info().bytesPerPixel());
+    SkASSERT(s.fAlphaScale == 256);
+
+    int y0, y1, wy;
+    decode_packed_coordinates_and_weight(*xy++, &y0, &y1, &wy);
+
+    auto row0 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y0 * s.fPixmap.rowBytes() ),
+         row1 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y1 * s.fPixmap.rowBytes() );
+
+    uint32_t tmp0, tmp1, tmp2, tmp3, x;
+    __asm__ volatile (
+            "vpush       {q4}                        \n\t"
+            "vmov.i16    d22, #0xf                   \n\t"
+            "vmov.i16    d23, #0x10                  \n\t"
+            "vmov.i32    q12, #0x3fff                \n\t"
+            "vdup.32     q13, %[row0]                \n\t"
+            "vdup.32     q14, %[row1]                \n\t"
+            "vdup.i8     d30, %[subY]                \n\t"
+            "vmov.i8     d31, #16                    \n\t"
+            "vshl.i32    q12, #2                     \n\t"
+            "tst         %[dst], #0xc                \n\t"
+            "vsub.i8     d31, d30                    \n\t"
+            "beq         2f                          \n\t"
+
+            "1:                                      \n\t"
+            S32_OPAQUE_D32_FILTER_DX_1PIX_NEON(
+            "add         %[tmp0], %[dst], #4         \n\t"
+            "subs        %[len], #1                  \n\t"
+            "it          ne                          \n\t"
+            "tstne       %[tmp0], #0xc"
+            )
+            "bne         1b                          \n\t"
+
+            "2:"
+            "subs        %[len], #4                  \n\t"
+            "bmi         13f                         \n\t"
+
+            "vld1.32     {q8}, [%[xy]]!              \n\t"
+            "vshr.u32    q9, q8, #16                 \n\t"
+            "vand        q9, q12                     \n\t"
+            "vadd.i32    q1, q13, q9                 \n\t"
+            "vshl.i32    q0, q8, #2                  \n\t"
+            "vand        q0, q12                     \n\t"
+            "vadd.i32    q2, q13, q0                 \n\t"
+            "vmov        %[tmp0], s4                 \n\t"
+            "vmov        %[tmp1], s5                 \n\t"
+
+            "11:                                     \n\t"
+            "vadd.i32    q3, q14, q9                 \n\t"
+            "vmov        %[tmp2], %[tmp3], d3        \n\t"
+            "vadd.i32    q4, q14, q0                 \n\t"
+            "vldr        s4, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s8                 \n\t"
+            "vldr        s5, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s9                 \n\t"
+            "vldr        s6, [%[tmp2]]               \n\t"
+            "vmov        %[tmp2], s10                \n\t"
+            "vldr        s7, [%[tmp3]]               \n\t"
+            "vmov        %[tmp3], s11                \n\t"
+            "vldr        s8, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s12                \n\t"
+            "vldr        s9, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s13                \n\t"
+            "vldr        s10, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s14                \n\t"
+            "vldr        s11, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s15                \n\t"
+            "vldr        s12, [%[tmp0]]              \n\t"
+            "vmov        %[tmp0], s16                \n\t"
+            "vldr        s13, [%[tmp1]]              \n\t"
+            "vmov        %[tmp1], s17                \n\t"
+            "vldr        s14, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s18                \n\t"
+            "vldr        s15, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s19                \n\t"
+            "vldr        s16, [%[tmp0]]              \n\t"
+            "vshrn.i32   d1, q8, #14                 \n\t"
+            "vldr        s17, [%[tmp1]]              \n\t"
+            "vand        d1, d22                     \n\t"
+            "vldr        s18, [%[tmp2]]              \n\t"
+            "vsub.i16    d0, d23, d1                 \n\t"
+            "vldr        s19, [%[tmp3]]              \n\t"
+            "vmull.u8    q10, d2, d31                \n\t"
+            "vmlal.u8    q10, d6, d30                \n\t"
+            "vmull.u8    q1, d3, d31                 \n\t"
+            "vmlal.u8    q1, d7, d30                 \n\t"
+            "vmull.u8    q3, d4, d31                 \n\t"
+            "subs        %[len], #4                  \n\t"
+            "vmlal.u8    q3, d8, d30                 \n\t"
+            "bmi         12f                         \n\t"
+
+            "  vld1.32     {q8}, [%[xy]]!            \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "  vshr.u32    d18, d16, #16             \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "  vshr.u32    d19, d17, #16             \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "  vand        d18, d24                  \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "  vand        d19, d25                  \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "  vadd.i32    d2, d26, d18              \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "  vadd.i32    d3, d27, d19              \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "  vshl.i32    d0, d16, #2               \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "  vshl.i32    d1, d17, #2               \n\t"
+            "  vand        q0, q12                   \n\t"
+            "  vadd.i32    q2, q13, q0               \n\t"
+            "  vmov        %[tmp0], s4               \n\t"
+            "  vmov        %[tmp1], s5               \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+            "b           11b                         \n\t"
+
+            "12:                                     \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+
+            "13:                                     \n\t"
+            "adds        %[len], #4-1                \n\t"
+            "bmi         22f                         \n\t"
+
+            "21:                                     \n\t"
+            S32_OPAQUE_D32_FILTER_DX_1PIX_NEON("subs %[len], #1")
+            "bpl         21b                         \n\t"
+
+            "22:                                     \n\t"
+            "vpop        {q4}                        \n\t"
+    : // Outputs
+             [dst]"+r"(colors),
+              [xy]"+r"(xy),
+             [len]"+r"(count),
+            [tmp0]"=&r"(tmp0),
+            [tmp1]"=&r"(tmp1),
+            [tmp2]"=&r"(tmp2),
+            [tmp3]"=&r"(tmp3),
+               [x]"=&r"(x)
+    : // Inputs
+            [row0]"r"(row0),
+            [row1]"r"(row1),
+            [subY]"r"(wy)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+
+#endif
+
 }  // namespace SK_OPTS_NS
 
 namespace sktests {
--- a/src/third_party/skia/src/opts/SkBlitMask_opts.h
+++ b/src/third_party/skia/src/opts/SkBlitMask_opts.h
@@ -233,6 +233,322 @@ namespace SK_OPTS_NS {
     }
 }
 
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+// These macros permit optionally-included features to be switched using a parameter to another macro
+#define YES(x) x
+#define NO(x)
+
+// How far ahead (pixels) to preload (undefine to disable prefetch) - determined empirically
+#define PREFETCH_DISTANCE "52"
+
+#ifdef PREFETCH_DISTANCE
+#define IF_PRELOAD YES
+#else
+#define IF_PRELOAD NO
+#endif
+
+/// Macro to load 1..7 source and mask pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_A8_LOAD_SM_LEADING_7(r0, r1, r2, r3, s_base, r4, m_base, opt1, opt2)                       \
+                opt1"                                                                           \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                opt2"                                                                           \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[1]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[2]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[3]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[4]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[5]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[6]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[7]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load or store 1..7 destination pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_A8_LOADSTORE_D_LEADING_7(ls, r0, r1, r2, r3, d_base)                                       \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#d_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "add         %[tmp], %["#d_base"], #4                                           \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load 1..7 source and mask pixels in shrinking powers-of-2 in size - suitable for trailing pixels
+#define S32A_A8_LOAD_SM_TRAILING_7(r0, r1, r2, r3, s_base, r4, m_base, opt1, opt2)                      \
+                opt1"                                                                           \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                opt2"                                                                           \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[0]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[1]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[2]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[3]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[4]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[5]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[6]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load or store 1..7 destination pixels in shrinking powers-of-2 in size - suitable for trailing pixels
+#define S32A_A8_LOADSTORE_D_TRAILING_7(ls, r0, r1, r2, r3, d_base)                                      \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "add         %[tmp], %["#d_base"], #4                                           \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#d_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to do shortcut testing for "over" compositing of 32bpp premultiplied ARGB source and 8-bit alpha mask
+#define S32A_A8_TEST(dst_adjust)                                                                        \
+                "vmov        %[mlo], %[mhi], d16                                                \n\t"   \
+                "vmov        %[alo], s6                                                         \n\t"   \
+                "vmov        %[ahi], s7                                                         \n\t"   \
+                "and         %[tmp], %[mlo], %[mhi]                                             \n\t"   \
+                "orrs        %[mlo], %[mhi]                                                     \n\t"   \
+                "it          ne                                                                 \n\t"   \
+                "orrsne      %[mlo], %[alo], %[ahi]                                             \n\t"   \
+                "it          eq                                                                 \n\t"   \
+                "addeq       %[dst], " dst_adjust "                                             \n\t"   \
+                "beq         9f                                                                 \n\t"   \
+                "and         %[tmp], %[alo]                                                     \n\t"   \
+                "and         %[tmp], %[ahi]                                                     \n\t"   \
+                "cmp         %[tmp], #-1                                                        \n\t"   \
+                "beq         5f                                                                 \n\t"   \
+
+/// Macro to do testing and "over" compositing of a group of 1..7 32bpp premultiplied ARGB source and 1..7 8-bit alpha mask leading or trailing pixels
+#define S32A_A8_7PIX_PROCESS(load_sm_7, loadstore_d_7, size)                                            \
+    do {                                                                                                \
+        __asm__ volatile (                                                                              \
+                /* Load the leading/trailing source pixels,                                             \
+                 * after initialising all the unused indexes from the first pixel                       \
+                 * so the all-opaque and all-transparent tests still work */                            \
+                load_sm_7(d0, d1, d2, d3, src, d16, msk,                                                \
+                "vld1.8      {d16[]}, [%[msk]]",                                                        \
+                "vld4.8      {d0[], d1[], d2[], d3[]}, [%[src]]")                                       \
+                S32A_A8_TEST("%[group_size], lsl #2")                                                   \
+                /* Translucency used, or a mixture of opaque and transparent */                         \
+                loadstore_d_7(ld, d4, d5, d6, d7, dst)                                                  \
+                "sub         %[dst], %[group_size], lsl #2                                      \n\t"   \
+                S32A_A8_8PIX_BLEND(, NO, NO)                                                      \
+                loadstore_d_7(st, d0, d1, d2, d3, dst)                                                  \
+                /* Drop through */                                                                      \
+                "9:                                                                             \n\t"   \
+        : /* Outputs */                                                                                 \
+                [mlo]"=&r"(mlo),                                                                        \
+                [mhi]"=&r"(mhi),                                                                        \
+                [alo]"=&r"(alo),                                                                        \
+                [ahi]"=&r"(ahi),                                                                        \
+                [tmp]"=&r"(tmp),                                                                        \
+                [src]"+r"(src),                                                                         \
+                [msk]"+r"(msk),                                                                         \
+                [dst]"+r"(dst)                                                                          \
+        : /* Inputs */                                                                                  \
+                [group_size]"r"(size),                                                                  \
+                     [eight]"r"(eight)                                                                  \
+        : /* Clobbers */                                                                                \
+                "cc", "memory"                                                                          \
+        );                                                                                              \
+    } while (0)
+
+/// Macro to do "over" compositing blending on 8 32bpp premultiplied ARGB source and 8 8-bit alpha mask pixels
+/// which are with either translucent or a mixture of opaque and transparent.
+/// Relies on A(x) to determine whether to emit code in ARM state (as opposed to Thumb state).
+/// @arg align           bit-alignment specifier on destination loads/stores (optional)
+/// @arg if_loadstore    YES or NO: whether to do load/store of destination
+/// @arg if_preload      YES or NO: whether to insert prefetch instructions
+#define S32A_A8_8PIX_BLEND(align, if_loadstore, if_preload)                                        \
+if_loadstore(   "vld4.8      {d4-d7}, [%[dst]"#align"]                                          \n\t")  \
+if_preload(     "sub         %[tmp], %[len], #1                                                 \n\t")  \
+                "vmull.u8    q9, d3, d16                                                        \n\t"   \
+if_preload(     "cmp         %[tmp], #" PREFETCH_DISTANCE "                                     \n\t")  \
+                "vmull.u8    q10, d0, d16                                                       \n\t"   \
+if_preload(     "it          cs                                                                 \n\t")  \
+if_preload(     "movcs       %[tmp], #" PREFETCH_DISTANCE "                                     \n\t")  \
+                "vmull.u8    q11, d1, d16                                                       \n\t"   \
+                "vmull.u8    q8, d2, d16                                                        \n\t"   \
+                "vrshr.u16   q1, q9, #8                                                         \n\t"   \
+if_preload(     "pld         [%[msk], %[tmp]]                                                   \n\t")  \
+                "vrshr.u16   q0, q10, #8                                                        \n\t"   \
+if_preload(     "pld         [%[src], %[tmp], lsl #2]                                           \n\t")  \
+                "vraddhn.u16 d3, q9, q1                                                         \n\t"   \
+if_preload(     "add         %[tmp], #32/4                                                      \n\t")  \
+                "vrshr.u16   q9, q11, #8                                                        \n\t"   \
+                "vrshr.u16   q12, q8, #8                                                        \n\t"   \
+                "vmvn        d2, d3                                                             \n\t"   \
+if_preload(     "pld         [%[dst], %[tmp], lsl #2]                                           \n\t")  \
+                "vraddhn.u16 d0, q10, q0                                                        \n\t"   \
+                "vmull.u8    q10, d4, d2                                                        \n\t"   \
+                "vmull.u8    q13, d5, d2                                                        \n\t"   \
+                "vmull.u8    q14, d6, d2                                                        \n\t"   \
+                "vmull.u8    q15, d7, d2                                                        \n\t"   \
+                "vrshr.u16   q2, q10, #8                                                        \n\t"   \
+                "vrshr.u16   q3, q13, #8                                                        \n\t"   \
+                "vraddhn.u16 d1, q11, q9                                                        \n\t"   \
+                "vrshr.u16   q9, q14, #8                                                        \n\t"   \
+                "vrshr.u16   q11, q15, #8                                                       \n\t"   \
+                "vraddhn.u16 d4, q10, q2                                                        \n\t"   \
+                "vraddhn.u16 d5, q13, q3                                                        \n\t"   \
+                "vraddhn.u16 d2, q8, q12                                                        \n\t"   \
+                "vraddhn.u16 d6, q14, q9                                                        \n\t"   \
+                "vraddhn.u16 d7, q15, q11                                                       \n\t"   \
+                "vadd.u8     q0, q2                                                             \n\t"   \
+                "vadd.u8     q1, q3                                                             \n\t"   \
+                "5:                                                                             \n\t"   \
+if_loadstore(   "vst4.8      {d0-d3}, [%[dst]"#align"]!                                         \n\t")  \
+
+#endif
+
+/*not static*/ inline
+void blit_row_s32a_a8(SkPMColor* dst, const void* vmask, const SkPMColor* src, int n) {
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+    const SkAlpha* msk = static_cast<const SkAlpha*>(vmask);
+    uint32_t tmp, mlo, mhi, alo, ahi;
+    const int eight = 8;
+    if (n < 15) {
+        // Too short to attempt aligned processing
+        if (n & 8) {
+            __asm__ (
+                    "vld1.8      {d16}, [%[msk]]!                                                   \n\t"
+                    "vld4.8      {d0-d3}, [%[src]]!                                                 \n\t"
+                    S32A_A8_TEST("#8*4")
+                    /* Translucency used, or a mixture of opaque and transparent */
+                    S32A_A8_8PIX_BLEND(, YES, NO)
+                    /* Drop through */
+                    "9:                                                                             \n\t"
+            :  /* Outputs */
+                    [mlo]"=&r"(mlo),
+                    [mhi]"=&r"(mhi),
+                    [alo]"=&r"(alo),
+                    [ahi]"=&r"(ahi),
+                    [tmp]"=&r"(tmp),
+                    [src]"+r"(src),
+                    [msk]"+r"(msk),
+                    [dst]"+r"(dst)
+            : /* Inputs */
+            : /* Clobbers */
+                    "cc", "memory"
+            );
+        }
+        if (n & 7)
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_TRAILING_7, S32A_A8_LOADSTORE_D_TRAILING_7, n & 7);
+    } else {
+        // The last 0 - 7 pixels (starting from a 4-pixel boundary) are handled together
+        uintptr_t startrup = (uintptr_t) dst / sizeof (*dst) + 3;
+        uintptr_t end = (uintptr_t) dst / sizeof (*dst) + n;
+        size_t trailing;
+        if ((end & 3) == 0)
+            // No blocks of <8 pixels used at end in these cases
+            trailing = 0;
+        else
+            // If length (discounting alignment to 4-pixel boundaries) is an odd number of 4-pixels,
+            // assign 4 pixels to trailing end to avoid possibility of a leading run of exactly 4,
+            // otherwise use <4 trailing pixels to maximise central 8-pixel blocks
+            trailing = ((startrup ^ end) & 4) + (end & 3);
+        // The inner loop handles an integer number (0+) of 8-pixel blocks at 4-pixel boundaries
+        // The 0 - 7 pixels leading up to this are handled together
+        size_t leading = (n - trailing) & 7;
+
+        // Do leading pixels
+        if (leading != 0) {
+            n -= leading;
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_LEADING_7, S32A_A8_LOADSTORE_D_LEADING_7, leading);
+        }
+
+        // Do inner loop
+        __asm__ (
+                "subs        %[len], #8                                                         \n\t"
+                "bcc         50f                                                                \n\t"
+
+                "10:                                                                            \n\t"
+                "vld1.8      {d16}, [%[msk]]!                                                   \n\t"
+                "vld4.8      {d0-d3}, [%[src]]!                                                 \n\t"
+                S32A_A8_TEST("#8*4")
+                /* Translucency used, or a mixture of opaque and transparent */
+                S32A_A8_8PIX_BLEND(:128, YES, IF_PRELOAD)
+                /* Drop through */
+                "9:                                                                             \n\t"
+                "subs        %[len], #8                                                         \n\t"
+                "bcs         10b                                                                \n\t"
+                "50:                                                                            \n\t"
+        : // Outputs
+                [mlo]"=&r"(mlo),
+                [mhi]"=&r"(mhi),
+                [alo]"=&r"(alo),
+                [ahi]"=&r"(ahi),
+                [tmp]"=&r"(tmp),
+                [src]"+r"(src),
+                [msk]"+r"(msk),
+                [dst]"+r"(dst),
+                [len]"+r"(n)
+        : // Inputs
+        : // Clobbers
+                "cc", "memory"
+        );
+
+        // Do trailing pixels.
+        if (n & 7)
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_TRAILING_7, S32A_A8_LOADSTORE_D_TRAILING_7, n & 7);
+    }
+#else
+    auto mask = (const uint8_t*)vmask;
+
+#ifdef SK_SUPPORT_LEGACY_A8_MASKBLITTER
+    for (int i = 0; i < n; ++i) {
+        if (mask[i]) {
+            dst[i] = SkBlendARGB32(src[i], dst[i], mask[i]);
+        }
+    }
+#else
+    Sk4px::MapDstSrcAlpha(n, dst, src, mask, [](const Sk4px& d, const Sk4px& s, const Sk4px& aa) {
+        const auto s_aa = s.approxMulDiv255(aa);
+        return s_aa + d.approxMulDiv255(s_aa.alphas().inv());
+    });
+#endif
+#endif
+}
+
 }  // namespace SK_OPTS_NS
 
 #endif//SkBlitMask_opts_DEFINED
--- a/src/third_party/skia/src/opts/SkBlitRow_opts.h
+++ b/src/third_party/skia/src/opts/SkBlitRow_opts.h
@@ -89,6 +89,10 @@
 #endif
 
 #if defined(SK_ARM_HAS_NEON)
+#ifdef __ARM_64BIT_STATE
+// No attempt has been made to adapt the inline assembly version for AArch64
+// so fall back to the less performant version that uses intrinsics instead
+
     #include <arm_neon.h>
 
     // SkMulDiv255Round() applied to each lane.
@@ -114,8 +118,193 @@
         return vqadd_u8(src, SkMulDiv255Round_neon8(nalphas, dst));
     }
 
+#else // __ARM_64BIT_STATE
+// Inline ARM AArch32 assembly version
+
+// Macros to specify instructions to only include if targeting ARM or Thumb instruction sets
+#ifdef __thumb__
+#define A(x)
+#define T(x) x
+#else
+#define A(x) x
+#define T(x)
+#endif
+
+// These macros permit optionally-included features to be switched using a parameter to another macro
+#define YES(x) x
+#define NO(x)
+
+// How far ahead (pixels) to preload (undefine to disable prefetch) - determined empirically
+#undef PREFETCH_DISTANCE
+#define PREFETCH_DISTANCE "24"
+
+#ifdef PREFETCH_DISTANCE
+#define IF_PRELOAD YES
+#else
+#define IF_PRELOAD NO
 #endif
 
+/// Macro to load or store 1..7 pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_LOADSTORE_LEADING_7(ls, r0, r1, r2, r3, base, opt)                                       \
+                "tst         %[group_size], #1                                                \n\t"   \
+                opt"                                                                          \n\t"   \
+                "beq         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#base"]:32]!          \n\t"   \
+                "1:                                                                           \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                       \n\t"   \
+                "add         %[tmp], %["#base"], #4                                           \n\t"   \
+                "bpl         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "bcc         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+
+/// Macro to load or store 1..7 pixels in shrink powers-of-2 in size - suitable for trailing pixels
+#define S32A_LOADSTORE_TRAILING_7(ls, r0, r1, r2, r3, base, opt)                                      \
+                "lsls        %[tmp], %[group_size], #30                                       \n\t"   \
+                "add         %[tmp], %["#base"], #4                                           \n\t"   \
+                opt"                                                                          \n\t"   \
+                "bcc         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "bpl         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "tst         %[group_size], #1                                                \n\t"   \
+                "beq         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#base"]:32]!          \n\t"   \
+                "1:                                                                           \n\t"   \
+
+/// Macro to do testing and "over" compositing of a group of 1..7 32bpp premultiplied ARGB leading or trailing pixels
+#define S32A_OPAQUE_7PIX_PROCESS(loadstore_7, size)                                                   \
+    do {                                                                                              \
+        __asm__ volatile (                                                                            \
+                /* Load the leading/trailing source pixels,                                           \
+                 * after initialising all the unused indexes from the first pixel                     \
+                 * so the all-opaque and all-transparent tests still work */                          \
+                loadstore_7(ld, d0, d1, d2, d3, src,                                                  \
+                "vld4.8      {d0[],d1[],d2[],d3[]}, [%[src]]")                                        \
+                /* Test for all-opaque or all-transparent */                                          \
+                "vmov        %[alo], s6                                                       \n\t"   \
+                "vmov        %[ahi], s7                                                       \n\t"   \
+                "vmvn        d31, d3                                                          \n\t"   \
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "addeq       %[dst], %[group_size], lsl #2                                    \n\t"   \
+                "beq         9f                                                               \n\t"   \
+                "cmp         %[alo], #-1                                                      \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "cmpeq       %[ahi], #-1                                                      \n\t"   \
+                "beq         5f                                                               \n\t"   \
+                /* Translucency used, or a mixture of opaque and transparent */                       \
+                loadstore_7(ld, d20, d21, d22, d23, dst, )                                            \
+                "sub         %[dst], %[group_size], lsl #2                                    \n\t"   \
+                S32A_OPAQUE_8PIX_BLEND(, , q0, q1,, NO, NO, NO)                                       \
+                "5:                                                                           \n\t"   \
+                loadstore_7(st, d0, d1, d2, d3, dst, )                                                \
+                /* Drop through */                                                                    \
+                "9:                                                                           \n\t"   \
+        : /* Outputs */                                                                               \
+                [alo]"=&r"(alo),                                                                      \
+                [ahi]"=&r"(ahi),                                                                      \
+                [tmp]"=&r"(tmp),                                                                      \
+                [src]"+r"(src),                                                                       \
+                [dst]"+r"(dst)                                                                        \
+        : /* Inputs */                                                                                \
+                [group_size]"r"(size),                                                                \
+                     [eight]"r"(eight)                                                                \
+        : /* Clobbers */                                                                              \
+                "cc", "memory"                                                                        \
+        );                                                                                            \
+    } while (0)
+
+/// Macro to do testing and "over" compositing of an aligned group of 8 32bpp premultiplied ARGB leading or trailing pixels
+#define S32A_OPAQUE_8PIX_PROCESS(align, if_load)                                                      \
+    do {                                                                                              \
+        __asm__ (                                                                                     \
+if_load(        "vld4.8      {d0-d3}, [%[src]]!                                               \n\t")  \
+                /* Test for all-opaque or all-transparent */                                          \
+                "vmov        %[alo], s6                                                       \n\t"   \
+                "vmov        %[ahi], s7                                                       \n\t"   \
+                "vmvn        d31, d3                                                          \n\t"   \
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "addeq       %[dst], #8*4                                                     \n\t"   \
+                "beq         9f                                                               \n\t"   \
+                "cmp         %[alo], #-1                                                      \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "cmpeq       %[ahi], #-1                                                      \n\t"   \
+                "beq         5f                                                               \n\t"   \
+                /* Translucency used, or a mixture of opaque and transparent */                       \
+                S32A_OPAQUE_8PIX_BLEND(align, , q0, q1, "5:", YES, NO, NO)                            \
+                /* Drop through */                                                                    \
+                "9:                                                                           \n\t"   \
+        :  /* Outputs */                                                                              \
+                [alo]"=&r"(alo),                                                                      \
+                [ahi]"=&r"(ahi),                                                                      \
+                [tmp]"=&r"(tmp),                                                                      \
+                [src]"+r"(src),                                                                       \
+                [dst]"+r"(dst)                                                                        \
+        : /* Inputs */                                                                                \
+        : /* Clobbers */                                                                              \
+                "cc", "memory"                                                                        \
+        );                                                                                            \
+    } while (0)
+
+/// Macro to do "over" compositing blending on 8 32bpp premultiplied ARGB pixels
+/// which are with either translucent or a mixture of opaque and transparent.
+/// Relies on A(x) to determine whether to emit code in ARM state (as opposed to Thumb state).
+/// @arg align           bit-alignment specifier on destination loads/stores (optional)
+/// @arg other_src_alpha D-register specifier for alpha source in other bank (only IF_OVERLAP)
+/// @arg src0            Q-register specifier for blue/green source in this bank
+/// @arg src1            Q-register specifier for red/alpha source in this bank
+/// @arg opt             optional instruction to emit
+/// @arg if_loadstore    YES or NO: whether to do load/store
+/// @arg if_overlap      YES or NO: whether to interleave processing of next iteration
+/// @arg if_preload      YES or NO: whether to insert prefetch instructions
+#define S32A_OPAQUE_8PIX_BLEND(align, other_src_alpha, src0, src1, opt, if_loadstore, if_overlap, if_preload) \
+if_loadstore(   "vld4.8      {d20-d23}, [%[dst]"#align"]                                      \n\t")  \
+if_preload(     "sub         %[tmp], %[len], #1                                               \n\t")  \
+if_overlap(     "vmov        %[alo], %[ahi], "#other_src_alpha"                               \n\t")  \
+if_preload(     "cmp         %[tmp], #" PREFETCH_DISTANCE "                                   \n\t")  \
+                "vmull.u8    q8, d20, d31                                                     \n\t"   \
+if_preload(     "it          cs                                                               \n\t")  \
+if_preload(     "movcs       %[tmp], #" PREFETCH_DISTANCE "                                   \n\t")  \
+                "vmull.u8    q9, d21, d31                                                     \n\t"   \
+                "vmull.u8    q10, d22, d31                                                    \n\t"   \
+                "vmull.u8    q11, d23, d31                                                    \n\t"   \
+if_preload(     "pld         [%[src], %[tmp], lsl #2]                                         \n\t")  \
+                "vrshr.u16   q12, q8, #8                                                      \n\t"   \
+if_preload(     "add         %[tmp], #(32+32)/4                                               \n\t")  \
+                "vrshr.u16   q13, q9, #8                                                      \n\t"   \
+                "vrshr.u16   q14, q10, #8                                                     \n\t"   \
+                "vrshr.u16   q15, q11, #8                                                     \n\t"   \
+if_preload(     "pld         [%[dst], %[tmp], lsl #2]                                         \n\t")  \
+                "vraddhn.u16 d16, q8, q12                                                     \n\t"   \
+                "vraddhn.u16 d17, q9, q13                                                     \n\t"   \
+                "vraddhn.u16 d18, q10, q14                                                    \n\t"   \
+                "vraddhn.u16 d19, q11, q15                                                    \n\t"   \
+if_overlap(     "mvn         %[tmp], %[alo]                                                   \n\t")  \
+if_overlap(     "vmvn        d31, "#other_src_alpha"                                          \n\t")  \
+if_overlap(A(   "orr         %[alo], %[ahi]                                                   \n\t")) \
+                "vadd.i8     "#src0", q8                                                      \n\t"   \
+if_overlap(A(   "mvn         %[ahi], %[ahi]                                                   \n\t")) \
+                "vadd.i8     "#src1", q9                                                      \n\t"   \
+                opt"                                                                          \n\t"   \
+if_loadstore(   "vst4.8      {"#src0", "#src1"}, [%[dst]"#align"]!                            \n\t")  \
+
+#endif // __ARM_64BIT_STATE
+#endif // defined(SK_ARM_HAS_NEON)
+
 namespace SK_OPTS_NS {
 
 /*not static*/
@@ -145,6 +334,10 @@ inline void blit_row_s32a_opaque(SkPMCol
 #endif
 
 #if defined(SK_ARM_HAS_NEON)
+#ifdef __ARM_64BIT_STATE
+    // No attempt has been made to adapt the inline assembly version for AArch64
+    // so fall back to the less performant version that uses intrinsics instead
+
     while (len >= 8) {
         vst4_u8((uint8_t*)dst, SkPMSrcOver_neon8(vld4_u8((const uint8_t*)dst),
                                                  vld4_u8((const uint8_t*)src)));
@@ -167,6 +360,154 @@ inline void blit_row_s32a_opaque(SkPMCol
         vst1_lane_u32(dst, vreinterpret_u32_u8(result), 0);
     }
     return;
+
+#else // __ARM_64BIT_STATE
+    // Inline ARM AArch32 assembly version
+    uint32_t tmp, alo, ahi;
+    const int eight = 8;
+    if (len < 15) {
+        // Too short to attempt aligned processing
+        if (len & 8)
+            S32A_OPAQUE_8PIX_PROCESS(, YES);
+        if (len & 7)
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_TRAILING_7, len & 7);
+    } else {
+        // The last 8 - 15 pixels (starting from a 4-pixel boundary) are handled together
+        uintptr_t startrup = (uintptr_t) dst / sizeof (*dst) + 3;
+        uintptr_t end = (uintptr_t) dst / sizeof (*dst) + len;
+        size_t trailing;
+        if ((end & 3) == 0)
+            // No blocks of <8 pixels used at end in these cases
+            trailing = 8;
+        else
+            // If length (discounting alignment to 4-pixel boundaries) is an odd number of 4-pixels,
+            // assign this to trailing end to avoid possibility of a leading run of exactly 4
+            trailing = 8 + ((startrup ^ end) & 4) + (end & 3);
+        // The inner loop handles an integer number (0+) of 16-pixel blocks at 4-pixel boundaries
+        // The 0..15 pixels leading up to this are handled together
+        size_t leading8 = (len - trailing) & 8;
+        size_t leading7 = (len - trailing) & 7;
+
+        // Do leading pixels
+        if (leading7 != 0) {
+            len -= leading7;
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_LEADING_7, leading7);
+        }
+        if (leading8 != 0) {
+            len -= 8;
+            S32A_OPAQUE_8PIX_PROCESS(:128, YES);
+        }
+
+        // Do inner loop
+        __asm__ (
+                // We enter and leave each iteration of the inner loop with the source
+                // pointer 8 pixels ahead and the destination pointer 8 pixels behind
+                // in order to permit good pipelining. The count of remaining pixels is
+                // reduced by 16 to allow the loop termination test to be combined with
+                // the decrementing of the remaining length.
+                "sub         %[dst], #8*4                                                     \n\t"
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "subs        %[len], #16                                                      \n\t"
+                "bcc         49f                                                              \n\t"
+
+                "10:                                                                          \n\t"
+                // Move alpha to ARM registers for comparison
+                "vmov        %[alo], s6                                                       \n\t"
+                "vmov        %[ahi], s7                                                       \n\t"
+                // Fetch source data for next iteration
+                "vld4.8      {d4-d7}, [%[src]]!                                               \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                // Test if all source pixels are transparent (alpha=0)
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"
+                "beq         19f                                                              \n\t"
+                // Find inverse alpha in case full blending required
+                "vmvn        d31, d3                                                          \n\t"
+                // Test if all source pixels are opaque (alpha=0xff)
+                "cmp         %[alo], #-1                                                      \n\t"
+                "it          eq                                                               \n\t"
+                "cmpeq       %[ahi], #-1                                                      \n\t"
+                "bne         30f                                                              \n\t"
+                // Opaque case: copy source to destination
+                "vst4.8      {d0-d3}, [%[dst]:128]                                            \n\t"
+                // Drop through
+                "19:                                                                          \n\t"
+
+                // Move alpha to ARM registers for comparison
+                "vmov        %[alo], s14                                                      \n\t"
+                "vmov        %[ahi], s15                                                      \n\t"
+                // Fetch source data for next iteration
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                // Test if all source pixels are transparent (alpha=0)
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"
+                "beq         29f                                                              \n\t"
+                // Find inverse alpha in case full blending required
+                "vmvn        d31, d7                                                          \n\t"
+                // Test if all source pixels are opaque (alpha=0xff)
+                "cmp         %[alo], #-1                                                      \n\t"
+                "it          eq                                                               \n\t"
+                "cmpeq       %[ahi], #-1                                                      \n\t"
+                "bne         40f                                                              \n\t"
+                // Opaque case: copy source to destination
+                "vst4.8      {d4-d7}, [%[dst]:128]                                            \n\t"
+                // Drop through
+                "29:                                                                          \n\t"
+                "subs        %[len], #16                                                      \n\t"
+                "bcs         10b                                                              \n\t"
+                "b           49f                                                              \n\t"
+
+                // Mixed or translucent pixels in d0-d3
+                "30:                                                                          \n\t"
+                S32A_OPAQUE_8PIX_BLEND(:128, d7, q0, q1,, YES, YES, IF_PRELOAD)
+A(              "teq         %[alo], #0                                                       \n\t")
+T(              "orrs        %[alo], %[alo], %[ahi]                                           \n\t")
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "beq         29b                                                              \n\t"
+A(              "orrs        %[tmp], %[tmp], %[ahi]                                           \n\t")
+T(              "orns        %[tmp], %[tmp], %[ahi]                                           \n\t")
+                "bne         40f                                                              \n\t"
+                "vst4.8      {d4-d7}, [%[dst]:128]                                            \n\t"
+                "b           29b                                                              \n\t"
+
+                // Mixed or translucent pixels in d4-d7
+                "40:                                                                          \n\t"
+                S32A_OPAQUE_8PIX_BLEND(:128, d3, q2, q3, \
+                "subs        %[len], #16", YES, YES, NO)
+                "bcc         50f                                                              \n\t"
+A(              "teq         %[alo], #0                                                       \n\t")
+T(              "orrs        %[alo], %[alo], %[ahi]                                           \n\t")
+                "vld4.8      {d4-d7}, [%[src]]!                                               \n\t"
+                "beq         19b                                                              \n\t"
+A(              "orrs        %[tmp], %[tmp], %[ahi]                                           \n\t")
+T(              "orns        %[tmp], %[tmp], %[ahi]                                           \n\t")
+                "bne         30b                                                              \n\t"
+                "vst4.8      {d0-d3}, [%[dst]:128]                                            \n\t"
+                "b           19b                                                              \n\t"
+
+                "49:                                                                          \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                "50:                                                                          \n\t"
+        : // Outputs
+                [dst]"+r"(dst),
+                [src]"+r"(src),
+                [len]"+r"(len),
+                [alo]"+r"(alo),
+                [ahi]"+r"(ahi),
+                [tmp]"+r"(tmp)
+        : // Inputs
+        : // Clobbers
+                "cc", "memory"
+        );
+
+        // Do trailing pixels.
+        // There will always be more than 8 of these, and the first 8 are already in d0-d3
+        S32A_OPAQUE_8PIX_PROCESS(:128, NO);
+        if (len & 7)
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_TRAILING_7, len & 7);
+    }
+    return;
+
+#endif // __ARM_64BIT_STATE
 #endif
 
     while (len --> 0) {
